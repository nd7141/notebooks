{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "import openreview\n",
    "import gensim\n",
    "import nltk\n",
    "from collections import Counter, defaultdict as dd\n",
    "import numpy as np\n",
    "from pivottablejs import pivot_ui\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import qgrid\n",
    "from pprint import pprint\n",
    "import re \n",
    "import jellyfish\n",
    "import time\n",
    "\n",
    "from plotly.offline import init_notebook_mode\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = openreview.Client(baseurl='https://openreview.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notes = c.get_notes(invitation='ICLR.cc/2019/Conference/-/Blind_Submission') + \\\n",
    "    c.get_notes(invitation='ICLR.cc/2019/Conference/-/Blind_Submission', offset=1000, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "note = notes[0]\n",
    "jsnote = note.to_json()\n",
    "jsnote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = c.get_notes(forum=\"H1lqZhRcFm\")\n",
    "refs = c.get_references(referent=\"H1lqZhRcFm\")\n",
    "refs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict as dd\n",
    "import re \n",
    "def ratings_and_confidence(notes):\n",
    "    ratings = []\n",
    "    confs = []\n",
    "    for note in notes:\n",
    "        content = note.to_json()['content']\n",
    "        paper = note.to_json()['forum']\n",
    "        if 'rating' in content:\n",
    "            score = int(re.findall(pattern='\\d+', string=content['rating'])[0])\n",
    "            conf = int(re.findall(pattern='\\d+', string=content['confidence'])[0])\n",
    "            ratings.append(score)\n",
    "            confs.append(conf)\n",
    "    return ratings, confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paper_notes = c.get_notes(invitation='ICLR.cc/2019/Conference/-/Blind_Submission') + \\\n",
    "    c.get_notes(invitation='ICLR.cc/2019/Conference/-/Blind_Submission', offset=1000, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paper_notes2 = c.get_notes(invitation='ICLR.cc/2019/Conference/-/Blind_Submission') + \\\n",
    "    c.get_notes(invitation='ICLR.cc/2019/Conference/-/Blind_Submission', offset=1000, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint \n",
    "\n",
    "for ix in range(len(paper_notes)):\n",
    "    print(ix)\n",
    "    forumId = paper_notes[ix].forum\n",
    "    forum_notes = c.get_notes(forum=forumId)\n",
    "    ratings, confidence = ratings_and_confidence(forum_notes)\n",
    "    paper_notes[ix].ratings = ratings\n",
    "    paper_notes[ix].confidence = confidence\n",
    "#     if ix > 10:\n",
    "#         break\n",
    "\n",
    "with open('papers2019_icml.pcl', 'wb+') as f:\n",
    "    pickle.dump(paper_notes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('papers2019_icml.pcl', 'rb+') as f:\n",
    "    paper_notes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_of_ratings(paper_notes):\n",
    "    num_ratings = []\n",
    "    for paper in paper_notes:\n",
    "        num_ratings.append(len(paper.ratings))\n",
    "    return Counter(num_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_ratings(paper_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_rating(paper_notes, field='ratings'):\n",
    "    ratings = []\n",
    "    for paper in paper_notes:\n",
    "        ratings.extend(paper.__getattribute__(field))\n",
    "    return np.mean(ratings), Counter(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_rating(paper_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_rating(paper_notes, 'confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "ratings = []\n",
    "confidence = []\n",
    "for paper in paper_notes:\n",
    "    ratings.extend(paper.__getattribute__('ratings'))\n",
    "    confidence.extend(paper.__getattribute__('confidence'))\n",
    "    \n",
    "# pearsonr(ratings, confidence)\n",
    "len(ratings), len(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "copy = paper_notes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = paper_notes[0]\n",
    "getattr(p, 'confidence', '')\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for paper in paper_notes:\n",
    "    row = dict(tldr = paper.content.get('TL;DR', ''),\n",
    "              ratings = getattr(paper, 'ratings', []),\n",
    "              confidence = getattr(paper, 'confidence', []),\n",
    "              title = paper.content['title'],\n",
    "              avg_rating = np.mean(getattr(paper, 'ratings', [])),\n",
    "              avg_confidence = np.mean(getattr(paper, 'confidence', [])))\n",
    "    rows.append(row)\n",
    "df = pd.DataFrame(rows)\n",
    "df.index.name = 'Index'\n",
    "df = df.iloc[:, [4,1,0,5,3,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>avg_confidence</th>\n",
       "      <th>tldr</th>\n",
       "      <th>ratings</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State-Regularized Recurrent Networks</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.</td>\n",
       "      <td>[6, 6, 5]</td>\n",
       "      <td>[4, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.</td>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>[3, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Deep Weight Prior</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.</td>\n",
       "      <td>[4, 8, 7]</td>\n",
       "      <td>[4, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CoT: Cooperative Training for Generative Modeling of Discrete Data</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.</td>\n",
       "      <td>[7, 7, 7]</td>\n",
       "      <td>[2, 2, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adversarial Information Factorization</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>Learn representations for images that factor out a single attribute.</td>\n",
       "      <td>[6, 6, 6]</td>\n",
       "      <td>[4, 4, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               title  avg_rating  avg_confidence                                                                                                                                                                                                                                tldr    ratings confidence\n",
       "Index                                                                                                                                                                                                                                                                                                                                                                     \n",
       "0      State-Regularized Recurrent Networks                                           5.666667    4.666667        We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.  [6, 6, 5]  [4, 5, 5]\n",
       "1      Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior  5.666667    3.333333        By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.                                            [6, 5, 6]  [3, 3, 4]\n",
       "2      The Deep Weight Prior                                                          6.333333    3.666667        An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.                                                                                                                   [4, 8, 7]  [4, 4, 3]\n",
       "3      CoT: Cooperative Training for Generative Modeling of Discrete Data             7.000000    2.666667        We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.                                                                                                                              [7, 7, 7]  [2, 2, 4]\n",
       "4      Adversarial Information Factorization                                          6.000000    4.000000        Learn representations for images that factor out a single attribute.                                                                                                                                                                [6, 6, 6]  [4, 4, 4]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pivot_ui(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>ratings</th>\n",
       "      <th>title</th>\n",
       "      <th>tldr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4, 5, 5]</td>\n",
       "      <td>[6, 6, 5]</td>\n",
       "      <td>State-Regularized Recurrent Networks</td>\n",
       "      <td>We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3, 3, 4]</td>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior</td>\n",
       "      <td>By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4, 4, 3]</td>\n",
       "      <td>[4, 8, 7]</td>\n",
       "      <td>The Deep Weight Prior</td>\n",
       "      <td>An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2, 2, 4]</td>\n",
       "      <td>[7, 7, 7]</td>\n",
       "      <td>CoT: Cooperative Training for Generative Modeling of Discrete Data</td>\n",
       "      <td>We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4, 4, 4]</td>\n",
       "      <td>[6, 6, 6]</td>\n",
       "      <td>Adversarial Information Factorization</td>\n",
       "      <td>Learn representations for images that factor out a single attribute.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  confidence    ratings                                                                          title                                                                                                                                                                                                                                tldr\n",
       "0  [4, 5, 5]  [6, 6, 5]  State-Regularized Recurrent Networks                                           We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\n",
       "1  [3, 3, 4]  [6, 5, 6]  Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior  By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.                                          \n",
       "2  [4, 4, 3]  [4, 8, 7]  The Deep Weight Prior                                                          An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.                                                                                                                 \n",
       "3  [2, 2, 4]  [7, 7, 7]  CoT: Cooperative Training for Generative Modeling of Discrete Data             We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.                                                                                                                            \n",
       "4  [4, 4, 4]  [6, 6, 6]  Adversarial Information Factorization                                          Learn representations for images that factor out a single attribute.                                                                                                                                                              "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_options = {\n",
    "            'fullWidthRows': True,\n",
    "            'syncColumnCellResize': True,\n",
    "            'forceFitColumns': True,\n",
    "            'defaultColumnWidth': 150,\n",
    "            'rowHeight': 28,\n",
    "            'enableColumnReorder': False,\n",
    "            'enableTextSelectionOnCells': True,\n",
    "            'editable': True,\n",
    "            'autoEdit': False,\n",
    "            'explicitInitialization': True,\n",
    "            'maxVisibleRows': 15,\n",
    "            'minVisibleRows': 8\n",
    "        }\n",
    "# grid_options = {\n",
    "#     'rowHeight': 50\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = dict(title= 'CoT: Cooperative Training for Generative Modeling of Discrete Data',\n",
    "tldr= 'We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data. We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.')\n",
    "df = pd.DataFrame([row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_confidence</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>confidence</th>\n",
       "      <th>ratings</th>\n",
       "      <th>title</th>\n",
       "      <th>tldr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>[4, 5, 5]</td>\n",
       "      <td>[6, 6, 5]</td>\n",
       "      <td>State-Regularized Recurrent Networks</td>\n",
       "      <td>We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.333333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>[3, 3, 4]</td>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior</td>\n",
       "      <td>By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>[4, 4, 3]</td>\n",
       "      <td>[4, 8, 7]</td>\n",
       "      <td>The Deep Weight Prior</td>\n",
       "      <td>An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>[2, 2, 4]</td>\n",
       "      <td>[7, 7, 7]</td>\n",
       "      <td>CoT: Cooperative Training for Generative Modeling of Discrete Data</td>\n",
       "      <td>We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>[4, 4, 4]</td>\n",
       "      <td>[6, 6, 6]</td>\n",
       "      <td>Adversarial Information Factorization</td>\n",
       "      <td>Learn representations for images that factor out a single attribute.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_confidence  avg_rating confidence    ratings                                                                          title                                                                                                                                                                                                                                tldr\n",
       "Index                                                                                                                                                                                                                                                                                                                                                                     \n",
       "0      4.666667        5.666667    [4, 5, 5]  [6, 6, 5]  State-Regularized Recurrent Networks                                           We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\n",
       "1      3.333333        5.666667    [3, 3, 4]  [6, 5, 6]  Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior  By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.                                          \n",
       "2      3.666667        6.333333    [4, 4, 3]  [4, 8, 7]  The Deep Weight Prior                                                          An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.                                                                                                                 \n",
       "3      2.666667        7.000000    [2, 2, 4]  [7, 7, 7]  CoT: Cooperative Training for Generative Modeling of Discrete Data             We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.                                                                                                                            \n",
       "4      4.000000        6.000000    [4, 4, 4]  [6, 6, 6]  Adversarial Information Factorization                                          Learn representations for images that factor out a single attribute.                                                                                                                                                              "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cedb93d128d4b5d89ccd05edbbd875c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# col_opts = { \n",
    "#     'editable': False,\n",
    "#     'toolTip': \"Not editable\"\n",
    "# }\n",
    "\n",
    "col_defs = {\n",
    "    name: {\n",
    "        'width': 50\n",
    "    } for name in ['Index', 'avg_confidence', 'avg_rating', 'confidence', 'ratings']\n",
    "}\n",
    "qgrid.show_grid(df, column_definitions=col_defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint(paper_notes[0].to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = openreview.Client(baseurl='https://openreview.net')\n",
    "# notes = c.get_notes(limit = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cdate': 1542286428411,\n",
      " 'content': {'confidence': '4: The reviewer is confident but not absolutely '\n",
      "                           'certain that the evaluation is correct',\n",
      "             'rating': '5: Marginally below acceptance threshold',\n",
      "             'review': 'Summary. The authors propose a novel adversarial '\n",
      "                       'training method, e2SAD, that relies on a two-step '\n",
      "                       'process for generating sets of two training '\n",
      "                       'adversarial samples for each clean training sample. '\n",
      "                       'The first step is a classical FGSM that yields the '\n",
      "                       'first adversarial sample. The second adversarial '\n",
      "                       'sample is calculated with a FGSM that is based on the '\n",
      "                       'cross-entropy between the probabilities generated by '\n",
      "                       'the first adversarial sample and the probabilities '\n",
      "                       'generated by the second adversarial sample. The method '\n",
      "                       'is computationally efficient (two forward/backward '\n",
      "                       'passes per clean sample) w.r.t. powerful iterative '\n",
      "                       'attacks such as IFGSM or PGD requiring 40+ steps and '\n",
      "                       'the authors claim it gives comparable results to '\n",
      "                       'adversarial training with multi-step attacks methods '\n",
      "                       'in white and black-box settings.\\n'\n",
      "                       '\\n'\n",
      "                       'Clarity. Part 1 and 2 of the paper are well written '\n",
      "                       'and summarize the existing attacks/defense mechanisms, '\n",
      "                       'their pros and cons as well as the contributions '\n",
      "                       'clearly. The next sections could be made shorter (see '\n",
      "                       'comments below) to match ICLR’s recommended soft limit '\n",
      "                       'of 8 pages instead of the 10 pages hard limit. This '\n",
      "                       'would also help the reader grasp the key ideas faster '\n",
      "                       'and have a standard formatting (no negative spaces for '\n",
      "                       'instance).\\n'\n",
      "                       '\\n'\n",
      "                       'Novelty. The idea of simulating the effect of '\n",
      "                       'iterative attacks using two distinct steps is novel '\n",
      "                       'and appealing to me. The first step increases the loss '\n",
      "                       'while the second step shifts the probability '\n",
      "                       'distributions apart.\\n'\n",
      "                       '\\n'\n",
      "                       'Pros and cons.\\n'\n",
      "                       '(+) The paper is clear and easy to follow, although a '\n",
      "                       'bit long.\\n'\n",
      "                       '(+) The idea is interesting and clearly motivated in '\n",
      "                       'terms of computational efficiency and in terms of '\n",
      "                       'desired properties (Figure 2 illustrates this point '\n",
      "                       'well).\\n'\n",
      "                       '\\n'\n",
      "                       '(-) Only one aspect of the idea is exploited in the '\n",
      "                       'article. It would be interesting to compare this '\n",
      "                       'method as an attacker (both in terms of performance '\n",
      "                       'and in terms of generated samples, see comment below). '\n",
      "                       'Powerful adversarial training should indeed rely on '\n",
      "                       'powerful generated adversarial samples.\\n'\n",
      "                       '(-) The results seem somewhat mitigated in terms of '\n",
      "                       'significance and conclusions drawn by the authors. '\n",
      "                       'Also, the experimental setup is quite light, notably '\n",
      "                       'the used CNN architectures are quite small and other '\n",
      "                       'datasets could have been used (also linked to the '\n",
      "                       'significance of the results).\\n'\n",
      "                       '\\n'\n",
      "                       'Comments.\\n'\n",
      "                       '- Shorter paper. Here are suggested modifications for '\n",
      "                       'the paper that could help strengthen the impact of '\n",
      "                       'your paper. Section 3.1 could be almost entirely '\n",
      "                       'discarded as it brings no new ideas w.r.t sections 1 '\n",
      "                       'and 2. Figure 1 summarizes the method well, thus the '\n",
      "                       'description in Section 3.2 could be made shorter, '\n",
      "                       'especially when displaying Equation (8) right after '\n",
      "                       'Figure 1. This would then help reduce the size of '\n",
      "                       'Sections 3.2.1 and 3.2.2 (because Equation (8) and '\n",
      "                       'Figure 1 would prevent you from repeating claims made '\n",
      "                       'earlier in the paper). Algorithm 1 is straightforward '\n",
      "                       'and could be placed in Appendix. Conclusion and Result '\n",
      "                       'sections could be shortened a little as well (not as '\n",
      "                       'much as Section 3 though).\\n'\n",
      "                       '\\n'\n",
      "                       '- Significance of the results. The significance of '\n",
      "                       'some results is unclear to me. Could the authors '\n",
      "                       'provide the standard deviation over 3 or 5 runs? For '\n",
      "                       'example, in rows 1, 3, 4, 5, 6 of Table 2, it is not '\n",
      "                       'clear it e2SAD performs better than FGSM adversarial '\n",
      "                       'training, thus raising the question of the necessity '\n",
      "                       'of Step 2 of the attack (which is the core '\n",
      "                       'contribution of the paper).\\n'\n",
      "                       '\\n'\n",
      "                       '- Experimental setup. The last two rows of Table 1 are '\n",
      "                       'encouraging for e2SAD. However, the authors could '\n",
      "                       'introduce another dataset, e.g. CIFAR10 or 100 or even '\n",
      "                       'ImageNet restricted to 20 or 100 random classes/with '\n",
      "                       'fewer samples per class and use deeper modern CNN '\n",
      "                       'architectures like ResNets (even a ResNet18). Those '\n",
      "                       'models are widely adopted both in the research '\n",
      "                       'community and by the industry, thus defense mechanisms '\n",
      "                       'that provably work for such models can have a huge '\n",
      "                       'impact.\\n'\n",
      "                       '\\n'\n",
      "                       '- Defense setup. Is the order of Steps 1 and 2 '\n",
      "                       'relevant? What if the authors use only iterations of '\n",
      "                       'Step 2?\\n'\n",
      "                       '\\n'\n",
      "                       '- Attack setup. Here are a few suggestions for '\n",
      "                       'assessing your method in an attack setting: what is '\n",
      "                       'the precision of the network, without any defense, '\n",
      "                       'given an average dissimilarity L2 budget in the '\n",
      "                       'training/test samples, in a white/black box setting? '\n",
      "                       'How does it compare to standard techniques (e.g. FGSM, '\n",
      "                       'IFGSM, DeepFool, Carlini)? What happens if the authors '\n",
      "                       'use their method both for both defense and attack? '\n",
      "                       'Could the authors display adversarial samples '\n",
      "                       'generated by their method?\\n'\n",
      "                       '\\n'\n",
      "                       'Conclusion. The idea presented in the paper is '\n",
      "                       'interesting, but (1) the experimental results are not '\n",
      "                       'entirely satisfactory for the moment and (2) only one '\n",
      "                       'aspect of the idea is exploited in the paper, which '\n",
      "                       'can be made more interesting and impactful while '\n",
      "                       'studying both attack and defense setups. I strongly '\n",
      "                       'encourage the authors to continue their research in '\n",
      "                       'this area due to the high potential impact and '\n",
      "                       'benefits for the whole community.',\n",
      "             'title': 'Interesting research direction but needs more thorough '\n",
      "                      'experiments'},\n",
      " 'ddate': None,\n",
      " 'details': {'replyCount': 0},\n",
      " 'forum': 'BklpOo09tQ',\n",
      " 'id': 'ByeVD2kjam',\n",
      " 'invitation': 'ICLR.cc/2019/Conference/-/Paper398/Official_Review',\n",
      " 'nonreaders': [],\n",
      " 'number': 3,\n",
      " 'original': None,\n",
      " 'readers': ['everyone'],\n",
      " 'referent': None,\n",
      " 'replyto': 'BklpOo09tQ',\n",
      " 'signatures': ['ICLR.cc/2019/Conference/Paper398/AnonReviewer4'],\n",
      " 'tcdate': 1542286428411,\n",
      " 'tmdate': 1542286428411,\n",
      " 'writers': ['ICLR.cc/2019/Conference']}\n"
     ]
    }
   ],
   "source": [
    "review_iterator = openreview.tools.iterget_notes(client, invitation='ICLR.cc/2019/Conference/-/Paper.*/Official_Review')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Note(id = 'HJf7ts0cFm',original = 'B1l3kE55KQ',number = 431,cdate = 1538087803027,tcdate = 1538087803027,tmdate = 1542208692666,ddate = None,content = {'title': 'State-Regularized Recurrent Networks', 'abstract': \"Recurrent networks are a widely used class of neural architectures.  They have, however, two shortcomings. First, it is difficult to understand what exactly they learn. Second, they tend to work poorly on sequences requiring long-term memorization, despite having this capacity in principle. We aim to address both shortcomings with a class of recurrent networks that use a stochastic state transition mechanism between cell applications. This mechanism, which we term state-regularization, makes RNNs transition between a finite set of learnable states. We show that state-regularization (a) simplifies the extraction of finite state automata modeling an RNN's state transition dynamics, and (b) forces RNNs to operate more like automata with external memory and less like finite state machines.\", 'keywords': ['recurrent network', 'finite state machines', 'state-regularized', 'interpretability and explainability'], 'authorids': ['ICLR.cc/2019/Conference/Paper431/Authors'], 'authors': ['Anonymous'], 'TL;DR': 'We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.', 'pdf': '/pdf/b9076c54d2f1f0b845a2ae7198b0781826bddabd.pdf', 'paperhash': 'anonymous|stateregularized_recurrent_networks', '_bibtex': '@inproceedings{    \\nanonymous2019state-regularized,    \\ntitle={State-Regularized Recurrent Networks},    \\nauthor={Anonymous},    \\nbooktitle={Submitted to International Conference on Learning Representations},    \\nyear={2019},    \\nurl={https://openreview.net/forum?id=HJf7ts0cFm},    \\nnote={under review}    \\n}'},forum = 'HJf7ts0cFm',referent = None,invitation = 'ICLR.cc/2019/Conference/-/Blind_Submission',replyto = None,readers = ['everyone'],nonreaders = [],signatures = ['ICLR.cc/2019/Conference'],writers = ['ICLR.cc/2019/Conference'],details = {'replyCount': 6},ratings = [6, 6, 5],confidence = [4, 5, 5])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_notes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratings_and_confidence():\n",
    "    client = openreview.Client(baseurl='https://openreview.net')\n",
    "    review_iterator = openreview.tools.iterget_notes(client, invitation='ICLR.cc/2019/Conference/-/Paper.*/Official_Review')\n",
    "    ratings = dd(list)\n",
    "    confidence = dd(list)\n",
    "    for review in review_iterator:\n",
    "        ratings[review.forum].append(int(re.findall(pattern='\\d+', string=review.content['rating'])[0]))\n",
    "        confidence[review.forum].append(int(re.findall(pattern='\\d+', string=review.content['confidence'])[0]))\n",
    "    return ratings, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_papers():\n",
    "    client = openreview.Client(baseurl='https://openreview.net')\n",
    "    paper_iterator = openreview.tools.iterget_notes(client, invitation='ICLR.cc/2019/Conference/-/Blind_Submission')\n",
    "    return list(paper_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings, confidence = ratings_and_confidence()\n",
    "papers = all_papers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_ratings(papers, ratings, confidence):\n",
    "    for ix in range(len(papers)):\n",
    "        forum = papers[ix].forum\n",
    "        papers[ix].ratings = ratings.get(forum, [])\n",
    "        papers[ix].confidence = confidence.get(forum, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_ratings(papers, ratings, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(papers):\n",
    "    return list(set([word.strip().lower() for p in papers for word in p.content['keywords']]))\n",
    "\n",
    "def get_similarity(keywords):\n",
    "    sim = dict()\n",
    "    N = len(keywords)\n",
    "    for i in range(N-1):\n",
    "        for j in range(i+1, N):\n",
    "            topic1 = keywords[i]\n",
    "            topic2 = keywords[j]\n",
    "            dist = len(set(topic1).intersection(set(topic2)))/len(set(max([topic1, topic2], key=lambda v: len(v))))\n",
    "            if topic1 != topic2 and dist > 0.75:\n",
    "                dist = jellyfish.levenshtein_distance(topic1, topic2)\n",
    "                sim[topic1, topic2] = dist\n",
    "    return sim\n",
    "\n",
    "def get_top_matches(sim):\n",
    "    matches = dd(list)\n",
    "    for pair in sim:\n",
    "        if sim[pair] == 1:\n",
    "            matches[pair[0]].append(pair[1])\n",
    "            matches[pair[1]].append(pair[0])\n",
    "    return matches    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity computed in 118.28 sec\n"
     ]
    }
   ],
   "source": [
    "keywords = get_keywords(papers)\n",
    "start = time.time()\n",
    "sim = get_similarity(keywords) # this takes about 2 minutes \n",
    "finish = time.time()\n",
    "print('Similarity computed in {:.2f} sec'.format(finish - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('active learning', 'active  learning'), 1),\n",
      " (('active learning', 'machine learning'), 3),\n",
      " (('active tracking', 'active learning'), 4),\n",
      " (('active learning', 'code learning'), 4),\n",
      " (('active learning', 'inductive learning'), 4),\n",
      " (('feature learning', 'active learning'), 5),\n",
      " (('active learning', 'td learning'), 5),\n",
      " (('active learning', 'predictive learning'), 5),\n",
      " (('active learning', 'set learning'), 5),\n",
      " (('active learning', 'meta learning'), 5),\n",
      " (('active learning', 'metric learning'), 5),\n",
      " (('hebbian learning', 'active learning'), 6),\n",
      " (('active learning', 'robust learning'), 6),\n",
      " (('active learning', 'concept learning'), 6),\n",
      " (('active learning', 'structure learning'), 6),\n",
      " (('active learning', 'spectral learning'), 6),\n",
      " (('active learning', 'tactile sensing'), 6),\n",
      " (('active learning', 'relation learning'), 6),\n",
      " (('active learning', 'generative learning'), 6),\n",
      " (('active learning', 'stream learning'), 6),\n",
      " (('active learning', 'distance learning'), 6),\n",
      " (('active learning', 'continual learning'), 7),\n",
      " (('active learning', 'transfer learning'), 7),\n",
      " (('active learning', 'imitation learning'), 7),\n",
      " (('active learning', 'dictionary learning'), 7),\n",
      " (('active learning', 'structured learning'), 7),\n",
      " (('continuous learning', 'active learning'), 8),\n",
      " (('active learning', 'rule list learning'), 8),\n",
      " (('active learning', 'introspective learning'), 8),\n",
      " (('active learning', 'federated learning'), 8),\n",
      " (('active learning', 'active perception'), 8),\n",
      " (('active learning', 'lifelong learning'), 8),\n",
      " (('active learning', 'architecture learning'), 8),\n",
      " (('active learning', 'expectation learning'), 8),\n",
      " (('active learning', 'stable training'), 8),\n",
      " (('active learning', 'relational learning'), 8),\n",
      " (('active learning', 'geometric learning'), 8),\n",
      " (('preference learning', 'active learning'), 9),\n",
      " (('active learning', 'latent-tree-learning'), 9),\n",
      " (('active learning', 'adversarial learning'), 9),\n",
      " (('active learning', 'large-scale learning'), 9),\n",
      " (('active learning', 'incremental learning'), 9),\n",
      " (('active learning', 'multiscale rnn'), 9),\n",
      " (('active learning', 'curriculum learning'), 9),\n",
      " (('active learning', 'channel charting'), 9),\n",
      " (('active learning', 'channel pruning'), 9),\n",
      " (('active learning', 'semantic training'), 9),\n",
      " (('active learning', 'filter training'), 9),\n",
      " (('action recognition', 'active learning'), 10),\n",
      " (('active learning', 'asset pricing'), 10),\n",
      " (('active learning', 'apprenticeship learning'), 10),\n",
      " (('active learning', 'variable naming'), 10),\n",
      " (('active learning', 'feature pooling'), 10),\n",
      " (('active learning', 'cost-sensitive learning'), 10),\n",
      " (('neural causal learning', 'active learning'), 11),\n",
      " (('active learning', 'generative modeling'), 11),\n",
      " (('active learning', 'negative transfer'), 11),\n",
      " (('active learning', 'weight averaging'), 11),\n",
      " (('active learning', 'incremental parsing'), 11),\n",
      " (('active learning', 'distance kernel'), 11),\n",
      " (('active learning', 'fact verification'), 11),\n",
      " (('active learning', 'activity recognition'), 11),\n",
      " (('active learning', 'efficient deep learning'), 11),\n",
      " (('active learning', 'relational reasoning'), 11),\n",
      " (('active learning', 'scene generation'), 11),\n",
      " (('active learning', 'scale invariance'), 11),\n",
      " (('active learning', 'noise covariance'), 11),\n",
      " (('natural language', 'active learning'), 12),\n",
      " (('incremental training', 'active learning'), 12),\n",
      " (('large scale training', 'active learning'), 12),\n",
      " (('selective inference', 'active learning'), 12),\n",
      " (('learning rate', 'active learning'), 12),\n",
      " (('scaling rules', 'active learning'), 12),\n",
      " (('active learning', 'reinforcement learning'), 12),\n",
      " (('active learning', 'deictic reference'), 12),\n",
      " (('active learning', 'value iteration'), 12),\n",
      " (('active learning', 'evaluation metric'), 12),\n",
      " (('active learning', 'adversarial training'), 12),\n",
      " (('active learning', 'generative modelling'), 12),\n",
      " (('active learning', 'value function'), 12),\n",
      " (('active learning', 'distance metric learning'), 12),\n",
      " (('active learning', 'trail detection'), 12),\n",
      " (('active learning', 'learning to rank'), 12),\n",
      " (('active learning', 'language drift'), 12),\n",
      " (('active learning', 'image retrieval'), 12),\n",
      " (('active learning', 'face recognition'), 12),\n",
      " (('active learning', 'adversarial net'), 12),\n",
      " (('active learning', 'behavioral cloning'), 12),\n",
      " (('active learning', 'cognitive science'), 12),\n",
      " (('active learning', 'feature engineering'), 12),\n",
      " (('active learning', 'video generation'), 12),\n",
      " (('active learning', 'policy transfer'), 12),\n",
      " (('active learning', 'natural gradient'), 12),\n",
      " (('active learning', 'relative prediction'), 12),\n",
      " (('active learning', 'convergence time'), 12),\n",
      " (('active learning', 'image generation'), 12),\n",
      " (('active learning', 'agent evaluation'), 12),\n",
      " (('active learning', 'early terminating'), 12),\n",
      " (('active learning', 'learning to learn'), 12),\n",
      " (('active learning', 'face verification'), 12),\n",
      " (('learning-to-learn', 'active learning'), 13),\n",
      " (('learning to plan', 'active learning'), 13),\n",
      " (('differential training', 'active learning'), 13),\n",
      " (('large batch training', 'active learning'), 13),\n",
      " (('active learning', 'gradient descent'), 13),\n",
      " (('active learning', 'learning theory'), 13),\n",
      " (('active learning', 'temporal logic'), 13),\n",
      " (('active learning', 'teaching to teach'), 13),\n",
      " (('active learning', 'language generation'), 13),\n",
      " (('active learning', 'generative agents'), 13),\n",
      " (('active learning', 'learning curves'), 13),\n",
      " (('active learning', 'pattern recognition'), 13),\n",
      " (('active learning', 'animal recognition'), 13),\n",
      " (('active learning', 'relu activation'), 13),\n",
      " (('active learning', 'faster inference'), 13),\n",
      " (('active learning', 'navigation agent'), 13),\n",
      " (('active learning', 'variable selection'), 13),\n",
      " (('active learning', 'iterative neural training'), 13),\n",
      " (('active learning', 'word alignment'), 13),\n",
      " (('active learning', 'neural attention'), 13),\n",
      " (('active learning', 'latent variables'), 13),\n",
      " (('active learning', 'large-batch training'), 13),\n",
      " (('active learning', 'multilingual nmt'), 13),\n",
      " (('active learning', 'graph alignment'), 13),\n",
      " (('active learning', 'image recognition'), 13),\n",
      " (('active learning', 'data aggregation'), 13),\n",
      " (('active learning', 'materials science'), 13),\n",
      " (('active learning', 'learning to drive'), 13),\n",
      " (('active learning', 'neural listeners'), 13),\n",
      " (('active learning', 'genetic algorithm'), 13),\n",
      " (('wasserstein gan', 'active learning'), 14),\n",
      " (('active learning', 'relation extraction'), 14),\n",
      " (('active learning', 'variational encoder'), 14),\n",
      " (('active learning', 'riemannian transe'), 14),\n",
      " (('active learning', 'generative model'), 14),\n",
      " (('active learning', 'conditional gradient'), 14),\n",
      " (('active learning', 'gradient staleness'), 14),\n",
      " (('active learning', 'variation inference'), 14),\n",
      " (('active learning', 'revenue management'), 14),\n",
      " (('active learning', 'cyclic adversarial learning'), 14),\n",
      " (('active learning', 'energy efficiency'), 14),\n",
      " (('active learning', 'label correction'), 14),\n",
      " (('active learning', 'invariant feature learning'), 14),\n",
      " (('active learning', 'evolving algorithm'), 14),\n",
      " (('active learning', 'language recognition'), 14),\n",
      " (('active learning', 'singular values'), 14),\n",
      " (('active learning', 'training criteria'), 14),\n",
      " (('active learning', 'tensor ring nets'), 14),\n",
      " (('active learning', 'label correlation'), 14),\n",
      " (('active variable selection', 'active learning'), 15),\n",
      " (('target propagation', 'active learning'), 15),\n",
      " (('regression tree', 'active learning'), 15),\n",
      " (('active learning', 'improving retrieval'), 15),\n",
      " (('active learning', 'referential language'), 15),\n",
      " (('active learning', 'evaluation criteria'), 15),\n",
      " (('active learning', 'efficient inference'), 15),\n",
      " (('active learning', 'learning to execute'), 15),\n",
      " (('active learning', 'neural turing machine'), 15),\n",
      " (('active learning', 'meta reinforcement learning'), 15),\n",
      " (('active learning', 'learning rate decay'), 15),\n",
      " (('active learning', 'abstaining classifier'), 15),\n",
      " (('active learning', 'evolution strategies'), 15),\n",
      " (('active learning', 'variational lnference'), 15),\n",
      " (('active learning', 'hierarchical clustering'), 15),\n",
      " (('active learning', 'conditioned generation'), 15),\n",
      " (('active learning', 'sensitivity analysis'), 15),\n",
      " (('active learning', 'video action recognition'), 16),\n",
      " (('active learning', 'latent space engineering'), 16),\n",
      " (('active learning', 'conversational agent'), 16),\n",
      " (('active learning', 'adaptive gradient descent'), 16),\n",
      " (('active learning', 'variational inference'), 16),\n",
      " (('active learning', 'gradient acceleration'), 16),\n",
      " (('active learning', 'variational inference.'), 16),\n",
      " (('active learning', 'formal verification'), 16),\n",
      " (('active learning', 'new learning criterion'), 16),\n",
      " (('active learning', 'statistical inference'), 16),\n",
      " (('active learning', 'convergence analysis'), 16),\n",
      " (('active learning', 'translation control'), 16),\n",
      " (('adversarial instances', 'active learning'), 17),\n",
      " (('artificial intelligence', 'active learning'), 17),\n",
      " (('active learning', 'gradient equivalence'), 17),\n",
      " (('active learning', 'learning rate restarts'), 17),\n",
      " (('active learning', 'translational invariance'), 17),\n",
      " (('active learning', 'generalization error'), 17),\n",
      " (('active learning', 'discrete latent variable'), 17),\n",
      " (('active learning', 'variational autoencoder'), 17),\n",
      " (('adversarial divergences', 'active learning'), 18),\n",
      " (('active learning', 'discrete latent variables'), 18),\n",
      " (('active learning', 'variational auto encoder'), 18),\n",
      " (('active learning', 'generative adversarial nets'), 18),\n",
      " (('active learning', 'statistical relational learning'), 18),\n",
      " (('active learning', 'generative adversarial learning'), 18),\n",
      " (('active learning', 'training data selection'), 18),\n",
      " (('active learning', 'generative adversarial training'), 19),\n",
      " (('active learning', 'neural activation function'), 19),\n",
      " (('active learning', 'natural scene statistics'), 19),\n",
      " (('active learning', 'statistical characteristics'), 20),\n",
      " (('active learning', 'natural language inference'), 20),\n",
      " (('active learning', 'convergence rate analysis'), 20),\n",
      " (('active learning', 'large variations resistance'), 21),\n",
      " (('active learning', 'conditional image generation'), 21),\n",
      " (('active learning', 'sentence representations learning'), 21),\n",
      " (('active learning', 'natural language generation'), 21),\n",
      " (('controllable text generation', 'active learning'), 22),\n",
      " (('active learning', 'conditional generative model'), 22),\n",
      " (('active learning', 'controllable image generation'), 22),\n",
      " (('active learning', 'functional variational inference'), 23),\n",
      " (('active learning', 'hierarchical neural architecture'), 24),\n",
      " (('conditional variational autoencoder', 'active learning'), 28),\n",
      " (('active learning', 'reduction on convolution calculation'), 29)]\n"
     ]
    }
   ],
   "source": [
    "keys = []\n",
    "for key in sim:\n",
    "    if 'active learning' in key:\n",
    "        keys.append(key)\n",
    "pprint(sorted([(key, sim[key]) for key in keys], key=lambda v: v[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = get_top_matches(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'3d learning': ['td learning'],\n",
       "             'activation function': ['activation functions'],\n",
       "             'activation functions': ['activation function'],\n",
       "             'active  learning': ['active learning'],\n",
       "             'active learning': ['active  learning'],\n",
       "             'adam': ['admm'],\n",
       "             'adaptive method': ['adaptive methods'],\n",
       "             'adaptive methods': ['adaptive method'],\n",
       "             'admm': ['adam'],\n",
       "             'adversarial attack': ['adversarial attacks'],\n",
       "             'adversarial attacks': ['adversarial attack'],\n",
       "             'adversarial defence': ['adversarial defense'],\n",
       "             'adversarial defense': ['adversarial defence'],\n",
       "             'adversarial example': ['adversarial examples'],\n",
       "             'adversarial examples': ['adversarial example'],\n",
       "             'adversarial perturbation': ['adversarial perturbations'],\n",
       "             'adversarial perturbations': ['adversarial perturbation'],\n",
       "             'algorithm': ['algorithms'],\n",
       "             'algorithms': ['algorithm'],\n",
       "             'amortised inference': ['amortized inference'],\n",
       "             'amortized inference': ['amortised inference'],\n",
       "             'artificial neural network': ['artificial neural networks'],\n",
       "             'artificial neural networks': ['artificial neural network'],\n",
       "             'attention model': ['attention models'],\n",
       "             'attention models': ['attention model'],\n",
       "             'auto-encoders': ['autoencoders'],\n",
       "             'autodl': ['automl'],\n",
       "             'autoencoder': ['autoencoders'],\n",
       "             'autoencoders': ['autoencoder', 'auto-encoders'],\n",
       "             'automl': ['autodl'],\n",
       "             'autoregressive model': ['autoregressive models'],\n",
       "             'autoregressive models': ['autoregressive model'],\n",
       "             'back-propagation': ['backpropagation'],\n",
       "             'backpropagation': ['back-propagation'],\n",
       "             'bayesian neural network': ['bayesian neural networks'],\n",
       "             'bayesian neural networks': ['bayesian neural network'],\n",
       "             'bayesian nonparametric': ['bayesian nonparametrics'],\n",
       "             'bayesian nonparametrics': ['bayesian nonparametric'],\n",
       "             'bias-variance trade-off': ['bias-variance tradeoff'],\n",
       "             'bias-variance tradeoff': ['bias-variance trade-off'],\n",
       "             'binary neural network': ['binary neural networks'],\n",
       "             'binary neural networks': ['binary neural network'],\n",
       "             'black box': ['black-box'],\n",
       "             'black box optimization': ['blackbox optimization'],\n",
       "             'black-box': ['black box'],\n",
       "             'black-box attack': ['black-box attacks'],\n",
       "             'black-box attacks': ['black-box attack'],\n",
       "             'blackbox optimization': ['black box optimization'],\n",
       "             'capsule network': ['capsule networks'],\n",
       "             'capsule networks': ['capsule network'],\n",
       "             'catastrophic forgetting': ['catatrophic forgetting'],\n",
       "             'catatrophic forgetting': ['catastrophic forgetting'],\n",
       "             'compositionality': ['compostionality'],\n",
       "             'compostionality': ['compositionality'],\n",
       "             'conditional gan': ['conditional gans'],\n",
       "             'conditional gans': ['conditional gan'],\n",
       "             'conditional generative model': ['conditional generative models'],\n",
       "             'conditional generative models': ['conditional generative model'],\n",
       "             'continuous relaxation': ['continuous relaxations'],\n",
       "             'continuous relaxations': ['continuous relaxation'],\n",
       "             'convolution': ['convolutions'],\n",
       "             'convolutional network': ['convolutional networks'],\n",
       "             'convolutional networks': ['convolutional network'],\n",
       "             'convolutional neural network': ['convolutional neural networks'],\n",
       "             'convolutional neural networks': ['convolutional neural network'],\n",
       "             'convolutions': ['convolution'],\n",
       "             'cross entropy': ['cross-entropy'],\n",
       "             'cross-entropy': ['cross entropy'],\n",
       "             'decision tree': ['decision trees'],\n",
       "             'decision trees': ['decision tree'],\n",
       "             'deep generative model': ['deep generative models'],\n",
       "             'deep generative models': ['deep generative model'],\n",
       "             'deep learning': ['deep-learning', 'deeplearning'],\n",
       "             'deep network': ['deep networks'],\n",
       "             'deep networks': ['deep network'],\n",
       "             'deep neural network': ['deep neural networks'],\n",
       "             'deep neural networks': ['deep neural networks.',\n",
       "              'deep neural network'],\n",
       "             'deep neural networks.': ['deep neural networks'],\n",
       "             'deep rl': ['deeprl'],\n",
       "             'deep-learning': ['deep learning', 'deeplearning'],\n",
       "             'deeplearning': ['deep-learning', 'deep learning'],\n",
       "             'deeprl': ['deep rl'],\n",
       "             'defence': ['defense'],\n",
       "             'defense': ['defence'],\n",
       "             'denoising': ['denosing'],\n",
       "             'denosing': ['denoising'],\n",
       "             'differential equation': ['differential equations'],\n",
       "             'differential equations': ['differential equation'],\n",
       "             'discrete latent variable': ['discrete latent variables'],\n",
       "             'discrete latent variables': ['discrete latent variable'],\n",
       "             'disentangled representation': ['disentangled representations'],\n",
       "             'disentangled representations': ['disentangled representation'],\n",
       "             'dynamic network': ['dynamic networks'],\n",
       "             'dynamic networks': ['dynamic network'],\n",
       "             'dynamical system': ['dynamical systems'],\n",
       "             'dynamical systems': ['dynamical system'],\n",
       "             'embedding': ['embeddings'],\n",
       "             'embeddings': ['embedding'],\n",
       "             'ensemble': ['ensembles'],\n",
       "             'ensembles': ['ensemble'],\n",
       "             'evolutionary algorithm': ['evolutionary algorithms'],\n",
       "             'evolutionary algorithms': ['evolutionary algorithm'],\n",
       "             'extra-gradient': ['extragradient'],\n",
       "             'extragradient': ['extra-gradient'],\n",
       "             'face verification': ['fact verification'],\n",
       "             'fact verification': ['face verification'],\n",
       "             'feature attribution': ['feature attributions'],\n",
       "             'feature attributions': ['feature attribution'],\n",
       "             'few shot': ['few-shot'],\n",
       "             'few shot classification': ['few-shot classification'],\n",
       "             'few shot learning': ['few-shot learning'],\n",
       "             'few-shot': ['few shot'],\n",
       "             'few-shot classification': ['few shot classification'],\n",
       "             'few-shot learning': ['few shot learning'],\n",
       "             'fgsm': ['ifgsm'],\n",
       "             'finite state machine': ['finite state machines'],\n",
       "             'finite state machines': ['finite state machine'],\n",
       "             'first order logic': ['first-order logic'],\n",
       "             'first-order logic': ['first order logic'],\n",
       "             'forward model': ['forward models'],\n",
       "             'forward models': ['forward model'],\n",
       "             'game': ['games'],\n",
       "             'games': ['game'],\n",
       "             'gan': ['gnn'],\n",
       "             'gcn': ['gcnn', 'gnn'],\n",
       "             'gcnn': ['gcn'],\n",
       "             'genearative adversarial network': ['generative adversarial network'],\n",
       "             'generalization bound': ['generalization bounds'],\n",
       "             'generalization bounds': ['generalization bound'],\n",
       "             'generatice models': ['generative models'],\n",
       "             'generative adversarial network': ['genearative adversarial network',\n",
       "              'generative adversarial networks'],\n",
       "             'generative adversarial networks': ['generative adversarial networks.',\n",
       "              'generative adversarial network'],\n",
       "             'generative adversarial networks.': ['generative adversarial networks'],\n",
       "             'generative model': ['generative models'],\n",
       "             'generative modeling': ['generative modelling'],\n",
       "             'generative modelling': ['generative modeling'],\n",
       "             'generative models': ['generatice models', 'generative model'],\n",
       "             'genetic algorithm': ['genetic algorithms'],\n",
       "             'genetic algorithms': ['genetic algorithm'],\n",
       "             'gnn': ['gan', 'gcn'],\n",
       "             'gradient': ['gradients'],\n",
       "             'gradients': ['gradient'],\n",
       "             'graph': ['graphs'],\n",
       "             'graph convolution': ['graph convolutions'],\n",
       "             'graph convolutional network': ['graph convolutional networks'],\n",
       "             'graph convolutional networks': ['graph convolutional network'],\n",
       "             'graph convolutions': ['graph convolution'],\n",
       "             'graph neural network': ['graph neural networks'],\n",
       "             'graph neural networks': ['graph neural network'],\n",
       "             'graphical model': ['graphical models'],\n",
       "             'graphical models': ['graphical model'],\n",
       "             'graphs': ['graph'],\n",
       "             'hierarchical model': ['hierarchical models'],\n",
       "             'hierarchical models': ['hierarchical model'],\n",
       "             'hyperbolic space': ['hyperbolic spaces'],\n",
       "             'hyperbolic spaces': ['hyperbolic space'],\n",
       "             'hypernetwork': ['hypernetworks'],\n",
       "             'hypernetworks': ['hypernetwork'],\n",
       "             'i-fgsm': ['ifgsm'],\n",
       "             'ifgsm': ['i-fgsm', 'fgsm'],\n",
       "             'imitation learning': ['imitation-learning'],\n",
       "             'imitation-learning': ['imitation learning'],\n",
       "             'implicit probabilistic model': ['implicit probabilistic models'],\n",
       "             'implicit probabilistic models': ['implicit probabilistic model'],\n",
       "             'initialisation': ['initialization'],\n",
       "             'initialization': ['initialisation'],\n",
       "             'instruction following': ['instruction-following'],\n",
       "             'instruction-following': ['instruction following'],\n",
       "             'interpolation': ['interpolations'],\n",
       "             'interpolations': ['interpolation'],\n",
       "             'inverse problem': ['inverse problems'],\n",
       "             'inverse problems': ['inverse problem'],\n",
       "             'kernel method': ['kernel methods'],\n",
       "             'kernel methods': ['kernel method'],\n",
       "             'knowledge graph': ['knowledge graphs'],\n",
       "             'knowledge graphs': ['knowledge graph'],\n",
       "             'l1 regularization': ['l2 regularization'],\n",
       "             'l2 regularization': ['l1 regularization'],\n",
       "             'language model': ['langugage model'],\n",
       "             'language modeling': ['language modelling'],\n",
       "             'language modelling': ['language modeling'],\n",
       "             'langugage model': ['language model'],\n",
       "             'large batch training': ['large-batch training'],\n",
       "             'large scale': ['large-scale'],\n",
       "             'large-batch training': ['large batch training'],\n",
       "             'large-scale': ['large scale'],\n",
       "             'latent representation': ['latent representations'],\n",
       "             'latent representations': ['latent representation'],\n",
       "             'latent variable model': ['latent variable models'],\n",
       "             'latent variable modeling': ['latent variable modelling'],\n",
       "             'latent variable modelling': ['latent variable modeling'],\n",
       "             'latent variable models': ['latent variable model'],\n",
       "             'learning from demonstration': ['learning from demonstrations'],\n",
       "             'learning from demonstrations': ['learning from demonstration'],\n",
       "             'learning representation': ['learning representations'],\n",
       "             'learning representations': ['learning representation'],\n",
       "             'life-long learning': ['lifelong learning'],\n",
       "             'lifelong learning': ['life-long learning'],\n",
       "             'logic': ['logics'],\n",
       "             'logics': ['logic'],\n",
       "             'long short term memory': ['long short-term memory'],\n",
       "             'long short-term memory': ['long short term memory'],\n",
       "             'low precision': ['low-precision'],\n",
       "             'low-precision': ['low precision'],\n",
       "             'lstm': ['lstms'],\n",
       "             'lstms': ['lstm'],\n",
       "             'manifold': ['manifolds'],\n",
       "             'manifolds': ['manifold'],\n",
       "             'memory augmented neural networks': ['memory-augmented neural networks'],\n",
       "             'memory network': ['memory networks'],\n",
       "             'memory networks': ['memory network'],\n",
       "             'memory-augmented neural networks': ['memory augmented neural networks'],\n",
       "             'meta learning': ['meta-learning', 'metalearning'],\n",
       "             'meta reinforcement learning': ['meta-reinforcement learning'],\n",
       "             'meta-learning': ['meta learning', 'metalearning'],\n",
       "             'meta-reinforcement learning': ['meta reinforcement learning'],\n",
       "             'metalearning': ['meta learning', 'meta-learning'],\n",
       "             'mini-batch': ['minibatch'],\n",
       "             'minibatch': ['mini-batch'],\n",
       "             'mixture model': ['mixture models'],\n",
       "             'mixture models': ['mixture model'],\n",
       "             'mode collapse': ['mode-collapse'],\n",
       "             'mode-collapse': ['mode collapse'],\n",
       "             'model based reinforcement learning': ['model-based reinforcement learning'],\n",
       "             'model-based reinforcement learning': ['model based reinforcement learning'],\n",
       "             'modular network': ['modular networks'],\n",
       "             'modular networks': ['modular network'],\n",
       "             'multi agent': ['multi-agent', 'multiagent'],\n",
       "             'multi agent reinforcement learning': ['multi-agent reinforcement learning',\n",
       "              'multiagent reinforcement learning'],\n",
       "             'multi task': ['multi-task', 'multitask'],\n",
       "             'multi-agent': ['multiagent', 'multi agent'],\n",
       "             'multi-agent reinforcement learning': ['multiagent reinforcement learning',\n",
       "              'multi agent reinforcement learning'],\n",
       "             'multi-armed bandit': ['multi-armed bandits'],\n",
       "             'multi-armed bandits': ['multi-armed bandit'],\n",
       "             'multi-modal generation': ['multimodal generation'],\n",
       "             'multi-task': ['multitask', 'multi task'],\n",
       "             'multi-task learning': ['multitask learning'],\n",
       "             'multiagent': ['multi-agent', 'multi agent'],\n",
       "             'multiagent reinforcement learning': ['multi-agent reinforcement learning',\n",
       "              'multi agent reinforcement learning'],\n",
       "             'multimodal generation': ['multi-modal generation'],\n",
       "             'multitask': ['multi-task', 'multi task'],\n",
       "             'multitask learning': ['multi-task learning'],\n",
       "             'neural language model': ['neural language models'],\n",
       "             'neural language models': ['neural language model'],\n",
       "             'neural network': ['neural networks'],\n",
       "             'neural networks': ['neural-networks', 'neural network'],\n",
       "             'neural-networks': ['neural networks'],\n",
       "             'node embedding': ['node embeddings'],\n",
       "             'node embeddings': ['node embedding'],\n",
       "             'non convex optimization': ['nonconvex optimization',\n",
       "              'non-convex optimization'],\n",
       "             'non-convex optimization': ['non convex optimization',\n",
       "              'nonconvex optimization'],\n",
       "             'non-negative matrix factorisation': ['non-negative matrix factorization'],\n",
       "             'non-negative matrix factorization': ['non-negative matrix factorisation'],\n",
       "             'nonconvex optimization': ['non convex optimization',\n",
       "              'non-convex optimization'],\n",
       "             'open domain question answering': ['open-domain question answering'],\n",
       "             'open-domain question answering': ['open domain question answering'],\n",
       "             'optimisation': ['optimization'],\n",
       "             'optimization': ['optimisation'],\n",
       "             'over-parameterization': ['overparameterization',\n",
       "              'over-parametrization'],\n",
       "             'over-parametrization': ['over-parameterization'],\n",
       "             'overparameterization': ['over-parameterization'],\n",
       "             'partial differential equation': ['partial differential equations'],\n",
       "             'partial differential equations': ['partial differential equation'],\n",
       "             'permutation invariant': ['permutation-invariant'],\n",
       "             'permutation-invariant': ['permutation invariant'],\n",
       "             'perturbation': ['perturbations'],\n",
       "             'perturbations': ['perturbation'],\n",
       "             'point cloud': ['point clouds'],\n",
       "             'point clouds': ['point cloud'],\n",
       "             'policy gradient': ['policy gradients'],\n",
       "             'policy gradients': ['policy gradient'],\n",
       "             'question answering': ['question-answering'],\n",
       "             'question-answering': ['question answering'],\n",
       "             'real nvp': ['realnvp'],\n",
       "             'realnvp': ['real nvp'],\n",
       "             'recurrent network': ['recurrent networks'],\n",
       "             'recurrent networks': ['recurrent network'],\n",
       "             'recurrent neural network': ['recurrent neural networks'],\n",
       "             'recurrent neural networks': ['recurrent neural network'],\n",
       "             'reinforcement learning': ['reinforcement-learning'],\n",
       "             'reinforcement-learning': ['reinforcement learning'],\n",
       "             'relu': ['relus'],\n",
       "             'relus': ['relu'],\n",
       "             'representation': ['representations'],\n",
       "             'representations': ['representation'],\n",
       "             'rna': ['rnn'],\n",
       "             'rnn': ['rna'],\n",
       "             'robust optimisation': ['robust optimization'],\n",
       "             'robust optimization': ['robust optimisation'],\n",
       "             'rotation': ['rotations'],\n",
       "             'rotations': ['rotation'],\n",
       "             'saliency map': ['saliency maps'],\n",
       "             'saliency maps': ['saliency map'],\n",
       "             'self attention': ['self-attention'],\n",
       "             'self play': ['self-play'],\n",
       "             'self-attention': ['self attention'],\n",
       "             'self-play': ['self play'],\n",
       "             'semantic representation': ['semantic representations'],\n",
       "             'semantic representations': ['semantic representation'],\n",
       "             'semi supervised learning': ['semi-supervised learning'],\n",
       "             'semi-supervised learning': ['semi supervised learning'],\n",
       "             'sentence embedding': ['sentence embeddings'],\n",
       "             'sentence embeddings': ['sentence embedding'],\n",
       "             'sentence representation': ['sentence representations'],\n",
       "             'sentence representations': ['sentence representation'],\n",
       "             'sequence model': ['sequence models'],\n",
       "             'sequence modeling': ['sequence modelling'],\n",
       "             'sequence modelling': ['sequence modeling'],\n",
       "             'sequence models': ['sequence model'],\n",
       "             'set': ['sets'],\n",
       "             'set function': ['set functions'],\n",
       "             'set functions': ['set function'],\n",
       "             'sets': ['set'],\n",
       "             'shapley value': ['shapley values'],\n",
       "             'shapley values': ['shapley value'],\n",
       "             'siamese network': ['siamese networks'],\n",
       "             'siamese networks': ['siamese network'],\n",
       "             'sparse reward': ['sparse rewards'],\n",
       "             'sparse rewards': ['sparse reward'],\n",
       "             'stochastic computation graph': ['stochastic computation graphs'],\n",
       "             'stochastic computation graphs': ['stochastic computation graph'],\n",
       "             'straight-through estimator': ['straight-through-estimator'],\n",
       "             'straight-through-estimator': ['straight-through estimator'],\n",
       "             'structure learning': ['structured learning'],\n",
       "             'structured learning': ['structure learning'],\n",
       "             'structured scene representation': ['structured scene representations'],\n",
       "             'structured scene representations': ['structured scene representation'],\n",
       "             'successor representation': ['successor representations'],\n",
       "             'successor representations': ['successor representation'],\n",
       "             'td learning': ['3d learning'],\n",
       "             'text embedding': ['text embeddings'],\n",
       "             'text embeddings': ['text embedding'],\n",
       "             'transformer': ['transformers'],\n",
       "             'transformers': ['transformer'],\n",
       "             'uncertainty  estimation': ['uncertainty estimation'],\n",
       "             'uncertainty estimation': ['uncertainty  estimation'],\n",
       "             'variational auto encoder': ['variational auto encoders',\n",
       "              'variational auto-encoder',\n",
       "              'variational autoencoder'],\n",
       "             'variational auto encoders': ['variational auto encoder',\n",
       "              'variational auto-encoders',\n",
       "              'variational autoencoders'],\n",
       "             'variational auto-encoder': ['variational auto encoder',\n",
       "              'variational auto-encoders',\n",
       "              'variational autoencoder'],\n",
       "             'variational auto-encoders': ['variational auto encoders',\n",
       "              'variational auto-encoder',\n",
       "              'variational autoencoders'],\n",
       "             'variational autoencoder': ['variational auto encoder',\n",
       "              'variational auto-encoder',\n",
       "              'variational autoencoders'],\n",
       "             'variational autoencoders': ['variational autoencoders.',\n",
       "              'variational auto encoders',\n",
       "              'variational auto-encoders',\n",
       "              'variational autoencoder'],\n",
       "             'variational autoencoders.': ['variational autoencoders'],\n",
       "             'variational inference': ['variational inference.',\n",
       "              'variational lnference'],\n",
       "             'variational inference.': ['variational inference'],\n",
       "             'variational lnference': ['variational inference'],\n",
       "             'variational model': ['variational models'],\n",
       "             'variational models': ['variational model'],\n",
       "             'visual question answering': ['visual questions answering'],\n",
       "             'visual questions answering': ['visual question answering'],\n",
       "             'visualisation': ['visualization'],\n",
       "             'visualization': ['visualisation'],\n",
       "             'wasserstein distance': ['wasserstein distances'],\n",
       "             'wasserstein distances': ['wasserstein distance'],\n",
       "             'wavenet': ['wavnet'],\n",
       "             'wavnet': ['wavenet'],\n",
       "             'weakly supervised learning': ['weakly-supervised learning'],\n",
       "             'weakly-supervised learning': ['weakly supervised learning'],\n",
       "             'word embeddings': ['word-embeddings'],\n",
       "             'word-embeddings': ['word embeddings'],\n",
       "             'zero-short learning': ['zero-shot learning'],\n",
       "             'zero-shot learning': ['zero-short learning']})"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_clusters(matches):\n",
    "    clusters = dict()\n",
    "    for topic in matches:\n",
    "        values = matches[topic]\n",
    "        clusters[topic] = topic\n",
    "        for v in values:\n",
    "            if len(matches.get(v, [])) > len(values) or \\\n",
    "            (len(matches.get(v, [])) == len(values) and topic > v):\n",
    "                clusters[topic] = v\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = get_clusters(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_df(papers, clusters):\n",
    "    rows = []\n",
    "    for paper in papers:\n",
    "        topic = paper.content['keywords'][0] if len(paper.content['keywords']) else ''\n",
    "        cluster = clusters.get(topic.lower(), topic.lower() if topic else None)\n",
    "        row = dict(tldr = paper.content.get('TL;DR', ''),\n",
    "                  ratings = getattr(paper, 'ratings', []),\n",
    "                  confidence = getattr(paper, 'confidence', []),\n",
    "                  title = paper.content['title'],\n",
    "                  avg_rating = np.mean(getattr(paper, 'ratings', [])),\n",
    "                  avg_confidence = np.mean(getattr(paper, 'confidence', [])),\n",
    "                  topic = cluster,\n",
    "                  url = \"https://openreview.net/forum?id=\" + paper.forum\n",
    "                  )\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.index.name = 'Index'\n",
    "    df = df.iloc[:, [4,1,0,6,5,3,2,7]]\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df(papers, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>avg_confidence</th>\n",
       "      <th>topic</th>\n",
       "      <th>tldr</th>\n",
       "      <th>ratings</th>\n",
       "      <th>confidence</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G-SGD: Optimizing ReLU Neural Networks in its ...</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>optimisation</td>\n",
       "      <td></td>\n",
       "      <td>[7, 7, 6]</td>\n",
       "      <td>[2, 3, 4]</td>\n",
       "      <td>https://openreview.net/forum?id=SyxfEn09Y7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADef: an Iterative Algorithm to Construct Adve...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>adversarial example</td>\n",
       "      <td>We propose a new, efficient algorithm to const...</td>\n",
       "      <td>[7, 7, 4]</td>\n",
       "      <td>[4, 3, 3]</td>\n",
       "      <td>https://openreview.net/forum?id=Hk4dFjR5K7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generative Code Modeling with Graphs</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>generative models</td>\n",
       "      <td>Representing programs as graphs including sema...</td>\n",
       "      <td>[7, 7, 5]</td>\n",
       "      <td>[4, 4, 5]</td>\n",
       "      <td>https://openreview.net/forum?id=Bke4KsA5FX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quality Evaluation of GANs Using Cross Local I...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>generative adversarial network</td>\n",
       "      <td>We propose a new metric for evaluating GAN mod...</td>\n",
       "      <td>[4, 6, 5]</td>\n",
       "      <td>[3, 4, 5]</td>\n",
       "      <td>https://openreview.net/forum?id=BJgYl205tQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L-Shapley and C-Shapley: Efficient Model Inter...</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>model interpretation</td>\n",
       "      <td>We develop two linear-complexity algorithms fo...</td>\n",
       "      <td>[7, 7, 5]</td>\n",
       "      <td>[3, 2, 4]</td>\n",
       "      <td>https://openreview.net/forum?id=S1E3Ko09F7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  avg_rating  \\\n",
       "Index                                                                  \n",
       "0      G-SGD: Optimizing ReLU Neural Networks in its ...    6.666667   \n",
       "1      ADef: an Iterative Algorithm to Construct Adve...    6.000000   \n",
       "2                   Generative Code Modeling with Graphs    6.333333   \n",
       "3      Quality Evaluation of GANs Using Cross Local I...    5.000000   \n",
       "4      L-Shapley and C-Shapley: Efficient Model Inter...    6.333333   \n",
       "\n",
       "       avg_confidence                           topic  \\\n",
       "Index                                                   \n",
       "0            3.000000                    optimisation   \n",
       "1            3.333333             adversarial example   \n",
       "2            4.333333               generative models   \n",
       "3            4.000000  generative adversarial network   \n",
       "4            3.000000            model interpretation   \n",
       "\n",
       "                                                    tldr    ratings  \\\n",
       "Index                                                                 \n",
       "0                                                         [7, 7, 6]   \n",
       "1      We propose a new, efficient algorithm to const...  [7, 7, 4]   \n",
       "2      Representing programs as graphs including sema...  [7, 7, 5]   \n",
       "3      We propose a new metric for evaluating GAN mod...  [4, 6, 5]   \n",
       "4      We develop two linear-complexity algorithms fo...  [7, 7, 5]   \n",
       "\n",
       "      confidence                                         url  \n",
       "Index                                                         \n",
       "0      [2, 3, 4]  https://openreview.net/forum?id=SyxfEn09Y7  \n",
       "1      [4, 3, 3]  https://openreview.net/forum?id=Hk4dFjR5K7  \n",
       "2      [4, 4, 5]  https://openreview.net/forum?id=Bke4KsA5FX  \n",
       "3      [3, 4, 5]  https://openreview.net/forum?id=BJgYl205tQ  \n",
       "4      [3, 2, 4]  https://openreview.net/forum?id=S1E3Ko09F7  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "show_grid() got an unexpected keyword argument 'export_mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-213-6ef28b81ab2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mcol_defs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'topic'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'width'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mgrid_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'forceFitColumns'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'defaultColumnWidth'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mqgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_definitions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol_defs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: show_grid() got an unexpected keyword argument 'export_mode'"
     ]
    }
   ],
   "source": [
    "col_defs = {\n",
    "    name: {\n",
    "        'width': 50\n",
    "    } for name in ['Index', 'confidence', 'ratings']\n",
    "}\n",
    "col_defs['title'] = {'width': 500}\n",
    "col_defs['avg_rating'] = {'width': 100}\n",
    "col_defs['tldr'] = {'width': 1000}\n",
    "col_defs['url'] = {'width': 300}\n",
    "col_defs['topic'] = {'width': 200}\n",
    "grid_options={'forceFitColumns': False, 'defaultColumnWidth': 100}\n",
    "qgrid.show_grid(df, column_definitions=col_defs, grid_options = grid_options, precision=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "?qgrid.show_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-convex optimization ['non convex optimization', 'nonconvex optimization']\n",
      "multi-agent reinforcement learning ['multiagent reinforcement learning', 'multi agent reinforcement learning']\n",
      "variational inference ['variational inference.', 'variational lnference']\n",
      "multiagent reinforcement learning ['multi-agent reinforcement learning', 'multi agent reinforcement learning']\n",
      "multiagent ['multi agent', 'multi-agent']\n",
      "neural networks ['neural network', 'neural-networks']\n",
      "autoencoders ['autoencoder', 'auto-encoders']\n",
      "over-parameterization ['overparameterization', 'over-parametrization']\n",
      "variational auto encoder ['variational autoencoder', 'variational auto encoders', 'variational auto-encoder']\n",
      "generative adversarial networks ['generative adversarial network', 'generative adversarial networks.']\n",
      "generative models ['generatice models', 'generative model']\n",
      "variational autoencoder ['variational auto encoder', 'variational auto-encoder', 'variational autoencoders']\n",
      "deep-learning ['deep learning', 'deeplearning']\n",
      "non convex optimization ['non-convex optimization', 'nonconvex optimization']\n",
      "variational auto encoders ['variational auto encoder', 'variational auto-encoders', 'variational autoencoders']\n",
      "multi agent ['multiagent', 'multi-agent']\n",
      "deep learning ['deep-learning', 'deeplearning']\n",
      "meta learning ['meta-learning', 'metalearning']\n",
      "generative adversarial network ['genearative adversarial network', 'generative adversarial networks']\n",
      "deep neural networks ['deep neural network', 'deep neural networks.']\n",
      "meta-learning ['meta learning', 'metalearning']\n",
      "nonconvex optimization ['non-convex optimization', 'non convex optimization']\n",
      "multi-task ['multitask', 'multi task']\n",
      "variational auto-encoder ['variational auto encoder', 'variational autoencoder', 'variational auto-encoders']\n",
      "variational auto-encoders ['variational auto encoders', 'variational auto-encoder', 'variational autoencoders']\n",
      "multitask ['multi-task', 'multi task']\n",
      "multi-agent ['multiagent', 'multi agent']\n",
      "multi task ['multi-task', 'multitask']\n",
      "gnn ['gan', 'gcn']\n",
      "deeplearning ['deep-learning', 'deep learning']\n",
      "metalearning ['meta learning', 'meta-learning']\n",
      "ifgsm ['i-fgsm', 'fgsm']\n",
      "variational autoencoders ['variational autoencoders.', 'variational autoencoder', 'variational auto encoders', 'variational auto-encoders']\n",
      "multi agent reinforcement learning ['multi-agent reinforcement learning', 'multiagent reinforcement learning']\n"
     ]
    }
   ],
   "source": [
    "for topic in top:\n",
    "    if len(top[topic]) > 1:\n",
    "        print(topic, top[topic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-convex optimization', 'nonconvex optimization']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top['non convex optimization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['3d learning', 'td learning'],\n",
       " ['3d learning', 'td learning'],\n",
       " ['activation function', 'activation functions'],\n",
       " ['activation function', 'activation functions'],\n",
       " ['active  learning', 'active learning'],\n",
       " ['active  learning', 'active learning'],\n",
       " ['adam', 'admm'],\n",
       " ['adam', 'admm'],\n",
       " ['adaptive method', 'adaptive methods'],\n",
       " ['adaptive method', 'adaptive methods'],\n",
       " ['adversarial attack', 'adversarial attacks'],\n",
       " ['adversarial attack', 'adversarial attacks'],\n",
       " ['adversarial defence', 'adversarial defense'],\n",
       " ['adversarial defence', 'adversarial defense'],\n",
       " ['adversarial example', 'adversarial examples'],\n",
       " ['adversarial example', 'adversarial examples'],\n",
       " ['adversarial perturbation', 'adversarial perturbations'],\n",
       " ['adversarial perturbation', 'adversarial perturbations'],\n",
       " ['algorithm', 'algorithms'],\n",
       " ['algorithm', 'algorithms'],\n",
       " ['amortised inference', 'amortized inference'],\n",
       " ['amortised inference', 'amortized inference'],\n",
       " ['artificial neural network', 'artificial neural networks'],\n",
       " ['artificial neural network', 'artificial neural networks'],\n",
       " ['attention model', 'attention models'],\n",
       " ['attention model', 'attention models'],\n",
       " ['auto-encoders', 'autoencoders'],\n",
       " ['auto-encoders', 'autoencoders'],\n",
       " ['autodl', 'automl'],\n",
       " ['autodl', 'automl'],\n",
       " ['autoencoder', 'autoencoders'],\n",
       " ['autoencoder', 'autoencoders'],\n",
       " ['autoregressive model', 'autoregressive models'],\n",
       " ['autoregressive model', 'autoregressive models'],\n",
       " ['back-propagation', 'backpropagation'],\n",
       " ['back-propagation', 'backpropagation'],\n",
       " ['bayesian neural network', 'bayesian neural networks'],\n",
       " ['bayesian neural network', 'bayesian neural networks'],\n",
       " ['bayesian nonparametric', 'bayesian nonparametrics'],\n",
       " ['bayesian nonparametric', 'bayesian nonparametrics'],\n",
       " ['bias-variance trade-off', 'bias-variance tradeoff'],\n",
       " ['bias-variance trade-off', 'bias-variance tradeoff'],\n",
       " ['binary neural network', 'binary neural networks'],\n",
       " ['binary neural network', 'binary neural networks'],\n",
       " ['black box', 'black-box'],\n",
       " ['black box', 'black-box'],\n",
       " ['black box optimization', 'blackbox optimization'],\n",
       " ['black box optimization', 'blackbox optimization'],\n",
       " ['black-box attack', 'black-box attacks'],\n",
       " ['black-box attack', 'black-box attacks'],\n",
       " ['capsule network', 'capsule networks'],\n",
       " ['capsule network', 'capsule networks'],\n",
       " ['catastrophic forgetting', 'catatrophic forgetting'],\n",
       " ['catastrophic forgetting', 'catatrophic forgetting'],\n",
       " ['compositionality', 'compostionality'],\n",
       " ['compositionality', 'compostionality'],\n",
       " ['conditional gan', 'conditional gans'],\n",
       " ['conditional gan', 'conditional gans'],\n",
       " ['conditional generative model', 'conditional generative models'],\n",
       " ['conditional generative model', 'conditional generative models'],\n",
       " ['continuous relaxation', 'continuous relaxations'],\n",
       " ['continuous relaxation', 'continuous relaxations'],\n",
       " ['convolution', 'convolutions'],\n",
       " ['convolution', 'convolutions'],\n",
       " ['convolutional network', 'convolutional networks'],\n",
       " ['convolutional network', 'convolutional networks'],\n",
       " ['convolutional neural network', 'convolutional neural networks'],\n",
       " ['convolutional neural network', 'convolutional neural networks'],\n",
       " ['cross entropy', 'cross-entropy'],\n",
       " ['cross entropy', 'cross-entropy'],\n",
       " ['decision tree', 'decision trees'],\n",
       " ['decision tree', 'decision trees'],\n",
       " ['deep generative model', 'deep generative models'],\n",
       " ['deep generative model', 'deep generative models'],\n",
       " ['deep learning', 'deep-learning'],\n",
       " ['deep learning', 'deep-learning'],\n",
       " ['deep learning', 'deeplearning'],\n",
       " ['deep learning', 'deeplearning'],\n",
       " ['deep network', 'deep networks'],\n",
       " ['deep network', 'deep networks'],\n",
       " ['deep neural network', 'deep neural networks'],\n",
       " ['deep neural network', 'deep neural networks'],\n",
       " ['deep neural networks', 'deep neural networks.'],\n",
       " ['deep neural networks', 'deep neural networks.'],\n",
       " ['deep rl', 'deeprl'],\n",
       " ['deep rl', 'deeprl'],\n",
       " ['deep-learning', 'deeplearning'],\n",
       " ['deep-learning', 'deeplearning'],\n",
       " ['defence', 'defense'],\n",
       " ['defence', 'defense'],\n",
       " ['denoising', 'denosing'],\n",
       " ['denoising', 'denosing'],\n",
       " ['differential equation', 'differential equations'],\n",
       " ['differential equation', 'differential equations'],\n",
       " ['discrete latent variable', 'discrete latent variables'],\n",
       " ['discrete latent variable', 'discrete latent variables'],\n",
       " ['disentangled representation', 'disentangled representations'],\n",
       " ['disentangled representation', 'disentangled representations'],\n",
       " ['dynamic network', 'dynamic networks'],\n",
       " ['dynamic network', 'dynamic networks'],\n",
       " ['dynamical system', 'dynamical systems'],\n",
       " ['dynamical system', 'dynamical systems'],\n",
       " ['embedding', 'embeddings'],\n",
       " ['embedding', 'embeddings'],\n",
       " ['ensemble', 'ensembles'],\n",
       " ['ensemble', 'ensembles'],\n",
       " ['evolutionary algorithm', 'evolutionary algorithms'],\n",
       " ['evolutionary algorithm', 'evolutionary algorithms'],\n",
       " ['extra-gradient', 'extragradient'],\n",
       " ['extra-gradient', 'extragradient'],\n",
       " ['face verification', 'fact verification'],\n",
       " ['face verification', 'fact verification'],\n",
       " ['feature attribution', 'feature attributions'],\n",
       " ['feature attribution', 'feature attributions'],\n",
       " ['few shot', 'few-shot'],\n",
       " ['few shot', 'few-shot'],\n",
       " ['few shot classification', 'few-shot classification'],\n",
       " ['few shot classification', 'few-shot classification'],\n",
       " ['few shot learning', 'few-shot learning'],\n",
       " ['few shot learning', 'few-shot learning'],\n",
       " ['fgsm', 'ifgsm'],\n",
       " ['fgsm', 'ifgsm'],\n",
       " ['finite state machine', 'finite state machines'],\n",
       " ['finite state machine', 'finite state machines'],\n",
       " ['first order logic', 'first-order logic'],\n",
       " ['first order logic', 'first-order logic'],\n",
       " ['forward model', 'forward models'],\n",
       " ['forward model', 'forward models'],\n",
       " ['game', 'games'],\n",
       " ['game', 'games'],\n",
       " ['gan', 'gnn'],\n",
       " ['gcn', 'gcnn'],\n",
       " ['gcn', 'gcnn'],\n",
       " ['gcn', 'gnn'],\n",
       " ['genearative adversarial network', 'generative adversarial network'],\n",
       " ['genearative adversarial network', 'generative adversarial network'],\n",
       " ['generalization bound', 'generalization bounds'],\n",
       " ['generalization bound', 'generalization bounds'],\n",
       " ['generatice models', 'generative models'],\n",
       " ['generatice models', 'generative models'],\n",
       " ['generative adversarial network', 'generative adversarial networks'],\n",
       " ['generative adversarial network', 'generative adversarial networks'],\n",
       " ['generative adversarial networks', 'generative adversarial networks.'],\n",
       " ['generative adversarial networks', 'generative adversarial networks.'],\n",
       " ['generative model', 'generative models'],\n",
       " ['generative model', 'generative models'],\n",
       " ['generative modeling', 'generative modelling'],\n",
       " ['generative modeling', 'generative modelling'],\n",
       " ['genetic algorithm', 'genetic algorithms'],\n",
       " ['genetic algorithm', 'genetic algorithms'],\n",
       " ['gradient', 'gradients'],\n",
       " ['gradient', 'gradients'],\n",
       " ['graph', 'graphs'],\n",
       " ['graph', 'graphs'],\n",
       " ['graph convolution', 'graph convolutions'],\n",
       " ['graph convolution', 'graph convolutions'],\n",
       " ['graph convolutional network', 'graph convolutional networks'],\n",
       " ['graph convolutional network', 'graph convolutional networks'],\n",
       " ['graph neural network', 'graph neural networks'],\n",
       " ['graph neural network', 'graph neural networks'],\n",
       " ['graphical model', 'graphical models'],\n",
       " ['graphical model', 'graphical models'],\n",
       " ['hierarchical model', 'hierarchical models'],\n",
       " ['hierarchical model', 'hierarchical models'],\n",
       " ['hyperbolic space', 'hyperbolic spaces'],\n",
       " ['hyperbolic space', 'hyperbolic spaces'],\n",
       " ['hypernetwork', 'hypernetworks'],\n",
       " ['hypernetwork', 'hypernetworks'],\n",
       " ['i-fgsm', 'ifgsm'],\n",
       " ['i-fgsm', 'ifgsm'],\n",
       " ['imitation learning', 'imitation-learning'],\n",
       " ['imitation learning', 'imitation-learning'],\n",
       " ['implicit probabilistic model', 'implicit probabilistic models'],\n",
       " ['implicit probabilistic model', 'implicit probabilistic models'],\n",
       " ['initialisation', 'initialization'],\n",
       " ['initialisation', 'initialization'],\n",
       " ['instruction following', 'instruction-following'],\n",
       " ['interpolation', 'interpolations'],\n",
       " ['interpolation', 'interpolations'],\n",
       " ['inverse problem', 'inverse problems'],\n",
       " ['inverse problem', 'inverse problems'],\n",
       " ['kernel method', 'kernel methods'],\n",
       " ['kernel method', 'kernel methods'],\n",
       " ['knowledge graph', 'knowledge graphs'],\n",
       " ['knowledge graph', 'knowledge graphs'],\n",
       " ['l1 regularization', 'l2 regularization'],\n",
       " ['l1 regularization', 'l2 regularization'],\n",
       " ['language model', 'langugage model'],\n",
       " ['language model', 'langugage model'],\n",
       " ['language modeling', 'language modelling'],\n",
       " ['language modeling', 'language modelling'],\n",
       " ['large batch training', 'large-batch training'],\n",
       " ['large batch training', 'large-batch training'],\n",
       " ['large scale', 'large-scale'],\n",
       " ['large scale', 'large-scale'],\n",
       " ['latent representation', 'latent representations'],\n",
       " ['latent representation', 'latent representations'],\n",
       " ['latent variable model', 'latent variable models'],\n",
       " ['latent variable model', 'latent variable models'],\n",
       " ['latent variable modeling', 'latent variable modelling'],\n",
       " ['latent variable modeling', 'latent variable modelling'],\n",
       " ['learning from demonstration', 'learning from demonstrations'],\n",
       " ['learning from demonstration', 'learning from demonstrations'],\n",
       " ['learning representation', 'learning representations'],\n",
       " ['learning representation', 'learning representations'],\n",
       " ['life-long learning', 'lifelong learning'],\n",
       " ['life-long learning', 'lifelong learning'],\n",
       " ['logic', 'logics'],\n",
       " ['logic', 'logics'],\n",
       " ['long short term memory', 'long short-term memory'],\n",
       " ['long short term memory', 'long short-term memory'],\n",
       " ['low precision', 'low-precision'],\n",
       " ['low precision', 'low-precision'],\n",
       " ['lstm', 'lstms'],\n",
       " ['lstm', 'lstms'],\n",
       " ['manifold', 'manifolds'],\n",
       " ['manifold', 'manifolds'],\n",
       " ['memory augmented neural networks', 'memory-augmented neural networks'],\n",
       " ['memory augmented neural networks', 'memory-augmented neural networks'],\n",
       " ['memory network', 'memory networks'],\n",
       " ['memory network', 'memory networks'],\n",
       " ['meta learning', 'meta-learning'],\n",
       " ['meta learning', 'meta-learning'],\n",
       " ['meta learning', 'metalearning'],\n",
       " ['meta learning', 'metalearning'],\n",
       " ['meta reinforcement learning', 'meta-reinforcement learning'],\n",
       " ['meta reinforcement learning', 'meta-reinforcement learning'],\n",
       " ['meta-learning', 'metalearning'],\n",
       " ['meta-learning', 'metalearning'],\n",
       " ['mini-batch', 'minibatch'],\n",
       " ['mini-batch', 'minibatch'],\n",
       " ['mixture model', 'mixture models'],\n",
       " ['mixture model', 'mixture models'],\n",
       " ['mode collapse', 'mode-collapse'],\n",
       " ['mode collapse', 'mode-collapse'],\n",
       " ['model based reinforcement learning', 'model-based reinforcement learning'],\n",
       " ['model based reinforcement learning', 'model-based reinforcement learning'],\n",
       " ['modular network', 'modular networks'],\n",
       " ['modular network', 'modular networks'],\n",
       " ['multi agent', 'multi-agent'],\n",
       " ['multi agent', 'multi-agent'],\n",
       " ['multi agent', 'multiagent'],\n",
       " ['multi agent', 'multiagent'],\n",
       " ['multi agent reinforcement learning', 'multi-agent reinforcement learning'],\n",
       " ['multi agent reinforcement learning', 'multi-agent reinforcement learning'],\n",
       " ['multi agent reinforcement learning', 'multiagent reinforcement learning'],\n",
       " ['multi agent reinforcement learning', 'multiagent reinforcement learning'],\n",
       " ['multi task', 'multi-task'],\n",
       " ['multi task', 'multi-task'],\n",
       " ['multi task', 'multitask'],\n",
       " ['multi task', 'multitask'],\n",
       " ['multi-agent', 'multiagent'],\n",
       " ['multi-agent', 'multiagent'],\n",
       " ['multi-agent reinforcement learning', 'multiagent reinforcement learning'],\n",
       " ['multi-agent reinforcement learning', 'multiagent reinforcement learning'],\n",
       " ['multi-armed bandit', 'multi-armed bandits'],\n",
       " ['multi-armed bandit', 'multi-armed bandits'],\n",
       " ['multi-modal generation', 'multimodal generation'],\n",
       " ['multi-modal generation', 'multimodal generation'],\n",
       " ['multi-task', 'multitask'],\n",
       " ['multi-task', 'multitask'],\n",
       " ['multi-task learning', 'multitask learning'],\n",
       " ['multi-task learning', 'multitask learning'],\n",
       " ['neural language model', 'neural language models'],\n",
       " ['neural language model', 'neural language models'],\n",
       " ['neural network', 'neural networks'],\n",
       " ['neural network', 'neural networks'],\n",
       " ['neural networks', 'neural-networks'],\n",
       " ['neural networks', 'neural-networks'],\n",
       " ['node embedding', 'node embeddings'],\n",
       " ['node embedding', 'node embeddings'],\n",
       " ['non convex optimization', 'non-convex optimization'],\n",
       " ['non convex optimization', 'non-convex optimization'],\n",
       " ['non convex optimization', 'nonconvex optimization'],\n",
       " ['non convex optimization', 'nonconvex optimization'],\n",
       " ['non-convex optimization', 'nonconvex optimization'],\n",
       " ['non-convex optimization', 'nonconvex optimization'],\n",
       " ['non-negative matrix factorisation', 'non-negative matrix factorization'],\n",
       " ['non-negative matrix factorisation', 'non-negative matrix factorization'],\n",
       " ['open domain question answering', 'open-domain question answering'],\n",
       " ['open domain question answering', 'open-domain question answering'],\n",
       " ['optimisation', 'optimization'],\n",
       " ['optimisation', 'optimization'],\n",
       " ['over-parameterization', 'over-parametrization'],\n",
       " ['over-parameterization', 'over-parametrization'],\n",
       " ['over-parameterization', 'overparameterization'],\n",
       " ['over-parameterization', 'overparameterization'],\n",
       " ['partial differential equation', 'partial differential equations'],\n",
       " ['partial differential equation', 'partial differential equations'],\n",
       " ['permutation invariant', 'permutation-invariant'],\n",
       " ['permutation invariant', 'permutation-invariant'],\n",
       " ['perturbation', 'perturbations'],\n",
       " ['perturbation', 'perturbations'],\n",
       " ['point cloud', 'point clouds'],\n",
       " ['point cloud', 'point clouds'],\n",
       " ['policy gradient', 'policy gradients'],\n",
       " ['policy gradient', 'policy gradients'],\n",
       " ['question answering', 'question-answering'],\n",
       " ['question answering', 'question-answering'],\n",
       " ['real nvp', 'realnvp'],\n",
       " ['real nvp', 'realnvp'],\n",
       " ['recurrent network', 'recurrent networks'],\n",
       " ['recurrent network', 'recurrent networks'],\n",
       " ['recurrent neural network', 'recurrent neural networks'],\n",
       " ['recurrent neural network', 'recurrent neural networks'],\n",
       " ['reinforcement learning', 'reinforcement-learning'],\n",
       " ['reinforcement learning', 'reinforcement-learning'],\n",
       " ['relu', 'relus'],\n",
       " ['relu', 'relus'],\n",
       " ['representation', 'representations'],\n",
       " ['representation', 'representations'],\n",
       " ['rna', 'rnn'],\n",
       " ['robust optimisation', 'robust optimization'],\n",
       " ['robust optimisation', 'robust optimization'],\n",
       " ['rotation', 'rotations'],\n",
       " ['rotation', 'rotations'],\n",
       " ['saliency map', 'saliency maps'],\n",
       " ['saliency map', 'saliency maps'],\n",
       " ['self attention', 'self-attention'],\n",
       " ['self attention', 'self-attention'],\n",
       " ['self play', 'self-play'],\n",
       " ['self play', 'self-play'],\n",
       " ['semantic representation', 'semantic representations'],\n",
       " ['semantic representation', 'semantic representations'],\n",
       " ['semi supervised learning', 'semi-supervised learning'],\n",
       " ['semi supervised learning', 'semi-supervised learning'],\n",
       " ['sentence embedding', 'sentence embeddings'],\n",
       " ['sentence embedding', 'sentence embeddings'],\n",
       " ['sentence representation', 'sentence representations'],\n",
       " ['sentence representation', 'sentence representations'],\n",
       " ['sequence model', 'sequence models'],\n",
       " ['sequence model', 'sequence models'],\n",
       " ['sequence modeling', 'sequence modelling'],\n",
       " ['sequence modeling', 'sequence modelling'],\n",
       " ['set', 'sets'],\n",
       " ['set', 'sets'],\n",
       " ['set function', 'set functions'],\n",
       " ['set function', 'set functions'],\n",
       " ['shapley value', 'shapley values'],\n",
       " ['shapley value', 'shapley values'],\n",
       " ['siamese network', 'siamese networks'],\n",
       " ['siamese network', 'siamese networks'],\n",
       " ['sparse reward', 'sparse rewards'],\n",
       " ['sparse reward', 'sparse rewards'],\n",
       " ['stochastic computation graph', 'stochastic computation graphs'],\n",
       " ['stochastic computation graph', 'stochastic computation graphs'],\n",
       " ['straight-through estimator', 'straight-through-estimator'],\n",
       " ['straight-through estimator', 'straight-through-estimator'],\n",
       " ['structure learning', 'structured learning'],\n",
       " ['structure learning', 'structured learning'],\n",
       " ['structured scene representation', 'structured scene representations'],\n",
       " ['structured scene representation', 'structured scene representations'],\n",
       " ['successor representation', 'successor representations'],\n",
       " ['successor representation', 'successor representations'],\n",
       " ['text embedding', 'text embeddings'],\n",
       " ['text embedding', 'text embeddings'],\n",
       " ['transformer', 'transformers'],\n",
       " ['transformer', 'transformers'],\n",
       " ['uncertainty  estimation', 'uncertainty estimation'],\n",
       " ['uncertainty  estimation', 'uncertainty estimation'],\n",
       " ['variational auto encoder', 'variational auto encoders'],\n",
       " ['variational auto encoder', 'variational auto encoders'],\n",
       " ['variational auto encoder', 'variational auto-encoder'],\n",
       " ['variational auto encoder', 'variational auto-encoder'],\n",
       " ['variational auto encoder', 'variational autoencoder'],\n",
       " ['variational auto encoder', 'variational autoencoder'],\n",
       " ['variational auto encoders', 'variational auto-encoders'],\n",
       " ['variational auto encoders', 'variational auto-encoders'],\n",
       " ['variational auto encoders', 'variational autoencoders'],\n",
       " ['variational auto encoders', 'variational autoencoders'],\n",
       " ['variational auto-encoder', 'variational auto-encoders'],\n",
       " ['variational auto-encoder', 'variational auto-encoders'],\n",
       " ['variational auto-encoder', 'variational autoencoder'],\n",
       " ['variational auto-encoder', 'variational autoencoder'],\n",
       " ['variational auto-encoders', 'variational autoencoders'],\n",
       " ['variational auto-encoders', 'variational autoencoders'],\n",
       " ['variational autoencoder', 'variational autoencoders'],\n",
       " ['variational autoencoder', 'variational autoencoders'],\n",
       " ['variational autoencoders', 'variational autoencoders.'],\n",
       " ['variational autoencoders', 'variational autoencoders.'],\n",
       " ['variational inference', 'variational inference.'],\n",
       " ['variational inference', 'variational inference.'],\n",
       " ['variational inference', 'variational lnference'],\n",
       " ['variational inference', 'variational lnference'],\n",
       " ['variational model', 'variational models'],\n",
       " ['variational model', 'variational models'],\n",
       " ['visual question answering', 'visual questions answering'],\n",
       " ['visual question answering', 'visual questions answering'],\n",
       " ['visualisation', 'visualization'],\n",
       " ['visualisation', 'visualization'],\n",
       " ['wasserstein distance', 'wasserstein distances'],\n",
       " ['wasserstein distance', 'wasserstein distances'],\n",
       " ['wavenet', 'wavnet'],\n",
       " ['wavenet', 'wavnet'],\n",
       " ['weakly supervised learning', 'weakly-supervised learning'],\n",
       " ['weakly supervised learning', 'weakly-supervised learning'],\n",
       " ['word embeddings', 'word-embeddings'],\n",
       " ['word embeddings', 'word-embeddings'],\n",
       " ['zero-short learning', 'zero-shot learning'],\n",
       " ['zero-short learning', 'zero-shot learning']]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = []\n",
    "for pair in sim:\n",
    "    if sim[pair] == 1:\n",
    "        l.append(sorted(pair))\n",
    "sorted(l)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((\"nesterov's method\", \"liapunov's method\"), 6)\n",
      "((\"nesterov's method\", 'variational models'), 15)\n",
      "((\"nesterov's method\", 'smoothed gradient'), 16)\n",
      "((\"nesterov's method\", 'generative models'), 13)\n",
      "((\"nesterov's method\", 'recommender systems'), 16)\n",
      "((\"nesterov's method\", 'adversarial methods'), 11)\n",
      "((\"nesterov's method\", 'kernel methods'), 9)\n",
      "(('state equation', 'data selection'), 7)\n",
      "(('state equation', 'set reconstruction'), 10)\n",
      "(('state equation', 'regression tree'), 13)\n",
      "(('state equation', 'sequence to sequence'), 15)\n"
     ]
    }
   ],
   "source": [
    "ix = 0 \n",
    "for item in sim.items():\n",
    "    print(item)\n",
    "    ix += 1\n",
    "    if ix > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cdate': 1538087978124,\n",
      " 'content': {'_bibtex': '@inproceedings{    \\n'\n",
      "                        'anonymous2019g-sgd:,    \\n'\n",
      "                        'title={G-SGD: Optimizing ReLU Neural Networks in its '\n",
      "                        'Positively Scale-Invariant Space},    \\n'\n",
      "                        'author={Anonymous},    \\n'\n",
      "                        'booktitle={Submitted to International Conference on '\n",
      "                        'Learning Representations},    \\n'\n",
      "                        'year={2019},    \\n'\n",
      "                        'url={https://openreview.net/forum?id=SyxfEn09Y7},    \\n'\n",
      "                        'note={under review}    \\n'\n",
      "                        '}',\n",
      "             'abstract': 'It is well known that neural networks with rectified '\n",
      "                         'linear units (ReLU) activation functions are '\n",
      "                         'positively scale-invariant. Conventional algorithms '\n",
      "                         'like stochastic gradient descent optimize the neural '\n",
      "                         'networks in the vector space of weights, which is, '\n",
      "                         'however, not positively scale-invariant. This '\n",
      "                         'mismatch may lead to problems during the '\n",
      "                         'optimization process. Then, a natural question is: '\n",
      "                         '\\\\emph{can we construct a new vector space that is '\n",
      "                         'positively scale-invariant and sufficient to '\n",
      "                         'represent ReLU neural networks so as to better '\n",
      "                         'facilitate the optimization process }? In this '\n",
      "                         'paper, we provide our positive answer to this '\n",
      "                         'question. First, we conduct a formal study on the '\n",
      "                         'positive scaling operators which forms a '\n",
      "                         'transformation group, denoted as $\\\\mathcal{G}$. We '\n",
      "                         'prove that the value of a path (i.e. the product of '\n",
      "                         'the weights along the path) in the neural network is '\n",
      "                         'invariant to positive scaling and the value vector '\n",
      "                         'of all the paths is sufficient to represent the '\n",
      "                         'neural networks under mild conditions. Second, we '\n",
      "                         'show that one can identify some basis paths out of '\n",
      "                         'all the paths and prove that the linear span of '\n",
      "                         'their value vectors (denoted as '\n",
      "                         '$\\\\mathcal{G}$-space) is an invariant space with '\n",
      "                         'lower dimension under the positive scaling group. '\n",
      "                         'Finally, we design stochastic gradient descent '\n",
      "                         'algorithm in $\\\\mathcal{G}$-space (abbreviated as '\n",
      "                         '$\\\\mathcal{G}$-SGD) to optimize the value vector of '\n",
      "                         'the basis paths of neural networks with little extra '\n",
      "                         'cost by leveraging back-propagation. Our experiments '\n",
      "                         'show that $\\\\mathcal{G}$-SGD significantly '\n",
      "                         'outperforms the conventional SGD algorithm in '\n",
      "                         'optimizing ReLU networks on benchmark datasets. ',\n",
      "             'authorids': ['ICLR.cc/2019/Conference/Paper1431/Authors'],\n",
      "             'authors': ['Anonymous'],\n",
      "             'keywords': ['optimization',\n",
      "                          'neural network',\n",
      "                          'irreducible positively scale-invariant space',\n",
      "                          'deep learning'],\n",
      "             'paperhash': 'anonymous|gsgd_optimizing_relu_neural_networks_in_its_positively_scaleinvariant_space',\n",
      "             'pdf': '/pdf/0c16bf3f6705cdad3918614136e9b3c8c85144f5.pdf',\n",
      "             'title': 'G-SGD: Optimizing ReLU Neural Networks in its '\n",
      "                      'Positively Scale-Invariant Space'},\n",
      " 'ddate': None,\n",
      " 'details': {'replyCount': 9},\n",
      " 'forum': 'SyxfEn09Y7',\n",
      " 'id': 'SyxfEn09Y7',\n",
      " 'invitation': 'ICLR.cc/2019/Conference/-/Blind_Submission',\n",
      " 'nonreaders': [],\n",
      " 'number': 1431,\n",
      " 'original': 'BklLeyEROQ',\n",
      " 'readers': ['everyone'],\n",
      " 'referent': None,\n",
      " 'replyto': None,\n",
      " 'signatures': ['ICLR.cc/2019/Conference'],\n",
      " 'tcdate': 1538087978124,\n",
      " 'tmdate': 1542287962892,\n",
      " 'writers': ['ICLR.cc/2019/Conference']}\n"
     ]
    }
   ],
   "source": [
    "pprint(papers[0].to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid.show_grid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings, confidence = ratings_and_confidence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1565, 1565)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings), len(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BklpOo09tQ', ['5', '6', '7'])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ratings.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = c.get_notes(invitation=\"ICLR.cc/2019/Conference/-/Paper.*/Public_Comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paper=  c.get_notes(forum=\"SyVU6s05K7\")\n",
    "ratings_and_confidence(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for n in notes:\n",
    "    print(n.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = add_ratings(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(c.get_notes(id='SyVU6s05K7')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "print(c.get_notes(id='r1g2QHW0h7')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('cro.features') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpl = []\n",
    "for split in text.split('|'):\n",
    "    if '101536' in split :\n",
    "        rpl.append(split.replace('101536', '-104356'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|1&-104356|100070&-104356|100128&-104356|100132&-104356|100145&-104356|100146&-104356|100164&-104356|100258&-104356|100259&-104356|100260&-104356|100282&-104356|100780&-104356|100783&-104356|100928&-104356|100929&-104356|100930&-104356|100931&-104356|100932&-104356|100933&-104356|100934&-104356|100935&-104356|100936&-104356|100937&-104356|100938&-104356|100939&-104356|100975&-104356|101131&-104356|101399&-104356|17&-104356|-104356&23|-104356&31|-104356&34|-104356&415|-104356&417|-104356&418|-104356&491|-104356&523|-104356&529|-104356&530|-104356&598|-104356&86|'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'|'+ '|'.join(rpl[:-1]) + '|'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
