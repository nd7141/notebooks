{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "import openreview\n",
    "import gensim\n",
    "import nltk\n",
    "from collections import Counter, defaultdict as dd\n",
    "import numpy as np\n",
    "from pivottablejs import pivot_ui\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import qgrid\n",
    "from pprint import pprint\n",
    "import re \n",
    "import jellyfish\n",
    "import time\n",
    "\n",
    "from plotly.offline import init_notebook_mode\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = openreview.Client(baseurl='https://openreview.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notes = c.get_notes(invitation='ICLR.cc/2019/Conference/-/Blind_Submission') + \\\n",
    "    c.get_notes(invitation='ICLR.cc/2019/Conference/-/Blind_Submission', offset=1000, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "note = notes[0]\n",
    "jsnote = note.to_json()\n",
    "jsnote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = c.get_notes(forum=\"H1lqZhRcFm\")\n",
    "refs = c.get_references(referent=\"H1lqZhRcFm\")\n",
    "refs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict as dd\n",
    "import re \n",
    "def ratings_and_confidence(notes):\n",
    "    ratings = []\n",
    "    confs = []\n",
    "    for note in notes:\n",
    "        content = note.to_json()['content']\n",
    "        paper = note.to_json()['forum']\n",
    "        if 'rating' in content:\n",
    "            score = int(re.findall(pattern='\\d+', string=content['rating'])[0])\n",
    "            conf = int(re.findall(pattern='\\d+', string=content['confidence'])[0])\n",
    "            ratings.append(score)\n",
    "            confs.append(conf)\n",
    "    return ratings, confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paper_notes = c.get_notes(invitation='ICLR.cc/2019/Conference/-/Blind_Submission') + \\\n",
    "    c.get_notes(invitation='ICLR.cc/2019/Conference/-/Blind_Submission', offset=1000, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paper_notes2 = c.get_notes(invitation='ICLR.cc/2019/Conference/-/Blind_Submission') + \\\n",
    "    c.get_notes(invitation='ICLR.cc/2019/Conference/-/Blind_Submission', offset=1000, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint \n",
    "\n",
    "for ix in range(len(paper_notes)):\n",
    "    print(ix)\n",
    "    forumId = paper_notes[ix].forum\n",
    "    forum_notes = c.get_notes(forum=forumId)\n",
    "    ratings, confidence = ratings_and_confidence(forum_notes)\n",
    "    paper_notes[ix].ratings = ratings\n",
    "    paper_notes[ix].confidence = confidence\n",
    "#     if ix > 10:\n",
    "#         break\n",
    "\n",
    "with open('papers2019_icml.pcl', 'wb+') as f:\n",
    "    pickle.dump(paper_notes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('papers2019_icml.pcl', 'rb+') as f:\n",
    "    paper_notes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_of_ratings(paper_notes):\n",
    "    num_ratings = []\n",
    "    for paper in paper_notes:\n",
    "        num_ratings.append(len(paper.ratings))\n",
    "    return Counter(num_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_ratings(paper_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_rating(paper_notes, field='ratings'):\n",
    "    ratings = []\n",
    "    for paper in paper_notes:\n",
    "        ratings.extend(paper.__getattribute__(field))\n",
    "    return np.mean(ratings), Counter(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_rating(paper_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_rating(paper_notes, 'confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "ratings = []\n",
    "confidence = []\n",
    "for paper in paper_notes:\n",
    "    ratings.extend(paper.__getattribute__('ratings'))\n",
    "    confidence.extend(paper.__getattribute__('confidence'))\n",
    "    \n",
    "# pearsonr(ratings, confidence)\n",
    "len(ratings), len(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "copy = paper_notes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = paper_notes[0]\n",
    "getattr(p, 'confidence', '')\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for paper in paper_notes:\n",
    "    row = dict(tldr = paper.content.get('TL;DR', ''),\n",
    "              ratings = getattr(paper, 'ratings', []),\n",
    "              confidence = getattr(paper, 'confidence', []),\n",
    "              title = paper.content['title'],\n",
    "              avg_rating = np.mean(getattr(paper, 'ratings', [])),\n",
    "              avg_confidence = np.mean(getattr(paper, 'confidence', [])))\n",
    "    rows.append(row)\n",
    "df = pd.DataFrame(rows)\n",
    "df.index.name = 'Index'\n",
    "df = df.iloc[:, [4,1,0,5,3,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>avg_confidence</th>\n",
       "      <th>tldr</th>\n",
       "      <th>ratings</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State-Regularized Recurrent Networks</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.</td>\n",
       "      <td>[6, 6, 5]</td>\n",
       "      <td>[4, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.</td>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>[3, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Deep Weight Prior</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.</td>\n",
       "      <td>[4, 8, 7]</td>\n",
       "      <td>[4, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CoT: Cooperative Training for Generative Modeling of Discrete Data</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.</td>\n",
       "      <td>[7, 7, 7]</td>\n",
       "      <td>[2, 2, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adversarial Information Factorization</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>Learn representations for images that factor out a single attribute.</td>\n",
       "      <td>[6, 6, 6]</td>\n",
       "      <td>[4, 4, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               title  avg_rating  avg_confidence                                                                                                                                                                                                                                tldr    ratings confidence\n",
       "Index                                                                                                                                                                                                                                                                                                                                                                     \n",
       "0      State-Regularized Recurrent Networks                                           5.666667    4.666667        We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.  [6, 6, 5]  [4, 5, 5]\n",
       "1      Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior  5.666667    3.333333        By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.                                            [6, 5, 6]  [3, 3, 4]\n",
       "2      The Deep Weight Prior                                                          6.333333    3.666667        An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.                                                                                                                   [4, 8, 7]  [4, 4, 3]\n",
       "3      CoT: Cooperative Training for Generative Modeling of Discrete Data             7.000000    2.666667        We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.                                                                                                                              [7, 7, 7]  [2, 2, 4]\n",
       "4      Adversarial Information Factorization                                          6.000000    4.000000        Learn representations for images that factor out a single attribute.                                                                                                                                                                [6, 6, 6]  [4, 4, 4]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pivot_ui(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>ratings</th>\n",
       "      <th>title</th>\n",
       "      <th>tldr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4, 5, 5]</td>\n",
       "      <td>[6, 6, 5]</td>\n",
       "      <td>State-Regularized Recurrent Networks</td>\n",
       "      <td>We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3, 3, 4]</td>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior</td>\n",
       "      <td>By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4, 4, 3]</td>\n",
       "      <td>[4, 8, 7]</td>\n",
       "      <td>The Deep Weight Prior</td>\n",
       "      <td>An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2, 2, 4]</td>\n",
       "      <td>[7, 7, 7]</td>\n",
       "      <td>CoT: Cooperative Training for Generative Modeling of Discrete Data</td>\n",
       "      <td>We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4, 4, 4]</td>\n",
       "      <td>[6, 6, 6]</td>\n",
       "      <td>Adversarial Information Factorization</td>\n",
       "      <td>Learn representations for images that factor out a single attribute.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  confidence    ratings                                                                          title                                                                                                                                                                                                                                tldr\n",
       "0  [4, 5, 5]  [6, 6, 5]  State-Regularized Recurrent Networks                                           We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\n",
       "1  [3, 3, 4]  [6, 5, 6]  Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior  By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.                                          \n",
       "2  [4, 4, 3]  [4, 8, 7]  The Deep Weight Prior                                                          An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.                                                                                                                 \n",
       "3  [2, 2, 4]  [7, 7, 7]  CoT: Cooperative Training for Generative Modeling of Discrete Data             We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.                                                                                                                            \n",
       "4  [4, 4, 4]  [6, 6, 6]  Adversarial Information Factorization                                          Learn representations for images that factor out a single attribute.                                                                                                                                                              "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_options = {\n",
    "            'fullWidthRows': True,\n",
    "            'syncColumnCellResize': True,\n",
    "            'forceFitColumns': True,\n",
    "            'defaultColumnWidth': 150,\n",
    "            'rowHeight': 28,\n",
    "            'enableColumnReorder': False,\n",
    "            'enableTextSelectionOnCells': True,\n",
    "            'editable': True,\n",
    "            'autoEdit': False,\n",
    "            'explicitInitialization': True,\n",
    "            'maxVisibleRows': 15,\n",
    "            'minVisibleRows': 8\n",
    "        }\n",
    "# grid_options = {\n",
    "#     'rowHeight': 50\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = dict(title= 'CoT: Cooperative Training for Generative Modeling of Discrete Data',\n",
    "tldr= 'We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data. We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.')\n",
    "df = pd.DataFrame([row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_confidence</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>confidence</th>\n",
       "      <th>ratings</th>\n",
       "      <th>title</th>\n",
       "      <th>tldr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>[4, 5, 5]</td>\n",
       "      <td>[6, 6, 5]</td>\n",
       "      <td>State-Regularized Recurrent Networks</td>\n",
       "      <td>We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.333333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>[3, 3, 4]</td>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior</td>\n",
       "      <td>By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>[4, 4, 3]</td>\n",
       "      <td>[4, 8, 7]</td>\n",
       "      <td>The Deep Weight Prior</td>\n",
       "      <td>An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>[2, 2, 4]</td>\n",
       "      <td>[7, 7, 7]</td>\n",
       "      <td>CoT: Cooperative Training for Generative Modeling of Discrete Data</td>\n",
       "      <td>We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>[4, 4, 4]</td>\n",
       "      <td>[6, 6, 6]</td>\n",
       "      <td>Adversarial Information Factorization</td>\n",
       "      <td>Learn representations for images that factor out a single attribute.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_confidence  avg_rating confidence    ratings                                                                          title                                                                                                                                                                                                                                tldr\n",
       "Index                                                                                                                                                                                                                                                                                                                                                                     \n",
       "0      4.666667        5.666667    [4, 5, 5]  [6, 6, 5]  State-Regularized Recurrent Networks                                           We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\n",
       "1      3.333333        5.666667    [3, 3, 4]  [6, 5, 6]  Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior  By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.                                          \n",
       "2      3.666667        6.333333    [4, 4, 3]  [4, 8, 7]  The Deep Weight Prior                                                          An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.                                                                                                                 \n",
       "3      2.666667        7.000000    [2, 2, 4]  [7, 7, 7]  CoT: Cooperative Training for Generative Modeling of Discrete Data             We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.                                                                                                                            \n",
       "4      4.000000        6.000000    [4, 4, 4]  [6, 6, 6]  Adversarial Information Factorization                                          Learn representations for images that factor out a single attribute.                                                                                                                                                              "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cedb93d128d4b5d89ccd05edbbd875c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# col_opts = { \n",
    "#     'editable': False,\n",
    "#     'toolTip': \"Not editable\"\n",
    "# }\n",
    "\n",
    "col_defs = {\n",
    "    name: {\n",
    "        'width': 50\n",
    "    } for name in ['Index', 'avg_confidence', 'avg_rating', 'confidence', 'ratings']\n",
    "}\n",
    "qgrid.show_grid(df, column_definitions=col_defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint(paper_notes[0].to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = openreview.Client(baseurl='https://openreview.net')\n",
    "# notes = c.get_notes(limit = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cdate': 1542286428411,\n",
      " 'content': {'confidence': '4: The reviewer is confident but not absolutely '\n",
      "                           'certain that the evaluation is correct',\n",
      "             'rating': '5: Marginally below acceptance threshold',\n",
      "             'review': 'Summary. The authors propose a novel adversarial '\n",
      "                       'training method, e2SAD, that relies on a two-step '\n",
      "                       'process for generating sets of two training '\n",
      "                       'adversarial samples for each clean training sample. '\n",
      "                       'The first step is a classical FGSM that yields the '\n",
      "                       'first adversarial sample. The second adversarial '\n",
      "                       'sample is calculated with a FGSM that is based on the '\n",
      "                       'cross-entropy between the probabilities generated by '\n",
      "                       'the first adversarial sample and the probabilities '\n",
      "                       'generated by the second adversarial sample. The method '\n",
      "                       'is computationally efficient (two forward/backward '\n",
      "                       'passes per clean sample) w.r.t. powerful iterative '\n",
      "                       'attacks such as IFGSM or PGD requiring 40+ steps and '\n",
      "                       'the authors claim it gives comparable results to '\n",
      "                       'adversarial training with multi-step attacks methods '\n",
      "                       'in white and black-box settings.\\n'\n",
      "                       '\\n'\n",
      "                       'Clarity. Part 1 and 2 of the paper are well written '\n",
      "                       'and summarize the existing attacks/defense mechanisms, '\n",
      "                       'their pros and cons as well as the contributions '\n",
      "                       'clearly. The next sections could be made shorter (see '\n",
      "                       'comments below) to match ICLR’s recommended soft limit '\n",
      "                       'of 8 pages instead of the 10 pages hard limit. This '\n",
      "                       'would also help the reader grasp the key ideas faster '\n",
      "                       'and have a standard formatting (no negative spaces for '\n",
      "                       'instance).\\n'\n",
      "                       '\\n'\n",
      "                       'Novelty. The idea of simulating the effect of '\n",
      "                       'iterative attacks using two distinct steps is novel '\n",
      "                       'and appealing to me. The first step increases the loss '\n",
      "                       'while the second step shifts the probability '\n",
      "                       'distributions apart.\\n'\n",
      "                       '\\n'\n",
      "                       'Pros and cons.\\n'\n",
      "                       '(+) The paper is clear and easy to follow, although a '\n",
      "                       'bit long.\\n'\n",
      "                       '(+) The idea is interesting and clearly motivated in '\n",
      "                       'terms of computational efficiency and in terms of '\n",
      "                       'desired properties (Figure 2 illustrates this point '\n",
      "                       'well).\\n'\n",
      "                       '\\n'\n",
      "                       '(-) Only one aspect of the idea is exploited in the '\n",
      "                       'article. It would be interesting to compare this '\n",
      "                       'method as an attacker (both in terms of performance '\n",
      "                       'and in terms of generated samples, see comment below). '\n",
      "                       'Powerful adversarial training should indeed rely on '\n",
      "                       'powerful generated adversarial samples.\\n'\n",
      "                       '(-) The results seem somewhat mitigated in terms of '\n",
      "                       'significance and conclusions drawn by the authors. '\n",
      "                       'Also, the experimental setup is quite light, notably '\n",
      "                       'the used CNN architectures are quite small and other '\n",
      "                       'datasets could have been used (also linked to the '\n",
      "                       'significance of the results).\\n'\n",
      "                       '\\n'\n",
      "                       'Comments.\\n'\n",
      "                       '- Shorter paper. Here are suggested modifications for '\n",
      "                       'the paper that could help strengthen the impact of '\n",
      "                       'your paper. Section 3.1 could be almost entirely '\n",
      "                       'discarded as it brings no new ideas w.r.t sections 1 '\n",
      "                       'and 2. Figure 1 summarizes the method well, thus the '\n",
      "                       'description in Section 3.2 could be made shorter, '\n",
      "                       'especially when displaying Equation (8) right after '\n",
      "                       'Figure 1. This would then help reduce the size of '\n",
      "                       'Sections 3.2.1 and 3.2.2 (because Equation (8) and '\n",
      "                       'Figure 1 would prevent you from repeating claims made '\n",
      "                       'earlier in the paper). Algorithm 1 is straightforward '\n",
      "                       'and could be placed in Appendix. Conclusion and Result '\n",
      "                       'sections could be shortened a little as well (not as '\n",
      "                       'much as Section 3 though).\\n'\n",
      "                       '\\n'\n",
      "                       '- Significance of the results. The significance of '\n",
      "                       'some results is unclear to me. Could the authors '\n",
      "                       'provide the standard deviation over 3 or 5 runs? For '\n",
      "                       'example, in rows 1, 3, 4, 5, 6 of Table 2, it is not '\n",
      "                       'clear it e2SAD performs better than FGSM adversarial '\n",
      "                       'training, thus raising the question of the necessity '\n",
      "                       'of Step 2 of the attack (which is the core '\n",
      "                       'contribution of the paper).\\n'\n",
      "                       '\\n'\n",
      "                       '- Experimental setup. The last two rows of Table 1 are '\n",
      "                       'encouraging for e2SAD. However, the authors could '\n",
      "                       'introduce another dataset, e.g. CIFAR10 or 100 or even '\n",
      "                       'ImageNet restricted to 20 or 100 random classes/with '\n",
      "                       'fewer samples per class and use deeper modern CNN '\n",
      "                       'architectures like ResNets (even a ResNet18). Those '\n",
      "                       'models are widely adopted both in the research '\n",
      "                       'community and by the industry, thus defense mechanisms '\n",
      "                       'that provably work for such models can have a huge '\n",
      "                       'impact.\\n'\n",
      "                       '\\n'\n",
      "                       '- Defense setup. Is the order of Steps 1 and 2 '\n",
      "                       'relevant? What if the authors use only iterations of '\n",
      "                       'Step 2?\\n'\n",
      "                       '\\n'\n",
      "                       '- Attack setup. Here are a few suggestions for '\n",
      "                       'assessing your method in an attack setting: what is '\n",
      "                       'the precision of the network, without any defense, '\n",
      "                       'given an average dissimilarity L2 budget in the '\n",
      "                       'training/test samples, in a white/black box setting? '\n",
      "                       'How does it compare to standard techniques (e.g. FGSM, '\n",
      "                       'IFGSM, DeepFool, Carlini)? What happens if the authors '\n",
      "                       'use their method both for both defense and attack? '\n",
      "                       'Could the authors display adversarial samples '\n",
      "                       'generated by their method?\\n'\n",
      "                       '\\n'\n",
      "                       'Conclusion. The idea presented in the paper is '\n",
      "                       'interesting, but (1) the experimental results are not '\n",
      "                       'entirely satisfactory for the moment and (2) only one '\n",
      "                       'aspect of the idea is exploited in the paper, which '\n",
      "                       'can be made more interesting and impactful while '\n",
      "                       'studying both attack and defense setups. I strongly '\n",
      "                       'encourage the authors to continue their research in '\n",
      "                       'this area due to the high potential impact and '\n",
      "                       'benefits for the whole community.',\n",
      "             'title': 'Interesting research direction but needs more thorough '\n",
      "                      'experiments'},\n",
      " 'ddate': None,\n",
      " 'details': {'replyCount': 0},\n",
      " 'forum': 'BklpOo09tQ',\n",
      " 'id': 'ByeVD2kjam',\n",
      " 'invitation': 'ICLR.cc/2019/Conference/-/Paper398/Official_Review',\n",
      " 'nonreaders': [],\n",
      " 'number': 3,\n",
      " 'original': None,\n",
      " 'readers': ['everyone'],\n",
      " 'referent': None,\n",
      " 'replyto': 'BklpOo09tQ',\n",
      " 'signatures': ['ICLR.cc/2019/Conference/Paper398/AnonReviewer4'],\n",
      " 'tcdate': 1542286428411,\n",
      " 'tmdate': 1542286428411,\n",
      " 'writers': ['ICLR.cc/2019/Conference']}\n"
     ]
    }
   ],
   "source": [
    "review_iterator = openreview.tools.iterget_notes(client, invitation='ICLR.cc/2019/Conference/-/Paper.*/Official_Review')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Note(id = 'HJf7ts0cFm',original = 'B1l3kE55KQ',number = 431,cdate = 1538087803027,tcdate = 1538087803027,tmdate = 1542208692666,ddate = None,content = {'title': 'State-Regularized Recurrent Networks', 'abstract': \"Recurrent networks are a widely used class of neural architectures.  They have, however, two shortcomings. First, it is difficult to understand what exactly they learn. Second, they tend to work poorly on sequences requiring long-term memorization, despite having this capacity in principle. We aim to address both shortcomings with a class of recurrent networks that use a stochastic state transition mechanism between cell applications. This mechanism, which we term state-regularization, makes RNNs transition between a finite set of learnable states. We show that state-regularization (a) simplifies the extraction of finite state automata modeling an RNN's state transition dynamics, and (b) forces RNNs to operate more like automata with external memory and less like finite state machines.\", 'keywords': ['recurrent network', 'finite state machines', 'state-regularized', 'interpretability and explainability'], 'authorids': ['ICLR.cc/2019/Conference/Paper431/Authors'], 'authors': ['Anonymous'], 'TL;DR': 'We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.', 'pdf': '/pdf/b9076c54d2f1f0b845a2ae7198b0781826bddabd.pdf', 'paperhash': 'anonymous|stateregularized_recurrent_networks', '_bibtex': '@inproceedings{    \\nanonymous2019state-regularized,    \\ntitle={State-Regularized Recurrent Networks},    \\nauthor={Anonymous},    \\nbooktitle={Submitted to International Conference on Learning Representations},    \\nyear={2019},    \\nurl={https://openreview.net/forum?id=HJf7ts0cFm},    \\nnote={under review}    \\n}'},forum = 'HJf7ts0cFm',referent = None,invitation = 'ICLR.cc/2019/Conference/-/Blind_Submission',replyto = None,readers = ['everyone'],nonreaders = [],signatures = ['ICLR.cc/2019/Conference'],writers = ['ICLR.cc/2019/Conference'],details = {'replyCount': 6},ratings = [6, 6, 5],confidence = [4, 5, 5])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_notes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratings_and_confidence():\n",
    "    client = openreview.Client(baseurl='https://openreview.net')\n",
    "    review_iterator = openreview.tools.iterget_notes(client, invitation='ICLR.cc/2019/Conference/-/Paper.*/Official_Review')\n",
    "    ratings = dd(list)\n",
    "    confidence = dd(list)\n",
    "    for review in review_iterator:\n",
    "        ratings[review.forum].append(int(re.findall(pattern='\\d+', string=review.content['rating'])[0]))\n",
    "        confidence[review.forum].append(int(re.findall(pattern='\\d+', string=review.content['confidence'])[0]))\n",
    "    return ratings, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_papers():\n",
    "    client = openreview.Client(baseurl='https://openreview.net')\n",
    "    paper_iterator = openreview.tools.iterget_notes(client, invitation='ICLR.cc/2019/Conference/-/Blind_Submission')\n",
    "    return list(paper_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings, confidence = ratings_and_confidence()\n",
    "papers = all_papers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_ratings(papers, ratings, confidence):\n",
    "    for ix in range(len(papers)):\n",
    "        forum = papers[ix].forum\n",
    "        papers[ix].ratings = ratings.get(forum, [])\n",
    "        papers[ix].confidence = confidence.get(forum, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_ratings(papers, ratings, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(papers):\n",
    "    return list(set([word.strip().lower() for p in papers for word in p.content['keywords']]))\n",
    "\n",
    "def get_similarity(keywords):\n",
    "    sim = dict()\n",
    "    N = len(keywords)\n",
    "    for i in range(N-1):\n",
    "        for j in range(i+1, N):\n",
    "            topic1 = keywords[i]\n",
    "            topic2 = keywords[j]\n",
    "            dist = len(set(topic1).intersection(set(topic2)))/len(set(max([topic1, topic2], key=lambda v: len(v))))\n",
    "            if topic1 != topic2 and dist > 0.75:\n",
    "                dist = jellyfish.levenshtein_distance(topic1, topic2)\n",
    "                sim[topic1, topic2] = dist\n",
    "    return sim\n",
    "\n",
    "def get_top_matches(sim):\n",
    "    matches = dd(list)\n",
    "    for pair in sim:\n",
    "        if sim[pair] == 1:\n",
    "            matches[pair[0]].append(pair[1])\n",
    "            matches[pair[1]].append(pair[0])\n",
    "    return matches    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity computed in 118.28 sec\n"
     ]
    }
   ],
   "source": [
    "keywords = get_keywords(papers)\n",
    "start = time.time()\n",
    "sim = get_similarity(keywords) # this takes about 2 minutes \n",
    "finish = time.time()\n",
    "print('Similarity computed in {:.2f} sec'.format(finish - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('active learning', 'active  learning'), 1),\n",
      " (('active learning', 'machine learning'), 3),\n",
      " (('active tracking', 'active learning'), 4),\n",
      " (('active learning', 'code learning'), 4),\n",
      " (('active learning', 'inductive learning'), 4),\n",
      " (('feature learning', 'active learning'), 5),\n",
      " (('active learning', 'td learning'), 5),\n",
      " (('active learning', 'predictive learning'), 5),\n",
      " (('active learning', 'set learning'), 5),\n",
      " (('active learning', 'meta learning'), 5),\n",
      " (('active learning', 'metric learning'), 5),\n",
      " (('hebbian learning', 'active learning'), 6),\n",
      " (('active learning', 'robust learning'), 6),\n",
      " (('active learning', 'concept learning'), 6),\n",
      " (('active learning', 'structure learning'), 6),\n",
      " (('active learning', 'spectral learning'), 6),\n",
      " (('active learning', 'tactile sensing'), 6),\n",
      " (('active learning', 'relation learning'), 6),\n",
      " (('active learning', 'generative learning'), 6),\n",
      " (('active learning', 'stream learning'), 6),\n",
      " (('active learning', 'distance learning'), 6),\n",
      " (('active learning', 'continual learning'), 7),\n",
      " (('active learning', 'transfer learning'), 7),\n",
      " (('active learning', 'imitation learning'), 7),\n",
      " (('active learning', 'dictionary learning'), 7),\n",
      " (('active learning', 'structured learning'), 7),\n",
      " (('continuous learning', 'active learning'), 8),\n",
      " (('active learning', 'rule list learning'), 8),\n",
      " (('active learning', 'introspective learning'), 8),\n",
      " (('active learning', 'federated learning'), 8),\n",
      " (('active learning', 'active perception'), 8),\n",
      " (('active learning', 'lifelong learning'), 8),\n",
      " (('active learning', 'architecture learning'), 8),\n",
      " (('active learning', 'expectation learning'), 8),\n",
      " (('active learning', 'stable training'), 8),\n",
      " (('active learning', 'relational learning'), 8),\n",
      " (('active learning', 'geometric learning'), 8),\n",
      " (('preference learning', 'active learning'), 9),\n",
      " (('active learning', 'latent-tree-learning'), 9),\n",
      " (('active learning', 'adversarial learning'), 9),\n",
      " (('active learning', 'large-scale learning'), 9),\n",
      " (('active learning', 'incremental learning'), 9),\n",
      " (('active learning', 'multiscale rnn'), 9),\n",
      " (('active learning', 'curriculum learning'), 9),\n",
      " (('active learning', 'channel charting'), 9),\n",
      " (('active learning', 'channel pruning'), 9),\n",
      " (('active learning', 'semantic training'), 9),\n",
      " (('active learning', 'filter training'), 9),\n",
      " (('action recognition', 'active learning'), 10),\n",
      " (('active learning', 'asset pricing'), 10),\n",
      " (('active learning', 'apprenticeship learning'), 10),\n",
      " (('active learning', 'variable naming'), 10),\n",
      " (('active learning', 'feature pooling'), 10),\n",
      " (('active learning', 'cost-sensitive learning'), 10),\n",
      " (('neural causal learning', 'active learning'), 11),\n",
      " (('active learning', 'generative modeling'), 11),\n",
      " (('active learning', 'negative transfer'), 11),\n",
      " (('active learning', 'weight averaging'), 11),\n",
      " (('active learning', 'incremental parsing'), 11),\n",
      " (('active learning', 'distance kernel'), 11),\n",
      " (('active learning', 'fact verification'), 11),\n",
      " (('active learning', 'activity recognition'), 11),\n",
      " (('active learning', 'efficient deep learning'), 11),\n",
      " (('active learning', 'relational reasoning'), 11),\n",
      " (('active learning', 'scene generation'), 11),\n",
      " (('active learning', 'scale invariance'), 11),\n",
      " (('active learning', 'noise covariance'), 11),\n",
      " (('natural language', 'active learning'), 12),\n",
      " (('incremental training', 'active learning'), 12),\n",
      " (('large scale training', 'active learning'), 12),\n",
      " (('selective inference', 'active learning'), 12),\n",
      " (('learning rate', 'active learning'), 12),\n",
      " (('scaling rules', 'active learning'), 12),\n",
      " (('active learning', 'reinforcement learning'), 12),\n",
      " (('active learning', 'deictic reference'), 12),\n",
      " (('active learning', 'value iteration'), 12),\n",
      " (('active learning', 'evaluation metric'), 12),\n",
      " (('active learning', 'adversarial training'), 12),\n",
      " (('active learning', 'generative modelling'), 12),\n",
      " (('active learning', 'value function'), 12),\n",
      " (('active learning', 'distance metric learning'), 12),\n",
      " (('active learning', 'trail detection'), 12),\n",
      " (('active learning', 'learning to rank'), 12),\n",
      " (('active learning', 'language drift'), 12),\n",
      " (('active learning', 'image retrieval'), 12),\n",
      " (('active learning', 'face recognition'), 12),\n",
      " (('active learning', 'adversarial net'), 12),\n",
      " (('active learning', 'behavioral cloning'), 12),\n",
      " (('active learning', 'cognitive science'), 12),\n",
      " (('active learning', 'feature engineering'), 12),\n",
      " (('active learning', 'video generation'), 12),\n",
      " (('active learning', 'policy transfer'), 12),\n",
      " (('active learning', 'natural gradient'), 12),\n",
      " (('active learning', 'relative prediction'), 12),\n",
      " (('active learning', 'convergence time'), 12),\n",
      " (('active learning', 'image generation'), 12),\n",
      " (('active learning', 'agent evaluation'), 12),\n",
      " (('active learning', 'early terminating'), 12),\n",
      " (('active learning', 'learning to learn'), 12),\n",
      " (('active learning', 'face verification'), 12),\n",
      " (('learning-to-learn', 'active learning'), 13),\n",
      " (('learning to plan', 'active learning'), 13),\n",
      " (('differential training', 'active learning'), 13),\n",
      " (('large batch training', 'active learning'), 13),\n",
      " (('active learning', 'gradient descent'), 13),\n",
      " (('active learning', 'learning theory'), 13),\n",
      " (('active learning', 'temporal logic'), 13),\n",
      " (('active learning', 'teaching to teach'), 13),\n",
      " (('active learning', 'language generation'), 13),\n",
      " (('active learning', 'generative agents'), 13),\n",
      " (('active learning', 'learning curves'), 13),\n",
      " (('active learning', 'pattern recognition'), 13),\n",
      " (('active learning', 'animal recognition'), 13),\n",
      " (('active learning', 'relu activation'), 13),\n",
      " (('active learning', 'faster inference'), 13),\n",
      " (('active learning', 'navigation agent'), 13),\n",
      " (('active learning', 'variable selection'), 13),\n",
      " (('active learning', 'iterative neural training'), 13),\n",
      " (('active learning', 'word alignment'), 13),\n",
      " (('active learning', 'neural attention'), 13),\n",
      " (('active learning', 'latent variables'), 13),\n",
      " (('active learning', 'large-batch training'), 13),\n",
      " (('active learning', 'multilingual nmt'), 13),\n",
      " (('active learning', 'graph alignment'), 13),\n",
      " (('active learning', 'image recognition'), 13),\n",
      " (('active learning', 'data aggregation'), 13),\n",
      " (('active learning', 'materials science'), 13),\n",
      " (('active learning', 'learning to drive'), 13),\n",
      " (('active learning', 'neural listeners'), 13),\n",
      " (('active learning', 'genetic algorithm'), 13),\n",
      " (('wasserstein gan', 'active learning'), 14),\n",
      " (('active learning', 'relation extraction'), 14),\n",
      " (('active learning', 'variational encoder'), 14),\n",
      " (('active learning', 'riemannian transe'), 14),\n",
      " (('active learning', 'generative model'), 14),\n",
      " (('active learning', 'conditional gradient'), 14),\n",
      " (('active learning', 'gradient staleness'), 14),\n",
      " (('active learning', 'variation inference'), 14),\n",
      " (('active learning', 'revenue management'), 14),\n",
      " (('active learning', 'cyclic adversarial learning'), 14),\n",
      " (('active learning', 'energy efficiency'), 14),\n",
      " (('active learning', 'label correction'), 14),\n",
      " (('active learning', 'invariant feature learning'), 14),\n",
      " (('active learning', 'evolving algorithm'), 14),\n",
      " (('active learning', 'language recognition'), 14),\n",
      " (('active learning', 'singular values'), 14),\n",
      " (('active learning', 'training criteria'), 14),\n",
      " (('active learning', 'tensor ring nets'), 14),\n",
      " (('active learning', 'label correlation'), 14),\n",
      " (('active variable selection', 'active learning'), 15),\n",
      " (('target propagation', 'active learning'), 15),\n",
      " (('regression tree', 'active learning'), 15),\n",
      " (('active learning', 'improving retrieval'), 15),\n",
      " (('active learning', 'referential language'), 15),\n",
      " (('active learning', 'evaluation criteria'), 15),\n",
      " (('active learning', 'efficient inference'), 15),\n",
      " (('active learning', 'learning to execute'), 15),\n",
      " (('active learning', 'neural turing machine'), 15),\n",
      " (('active learning', 'meta reinforcement learning'), 15),\n",
      " (('active learning', 'learning rate decay'), 15),\n",
      " (('active learning', 'abstaining classifier'), 15),\n",
      " (('active learning', 'evolution strategies'), 15),\n",
      " (('active learning', 'variational lnference'), 15),\n",
      " (('active learning', 'hierarchical clustering'), 15),\n",
      " (('active learning', 'conditioned generation'), 15),\n",
      " (('active learning', 'sensitivity analysis'), 15),\n",
      " (('active learning', 'video action recognition'), 16),\n",
      " (('active learning', 'latent space engineering'), 16),\n",
      " (('active learning', 'conversational agent'), 16),\n",
      " (('active learning', 'adaptive gradient descent'), 16),\n",
      " (('active learning', 'variational inference'), 16),\n",
      " (('active learning', 'gradient acceleration'), 16),\n",
      " (('active learning', 'variational inference.'), 16),\n",
      " (('active learning', 'formal verification'), 16),\n",
      " (('active learning', 'new learning criterion'), 16),\n",
      " (('active learning', 'statistical inference'), 16),\n",
      " (('active learning', 'convergence analysis'), 16),\n",
      " (('active learning', 'translation control'), 16),\n",
      " (('adversarial instances', 'active learning'), 17),\n",
      " (('artificial intelligence', 'active learning'), 17),\n",
      " (('active learning', 'gradient equivalence'), 17),\n",
      " (('active learning', 'learning rate restarts'), 17),\n",
      " (('active learning', 'translational invariance'), 17),\n",
      " (('active learning', 'generalization error'), 17),\n",
      " (('active learning', 'discrete latent variable'), 17),\n",
      " (('active learning', 'variational autoencoder'), 17),\n",
      " (('adversarial divergences', 'active learning'), 18),\n",
      " (('active learning', 'discrete latent variables'), 18),\n",
      " (('active learning', 'variational auto encoder'), 18),\n",
      " (('active learning', 'generative adversarial nets'), 18),\n",
      " (('active learning', 'statistical relational learning'), 18),\n",
      " (('active learning', 'generative adversarial learning'), 18),\n",
      " (('active learning', 'training data selection'), 18),\n",
      " (('active learning', 'generative adversarial training'), 19),\n",
      " (('active learning', 'neural activation function'), 19),\n",
      " (('active learning', 'natural scene statistics'), 19),\n",
      " (('active learning', 'statistical characteristics'), 20),\n",
      " (('active learning', 'natural language inference'), 20),\n",
      " (('active learning', 'convergence rate analysis'), 20),\n",
      " (('active learning', 'large variations resistance'), 21),\n",
      " (('active learning', 'conditional image generation'), 21),\n",
      " (('active learning', 'sentence representations learning'), 21),\n",
      " (('active learning', 'natural language generation'), 21),\n",
      " (('controllable text generation', 'active learning'), 22),\n",
      " (('active learning', 'conditional generative model'), 22),\n",
      " (('active learning', 'controllable image generation'), 22),\n",
      " (('active learning', 'functional variational inference'), 23),\n",
      " (('active learning', 'hierarchical neural architecture'), 24),\n",
      " (('conditional variational autoencoder', 'active learning'), 28),\n",
      " (('active learning', 'reduction on convolution calculation'), 29)]\n"
     ]
    }
   ],
   "source": [
    "keys = []\n",
    "for key in sim:\n",
    "    if 'active learning' in key:\n",
    "        keys.append(key)\n",
    "pprint(sorted([(key, sim[key]) for key in keys], key=lambda v: v[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = get_top_matches(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'3d learning': ['td learning'],\n",
       "             'activation function': ['activation functions'],\n",
       "             'activation functions': ['activation function'],\n",
       "             'active  learning': ['active learning'],\n",
       "             'active learning': ['active  learning'],\n",
       "             'adam': ['admm'],\n",
       "             'adaptive method': ['adaptive methods'],\n",
       "             'adaptive methods': ['adaptive method'],\n",
       "             'admm': ['adam'],\n",
       "             'adversarial attack': ['adversarial attacks'],\n",
       "             'adversarial attacks': ['adversarial attack'],\n",
       "             'adversarial defence': ['adversarial defense'],\n",
       "             'adversarial defense': ['adversarial defence'],\n",
       "             'adversarial example': ['adversarial examples'],\n",
       "             'adversarial examples': ['adversarial example'],\n",
       "             'adversarial perturbation': ['adversarial perturbations'],\n",
       "             'adversarial perturbations': ['adversarial perturbation'],\n",
       "             'algorithm': ['algorithms'],\n",
       "             'algorithms': ['algorithm'],\n",
       "             'amortised inference': ['amortized inference'],\n",
       "             'amortized inference': ['amortised inference'],\n",
       "             'artificial neural network': ['artificial neural networks'],\n",
       "             'artificial neural networks': ['artificial neural network'],\n",
       "             'attention model': ['attention models'],\n",
       "             'attention models': ['attention model'],\n",
       "             'auto-encoders': ['autoencoders'],\n",
       "             'autodl': ['automl'],\n",
       "             'autoencoder': ['autoencoders'],\n",
       "             'autoencoders': ['autoencoder', 'auto-encoders'],\n",
       "             'automl': ['autodl'],\n",
       "             'autoregressive model': ['autoregressive models'],\n",
       "             'autoregressive models': ['autoregressive model'],\n",
       "             'back-propagation': ['backpropagation'],\n",
       "             'backpropagation': ['back-propagation'],\n",
       "             'bayesian neural network': ['bayesian neural networks'],\n",
       "             'bayesian neural networks': ['bayesian neural network'],\n",
       "             'bayesian nonparametric': ['bayesian nonparametrics'],\n",
       "             'bayesian nonparametrics': ['bayesian nonparametric'],\n",
       "             'bias-variance trade-off': ['bias-variance tradeoff'],\n",
       "             'bias-variance tradeoff': ['bias-variance trade-off'],\n",
       "             'binary neural network': ['binary neural networks'],\n",
       "             'binary neural networks': ['binary neural network'],\n",
       "             'black box': ['black-box'],\n",
       "             'black box optimization': ['blackbox optimization'],\n",
       "             'black-box': ['black box'],\n",
       "             'black-box attack': ['black-box attacks'],\n",
       "             'black-box attacks': ['black-box attack'],\n",
       "             'blackbox optimization': ['black box optimization'],\n",
       "             'capsule network': ['capsule networks'],\n",
       "             'capsule networks': ['capsule network'],\n",
       "             'catastrophic forgetting': ['catatrophic forgetting'],\n",
       "             'catatrophic forgetting': ['catastrophic forgetting'],\n",
       "             'compositionality': ['compostionality'],\n",
       "             'compostionality': ['compositionality'],\n",
       "             'conditional gan': ['conditional gans'],\n",
       "             'conditional gans': ['conditional gan'],\n",
       "             'conditional generative model': ['conditional generative models'],\n",
       "             'conditional generative models': ['conditional generative model'],\n",
       "             'continuous relaxation': ['continuous relaxations'],\n",
       "             'continuous relaxations': ['continuous relaxation'],\n",
       "             'convolution': ['convolutions'],\n",
       "             'convolutional network': ['convolutional networks'],\n",
       "             'convolutional networks': ['convolutional network'],\n",
       "             'convolutional neural network': ['convolutional neural networks'],\n",
       "             'convolutional neural networks': ['convolutional neural network'],\n",
       "             'convolutions': ['convolution'],\n",
       "             'cross entropy': ['cross-entropy'],\n",
       "             'cross-entropy': ['cross entropy'],\n",
       "             'decision tree': ['decision trees'],\n",
       "             'decision trees': ['decision tree'],\n",
       "             'deep generative model': ['deep generative models'],\n",
       "             'deep generative models': ['deep generative model'],\n",
       "             'deep learning': ['deep-learning', 'deeplearning'],\n",
       "             'deep network': ['deep networks'],\n",
       "             'deep networks': ['deep network'],\n",
       "             'deep neural network': ['deep neural networks'],\n",
       "             'deep neural networks': ['deep neural networks.',\n",
       "              'deep neural network'],\n",
       "             'deep neural networks.': ['deep neural networks'],\n",
       "             'deep rl': ['deeprl'],\n",
       "             'deep-learning': ['deep learning', 'deeplearning'],\n",
       "             'deeplearning': ['deep-learning', 'deep learning'],\n",
       "             'deeprl': ['deep rl'],\n",
       "             'defence': ['defense'],\n",
       "             'defense': ['defence'],\n",
       "             'denoising': ['denosing'],\n",
       "             'denosing': ['denoising'],\n",
       "             'differential equation': ['differential equations'],\n",
       "             'differential equations': ['differential equation'],\n",
       "             'discrete latent variable': ['discrete latent variables'],\n",
       "             'discrete latent variables': ['discrete latent variable'],\n",
       "             'disentangled representation': ['disentangled representations'],\n",
       "             'disentangled representations': ['disentangled representation'],\n",
       "             'dynamic network': ['dynamic networks'],\n",
       "             'dynamic networks': ['dynamic network'],\n",
       "             'dynamical system': ['dynamical systems'],\n",
       "             'dynamical systems': ['dynamical system'],\n",
       "             'embedding': ['embeddings'],\n",
       "             'embeddings': ['embedding'],\n",
       "             'ensemble': ['ensembles'],\n",
       "             'ensembles': ['ensemble'],\n",
       "             'evolutionary algorithm': ['evolutionary algorithms'],\n",
       "             'evolutionary algorithms': ['evolutionary algorithm'],\n",
       "             'extra-gradient': ['extragradient'],\n",
       "             'extragradient': ['extra-gradient'],\n",
       "             'face verification': ['fact verification'],\n",
       "             'fact verification': ['face verification'],\n",
       "             'feature attribution': ['feature attributions'],\n",
       "             'feature attributions': ['feature attribution'],\n",
       "             'few shot': ['few-shot'],\n",
       "             'few shot classification': ['few-shot classification'],\n",
       "             'few shot learning': ['few-shot learning'],\n",
       "             'few-shot': ['few shot'],\n",
       "             'few-shot classification': ['few shot classification'],\n",
       "             'few-shot learning': ['few shot learning'],\n",
       "             'fgsm': ['ifgsm'],\n",
       "             'finite state machine': ['finite state machines'],\n",
       "             'finite state machines': ['finite state machine'],\n",
       "             'first order logic': ['first-order logic'],\n",
       "             'first-order logic': ['first order logic'],\n",
       "             'forward model': ['forward models'],\n",
       "             'forward models': ['forward model'],\n",
       "             'game': ['games'],\n",
       "             'games': ['game'],\n",
       "             'gan': ['gnn'],\n",
       "             'gcn': ['gcnn', 'gnn'],\n",
       "             'gcnn': ['gcn'],\n",
       "             'genearative adversarial network': ['generative adversarial network'],\n",
       "             'generalization bound': ['generalization bounds'],\n",
       "             'generalization bounds': ['generalization bound'],\n",
       "             'generatice models': ['generative models'],\n",
       "             'generative adversarial network': ['genearative adversarial network',\n",
       "              'generative adversarial networks'],\n",
       "             'generative adversarial networks': ['generative adversarial networks.',\n",
       "              'generative adversarial network'],\n",
       "             'generative adversarial networks.': ['generative adversarial networks'],\n",
       "             'generative model': ['generative models'],\n",
       "             'generative modeling': ['generative modelling'],\n",
       "             'generative modelling': ['generative modeling'],\n",
       "             'generative models': ['generatice models', 'generative model'],\n",
       "             'genetic algorithm': ['genetic algorithms'],\n",
       "             'genetic algorithms': ['genetic algorithm'],\n",
       "             'gnn': ['gan', 'gcn'],\n",
       "             'gradient': ['gradients'],\n",
       "             'gradients': ['gradient'],\n",
       "             'graph': ['graphs'],\n",
       "             'graph convolution': ['graph convolutions'],\n",
       "             'graph convolutional network': ['graph convolutional networks'],\n",
       "             'graph convolutional networks': ['graph convolutional network'],\n",
       "             'graph convolutions': ['graph convolution'],\n",
       "             'graph neural network': ['graph neural networks'],\n",
       "             'graph neural networks': ['graph neural network'],\n",
       "             'graphical model': ['graphical models'],\n",
       "             'graphical models': ['graphical model'],\n",
       "             'graphs': ['graph'],\n",
       "             'hierarchical model': ['hierarchical models'],\n",
       "             'hierarchical models': ['hierarchical model'],\n",
       "             'hyperbolic space': ['hyperbolic spaces'],\n",
       "             'hyperbolic spaces': ['hyperbolic space'],\n",
       "             'hypernetwork': ['hypernetworks'],\n",
       "             'hypernetworks': ['hypernetwork'],\n",
       "             'i-fgsm': ['ifgsm'],\n",
       "             'ifgsm': ['i-fgsm', 'fgsm'],\n",
       "             'imitation learning': ['imitation-learning'],\n",
       "             'imitation-learning': ['imitation learning'],\n",
       "             'implicit probabilistic model': ['implicit probabilistic models'],\n",
       "             'implicit probabilistic models': ['implicit probabilistic model'],\n",
       "             'initialisation': ['initialization'],\n",
       "             'initialization': ['initialisation'],\n",
       "             'instruction following': ['instruction-following'],\n",
       "             'instruction-following': ['instruction following'],\n",
       "             'interpolation': ['interpolations'],\n",
       "             'interpolations': ['interpolation'],\n",
       "             'inverse problem': ['inverse problems'],\n",
       "             'inverse problems': ['inverse problem'],\n",
       "             'kernel method': ['kernel methods'],\n",
       "             'kernel methods': ['kernel method'],\n",
       "             'knowledge graph': ['knowledge graphs'],\n",
       "             'knowledge graphs': ['knowledge graph'],\n",
       "             'l1 regularization': ['l2 regularization'],\n",
       "             'l2 regularization': ['l1 regularization'],\n",
       "             'language model': ['langugage model'],\n",
       "             'language modeling': ['language modelling'],\n",
       "             'language modelling': ['language modeling'],\n",
       "             'langugage model': ['language model'],\n",
       "             'large batch training': ['large-batch training'],\n",
       "             'large scale': ['large-scale'],\n",
       "             'large-batch training': ['large batch training'],\n",
       "             'large-scale': ['large scale'],\n",
       "             'latent representation': ['latent representations'],\n",
       "             'latent representations': ['latent representation'],\n",
       "             'latent variable model': ['latent variable models'],\n",
       "             'latent variable modeling': ['latent variable modelling'],\n",
       "             'latent variable modelling': ['latent variable modeling'],\n",
       "             'latent variable models': ['latent variable model'],\n",
       "             'learning from demonstration': ['learning from demonstrations'],\n",
       "             'learning from demonstrations': ['learning from demonstration'],\n",
       "             'learning representation': ['learning representations'],\n",
       "             'learning representations': ['learning representation'],\n",
       "             'life-long learning': ['lifelong learning'],\n",
       "             'lifelong learning': ['life-long learning'],\n",
       "             'logic': ['logics'],\n",
       "             'logics': ['logic'],\n",
       "             'long short term memory': ['long short-term memory'],\n",
       "             'long short-term memory': ['long short term memory'],\n",
       "             'low precision': ['low-precision'],\n",
       "             'low-precision': ['low precision'],\n",
       "             'lstm': ['lstms'],\n",
       "             'lstms': ['lstm'],\n",
       "             'manifold': ['manifolds'],\n",
       "             'manifolds': ['manifold'],\n",
       "             'memory augmented neural networks': ['memory-augmented neural networks'],\n",
       "             'memory network': ['memory networks'],\n",
       "             'memory networks': ['memory network'],\n",
       "             'memory-augmented neural networks': ['memory augmented neural networks'],\n",
       "             'meta learning': ['meta-learning', 'metalearning'],\n",
       "             'meta reinforcement learning': ['meta-reinforcement learning'],\n",
       "             'meta-learning': ['meta learning', 'metalearning'],\n",
       "             'meta-reinforcement learning': ['meta reinforcement learning'],\n",
       "             'metalearning': ['meta learning', 'meta-learning'],\n",
       "             'mini-batch': ['minibatch'],\n",
       "             'minibatch': ['mini-batch'],\n",
       "             'mixture model': ['mixture models'],\n",
       "             'mixture models': ['mixture model'],\n",
       "             'mode collapse': ['mode-collapse'],\n",
       "             'mode-collapse': ['mode collapse'],\n",
       "             'model based reinforcement learning': ['model-based reinforcement learning'],\n",
       "             'model-based reinforcement learning': ['model based reinforcement learning'],\n",
       "             'modular network': ['modular networks'],\n",
       "             'modular networks': ['modular network'],\n",
       "             'multi agent': ['multi-agent', 'multiagent'],\n",
       "             'multi agent reinforcement learning': ['multi-agent reinforcement learning',\n",
       "              'multiagent reinforcement learning'],\n",
       "             'multi task': ['multi-task', 'multitask'],\n",
       "             'multi-agent': ['multiagent', 'multi agent'],\n",
       "             'multi-agent reinforcement learning': ['multiagent reinforcement learning',\n",
       "              'multi agent reinforcement learning'],\n",
       "             'multi-armed bandit': ['multi-armed bandits'],\n",
       "             'multi-armed bandits': ['multi-armed bandit'],\n",
       "             'multi-modal generation': ['multimodal generation'],\n",
       "             'multi-task': ['multitask', 'multi task'],\n",
       "             'multi-task learning': ['multitask learning'],\n",
       "             'multiagent': ['multi-agent', 'multi agent'],\n",
       "             'multiagent reinforcement learning': ['multi-agent reinforcement learning',\n",
       "              'multi agent reinforcement learning'],\n",
       "             'multimodal generation': ['multi-modal generation'],\n",
       "             'multitask': ['multi-task', 'multi task'],\n",
       "             'multitask learning': ['multi-task learning'],\n",
       "             'neural language model': ['neural language models'],\n",
       "             'neural language models': ['neural language model'],\n",
       "             'neural network': ['neural networks'],\n",
       "             'neural networks': ['neural-networks', 'neural network'],\n",
       "             'neural-networks': ['neural networks'],\n",
       "             'node embedding': ['node embeddings'],\n",
       "             'node embeddings': ['node embedding'],\n",
       "             'non convex optimization': ['nonconvex optimization',\n",
       "              'non-convex optimization'],\n",
       "             'non-convex optimization': ['non convex optimization',\n",
       "              'nonconvex optimization'],\n",
       "             'non-negative matrix factorisation': ['non-negative matrix factorization'],\n",
       "             'non-negative matrix factorization': ['non-negative matrix factorisation'],\n",
       "             'nonconvex optimization': ['non convex optimization',\n",
       "              'non-convex optimization'],\n",
       "             'open domain question answering': ['open-domain question answering'],\n",
       "             'open-domain question answering': ['open domain question answering'],\n",
       "             'optimisation': ['optimization'],\n",
       "             'optimization': ['optimisation'],\n",
       "             'over-parameterization': ['overparameterization',\n",
       "              'over-parametrization'],\n",
       "             'over-parametrization': ['over-parameterization'],\n",
       "             'overparameterization': ['over-parameterization'],\n",
       "             'partial differential equation': ['partial differential equations'],\n",
       "             'partial differential equations': ['partial differential equation'],\n",
       "             'permutation invariant': ['permutation-invariant'],\n",
       "             'permutation-invariant': ['permutation invariant'],\n",
       "             'perturbation': ['perturbations'],\n",
       "             'perturbations': ['perturbation'],\n",
       "             'point cloud': ['point clouds'],\n",
       "             'point clouds': ['point cloud'],\n",
       "             'policy gradient': ['policy gradients'],\n",
       "             'policy gradients': ['policy gradient'],\n",
       "             'question answering': ['question-answering'],\n",
       "             'question-answering': ['question answering'],\n",
       "             'real nvp': ['realnvp'],\n",
       "             'realnvp': ['real nvp'],\n",
       "             'recurrent network': ['recurrent networks'],\n",
       "             'recurrent networks': ['recurrent network'],\n",
       "             'recurrent neural network': ['recurrent neural networks'],\n",
       "             'recurrent neural networks': ['recurrent neural network'],\n",
       "             'reinforcement learning': ['reinforcement-learning'],\n",
       "             'reinforcement-learning': ['reinforcement learning'],\n",
       "             'relu': ['relus'],\n",
       "             'relus': ['relu'],\n",
       "             'representation': ['representations'],\n",
       "             'representations': ['representation'],\n",
       "             'rna': ['rnn'],\n",
       "             'rnn': ['rna'],\n",
       "             'robust optimisation': ['robust optimization'],\n",
       "             'robust optimization': ['robust optimisation'],\n",
       "             'rotation': ['rotations'],\n",
       "             'rotations': ['rotation'],\n",
       "             'saliency map': ['saliency maps'],\n",
       "             'saliency maps': ['saliency map'],\n",
       "             'self attention': ['self-attention'],\n",
       "             'self play': ['self-play'],\n",
       "             'self-attention': ['self attention'],\n",
       "             'self-play': ['self play'],\n",
       "             'semantic representation': ['semantic representations'],\n",
       "             'semantic representations': ['semantic representation'],\n",
       "             'semi supervised learning': ['semi-supervised learning'],\n",
       "             'semi-supervised learning': ['semi supervised learning'],\n",
       "             'sentence embedding': ['sentence embeddings'],\n",
       "             'sentence embeddings': ['sentence embedding'],\n",
       "             'sentence representation': ['sentence representations'],\n",
       "             'sentence representations': ['sentence representation'],\n",
       "             'sequence model': ['sequence models'],\n",
       "             'sequence modeling': ['sequence modelling'],\n",
       "             'sequence modelling': ['sequence modeling'],\n",
       "             'sequence models': ['sequence model'],\n",
       "             'set': ['sets'],\n",
       "             'set function': ['set functions'],\n",
       "             'set functions': ['set function'],\n",
       "             'sets': ['set'],\n",
       "             'shapley value': ['shapley values'],\n",
       "             'shapley values': ['shapley value'],\n",
       "             'siamese network': ['siamese networks'],\n",
       "             'siamese networks': ['siamese network'],\n",
       "             'sparse reward': ['sparse rewards'],\n",
       "             'sparse rewards': ['sparse reward'],\n",
       "             'stochastic computation graph': ['stochastic computation graphs'],\n",
       "             'stochastic computation graphs': ['stochastic computation graph'],\n",
       "             'straight-through estimator': ['straight-through-estimator'],\n",
       "             'straight-through-estimator': ['straight-through estimator'],\n",
       "             'structure learning': ['structured learning'],\n",
       "             'structured learning': ['structure learning'],\n",
       "             'structured scene representation': ['structured scene representations'],\n",
       "             'structured scene representations': ['structured scene representation'],\n",
       "             'successor representation': ['successor representations'],\n",
       "             'successor representations': ['successor representation'],\n",
       "             'td learning': ['3d learning'],\n",
       "             'text embedding': ['text embeddings'],\n",
       "             'text embeddings': ['text embedding'],\n",
       "             'transformer': ['transformers'],\n",
       "             'transformers': ['transformer'],\n",
       "             'uncertainty  estimation': ['uncertainty estimation'],\n",
       "             'uncertainty estimation': ['uncertainty  estimation'],\n",
       "             'variational auto encoder': ['variational auto encoders',\n",
       "              'variational auto-encoder',\n",
       "              'variational autoencoder'],\n",
       "             'variational auto encoders': ['variational auto encoder',\n",
       "              'variational auto-encoders',\n",
       "              'variational autoencoders'],\n",
       "             'variational auto-encoder': ['variational auto encoder',\n",
       "              'variational auto-encoders',\n",
       "              'variational autoencoder'],\n",
       "             'variational auto-encoders': ['variational auto encoders',\n",
       "              'variational auto-encoder',\n",
       "              'variational autoencoders'],\n",
       "             'variational autoencoder': ['variational auto encoder',\n",
       "              'variational auto-encoder',\n",
       "              'variational autoencoders'],\n",
       "             'variational autoencoders': ['variational autoencoders.',\n",
       "              'variational auto encoders',\n",
       "              'variational auto-encoders',\n",
       "              'variational autoencoder'],\n",
       "             'variational autoencoders.': ['variational autoencoders'],\n",
       "             'variational inference': ['variational inference.',\n",
       "              'variational lnference'],\n",
       "             'variational inference.': ['variational inference'],\n",
       "             'variational lnference': ['variational inference'],\n",
       "             'variational model': ['variational models'],\n",
       "             'variational models': ['variational model'],\n",
       "             'visual question answering': ['visual questions answering'],\n",
       "             'visual questions answering': ['visual question answering'],\n",
       "             'visualisation': ['visualization'],\n",
       "             'visualization': ['visualisation'],\n",
       "             'wasserstein distance': ['wasserstein distances'],\n",
       "             'wasserstein distances': ['wasserstein distance'],\n",
       "             'wavenet': ['wavnet'],\n",
       "             'wavnet': ['wavenet'],\n",
       "             'weakly supervised learning': ['weakly-supervised learning'],\n",
       "             'weakly-supervised learning': ['weakly supervised learning'],\n",
       "             'word embeddings': ['word-embeddings'],\n",
       "             'word-embeddings': ['word embeddings'],\n",
       "             'zero-short learning': ['zero-shot learning'],\n",
       "             'zero-shot learning': ['zero-short learning']})"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_clusters(matches):\n",
    "    clusters = dict()\n",
    "    for topic in matches:\n",
    "        values = matches[topic]\n",
    "        clusters[topic] = topic\n",
    "        for v in values:\n",
    "            if len(matches.get(v, [])) > len(values) or \\\n",
    "            (len(matches.get(v, [])) == len(values) and topic > v):\n",
    "                clusters[topic] = v\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = get_clusters(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_df(papers, clusters):\n",
    "    rows = []\n",
    "    for paper in papers:\n",
    "        topic = paper.content['keywords'][0] if len(paper.content['keywords']) else ''\n",
    "        cluster = clusters.get(topic.lower(), topic.lower() if topic else None)\n",
    "        row = dict(tldr = paper.content.get('TL;DR', ''),\n",
    "                  ratings = getattr(paper, 'ratings', []),\n",
    "                  confidence = getattr(paper, 'confidence', []),\n",
    "                  title = paper.content['title'],\n",
    "                  avg_rating = np.mean(getattr(paper, 'ratings', [])),\n",
    "                  avg_confidence = np.mean(getattr(paper, 'confidence', [])),\n",
    "                  topic = cluster,\n",
    "                  url = \"https://openreview.net/forum?id=\" + paper.forum\n",
    "                  )\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.index.name = 'Index'\n",
    "    df = df.iloc[:, [4,1,0,6,5,3,2,7]]\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df(papers, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>avg_confidence</th>\n",
       "      <th>topic</th>\n",
       "      <th>tldr</th>\n",
       "      <th>ratings</th>\n",
       "      <th>confidence</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G-SGD: Optimizing ReLU Neural Networks in its ...</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>optimisation</td>\n",
       "      <td></td>\n",
       "      <td>[7, 7, 6]</td>\n",
       "      <td>[2, 3, 4]</td>\n",
       "      <td>https://openreview.net/forum?id=SyxfEn09Y7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADef: an Iterative Algorithm to Construct Adve...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>adversarial example</td>\n",
       "      <td>We propose a new, efficient algorithm to const...</td>\n",
       "      <td>[7, 7, 4]</td>\n",
       "      <td>[4, 3, 3]</td>\n",
       "      <td>https://openreview.net/forum?id=Hk4dFjR5K7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generative Code Modeling with Graphs</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>generative models</td>\n",
       "      <td>Representing programs as graphs including sema...</td>\n",
       "      <td>[7, 7, 5]</td>\n",
       "      <td>[4, 4, 5]</td>\n",
       "      <td>https://openreview.net/forum?id=Bke4KsA5FX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quality Evaluation of GANs Using Cross Local I...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>generative adversarial network</td>\n",
       "      <td>We propose a new metric for evaluating GAN mod...</td>\n",
       "      <td>[4, 6, 5]</td>\n",
       "      <td>[3, 4, 5]</td>\n",
       "      <td>https://openreview.net/forum?id=BJgYl205tQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L-Shapley and C-Shapley: Efficient Model Inter...</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>model interpretation</td>\n",
       "      <td>We develop two linear-complexity algorithms fo...</td>\n",
       "      <td>[7, 7, 5]</td>\n",
       "      <td>[3, 2, 4]</td>\n",
       "      <td>https://openreview.net/forum?id=S1E3Ko09F7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  avg_rating  \\\n",
       "Index                                                                  \n",
       "0      G-SGD: Optimizing ReLU Neural Networks in its ...    6.666667   \n",
       "1      ADef: an Iterative Algorithm to Construct Adve...    6.000000   \n",
       "2                   Generative Code Modeling with Graphs    6.333333   \n",
       "3      Quality Evaluation of GANs Using Cross Local I...    5.000000   \n",
       "4      L-Shapley and C-Shapley: Efficient Model Inter...    6.333333   \n",
       "\n",
       "       avg_confidence                           topic  \\\n",
       "Index                                                   \n",
       "0            3.000000                    optimisation   \n",
       "1            3.333333             adversarial example   \n",
       "2            4.333333               generative models   \n",
       "3            4.000000  generative adversarial network   \n",
       "4            3.000000            model interpretation   \n",
       "\n",
       "                                                    tldr    ratings  \\\n",
       "Index                                                                 \n",
       "0                                                         [7, 7, 6]   \n",
       "1      We propose a new, efficient algorithm to const...  [7, 7, 4]   \n",
       "2      Representing programs as graphs including sema...  [7, 7, 5]   \n",
       "3      We propose a new metric for evaluating GAN mod...  [4, 6, 5]   \n",
       "4      We develop two linear-complexity algorithms fo...  [7, 7, 5]   \n",
       "\n",
       "      confidence                                         url  \n",
       "Index                                                         \n",
       "0      [2, 3, 4]  https://openreview.net/forum?id=SyxfEn09Y7  \n",
       "1      [4, 3, 3]  https://openreview.net/forum?id=Hk4dFjR5K7  \n",
       "2      [4, 4, 5]  https://openreview.net/forum?id=Bke4KsA5FX  \n",
       "3      [3, 4, 5]  https://openreview.net/forum?id=BJgYl205tQ  \n",
       "4      [3, 2, 4]  https://openreview.net/forum?id=S1E3Ko09F7  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "show_grid() got an unexpected keyword argument 'export_mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-213-6ef28b81ab2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mcol_defs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'topic'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'width'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mgrid_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'forceFitColumns'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'defaultColumnWidth'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mqgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_definitions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol_defs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: show_grid() got an unexpected keyword argument 'export_mode'"
     ]
    }
   ],
   "source": [
    "col_defs = {\n",
    "    name: {\n",
    "        'width': 50\n",
    "    } for name in ['Index', 'confidence', 'ratings']\n",
    "}\n",
    "col_defs['title'] = {'width': 500}\n",
    "col_defs['avg_rating'] = {'width': 100}\n",
    "col_defs['tldr'] = {'width': 1000}\n",
    "col_defs['url'] = {'width': 300}\n",
    "col_defs['topic'] = {'width': 200}\n",
    "grid_options={'forceFitColumns': False, 'defaultColumnWidth': 100}\n",
    "qgrid.show_grid(df, column_definitions=col_defs, grid_options = grid_options, precision=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "?qgrid.show_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-convex optimization ['non convex optimization', 'nonconvex optimization']\n",
      "multi-agent reinforcement learning ['multiagent reinforcement learning', 'multi agent reinforcement learning']\n",
      "variational inference ['variational inference.', 'variational lnference']\n",
      "multiagent reinforcement learning ['multi-agent reinforcement learning', 'multi agent reinforcement learning']\n",
      "multiagent ['multi agent', 'multi-agent']\n",
      "neural networks ['neural network', 'neural-networks']\n",
      "autoencoders ['autoencoder', 'auto-encoders']\n",
      "over-parameterization ['overparameterization', 'over-parametrization']\n",
      "variational auto encoder ['variational autoencoder', 'variational auto encoders', 'variational auto-encoder']\n",
      "generative adversarial networks ['generative adversarial network', 'generative adversarial networks.']\n",
      "generative models ['generatice models', 'generative model']\n",
      "variational autoencoder ['variational auto encoder', 'variational auto-encoder', 'variational autoencoders']\n",
      "deep-learning ['deep learning', 'deeplearning']\n",
      "non convex optimization ['non-convex optimization', 'nonconvex optimization']\n",
      "variational auto encoders ['variational auto encoder', 'variational auto-encoders', 'variational autoencoders']\n",
      "multi agent ['multiagent', 'multi-agent']\n",
      "deep learning ['deep-learning', 'deeplearning']\n",
      "meta learning ['meta-learning', 'metalearning']\n",
      "generative adversarial network ['genearative adversarial network', 'generative adversarial networks']\n",
      "deep neural networks ['deep neural network', 'deep neural networks.']\n",
      "meta-learning ['meta learning', 'metalearning']\n",
      "nonconvex optimization ['non-convex optimization', 'non convex optimization']\n",
      "multi-task ['multitask', 'multi task']\n",
      "variational auto-encoder ['variational auto encoder', 'variational autoencoder', 'variational auto-encoders']\n",
      "variational auto-encoders ['variational auto encoders', 'variational auto-encoder', 'variational autoencoders']\n",
      "multitask ['multi-task', 'multi task']\n",
      "multi-agent ['multiagent', 'multi agent']\n",
      "multi task ['multi-task', 'multitask']\n",
      "gnn ['gan', 'gcn']\n",
      "deeplearning ['deep-learning', 'deep learning']\n",
      "metalearning ['meta learning', 'meta-learning']\n",
      "ifgsm ['i-fgsm', 'fgsm']\n",
      "variational autoencoders ['variational autoencoders.', 'variational autoencoder', 'variational auto encoders', 'variational auto-encoders']\n",
      "multi agent reinforcement learning ['multi-agent reinforcement learning', 'multiagent reinforcement learning']\n"
     ]
    }
   ],
   "source": [
    "for topic in top:\n",
    "    if len(top[topic]) > 1:\n",
    "        print(topic, top[topic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-convex optimization', 'nonconvex optimization']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top['non convex optimization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['3d learning', 'td learning'],\n",
       " ['3d learning', 'td learning'],\n",
       " ['activation function', 'activation functions'],\n",
       " ['activation function', 'activation functions'],\n",
       " ['active  learning', 'active learning'],\n",
       " ['active  learning', 'active learning'],\n",
       " ['adam', 'admm'],\n",
       " ['adam', 'admm'],\n",
       " ['adaptive method', 'adaptive methods'],\n",
       " ['adaptive method', 'adaptive methods'],\n",
       " ['adversarial attack', 'adversarial attacks'],\n",
       " ['adversarial attack', 'adversarial attacks'],\n",
       " ['adversarial defence', 'adversarial defense'],\n",
       " ['adversarial defence', 'adversarial defense'],\n",
       " ['adversarial example', 'adversarial examples'],\n",
       " ['adversarial example', 'adversarial examples'],\n",
       " ['adversarial perturbation', 'adversarial perturbations'],\n",
       " ['adversarial perturbation', 'adversarial perturbations'],\n",
       " ['algorithm', 'algorithms'],\n",
       " ['algorithm', 'algorithms'],\n",
       " ['amortised inference', 'amortized inference'],\n",
       " ['amortised inference', 'amortized inference'],\n",
       " ['artificial neural network', 'artificial neural networks'],\n",
       " ['artificial neural network', 'artificial neural networks'],\n",
       " ['attention model', 'attention models'],\n",
       " ['attention model', 'attention models'],\n",
       " ['auto-encoders', 'autoencoders'],\n",
       " ['auto-encoders', 'autoencoders'],\n",
       " ['autodl', 'automl'],\n",
       " ['autodl', 'automl'],\n",
       " ['autoencoder', 'autoencoders'],\n",
       " ['autoencoder', 'autoencoders'],\n",
       " ['autoregressive model', 'autoregressive models'],\n",
       " ['autoregressive model', 'autoregressive models'],\n",
       " ['back-propagation', 'backpropagation'],\n",
       " ['back-propagation', 'backpropagation'],\n",
       " ['bayesian neural network', 'bayesian neural networks'],\n",
       " ['bayesian neural network', 'bayesian neural networks'],\n",
       " ['bayesian nonparametric', 'bayesian nonparametrics'],\n",
       " ['bayesian nonparametric', 'bayesian nonparametrics'],\n",
       " ['bias-variance trade-off', 'bias-variance tradeoff'],\n",
       " ['bias-variance trade-off', 'bias-variance tradeoff'],\n",
       " ['binary neural network', 'binary neural networks'],\n",
       " ['binary neural network', 'binary neural networks'],\n",
       " ['black box', 'black-box'],\n",
       " ['black box', 'black-box'],\n",
       " ['black box optimization', 'blackbox optimization'],\n",
       " ['black box optimization', 'blackbox optimization'],\n",
       " ['black-box attack', 'black-box attacks'],\n",
       " ['black-box attack', 'black-box attacks'],\n",
       " ['capsule network', 'capsule networks'],\n",
       " ['capsule network', 'capsule networks'],\n",
       " ['catastrophic forgetting', 'catatrophic forgetting'],\n",
       " ['catastrophic forgetting', 'catatrophic forgetting'],\n",
       " ['compositionality', 'compostionality'],\n",
       " ['compositionality', 'compostionality'],\n",
       " ['conditional gan', 'conditional gans'],\n",
       " ['conditional gan', 'conditional gans'],\n",
       " ['conditional generative model', 'conditional generative models'],\n",
       " ['conditional generative model', 'conditional generative models'],\n",
       " ['continuous relaxation', 'continuous relaxations'],\n",
       " ['continuous relaxation', 'continuous relaxations'],\n",
       " ['convolution', 'convolutions'],\n",
       " ['convolution', 'convolutions'],\n",
       " ['convolutional network', 'convolutional networks'],\n",
       " ['convolutional network', 'convolutional networks'],\n",
       " ['convolutional neural network', 'convolutional neural networks'],\n",
       " ['convolutional neural network', 'convolutional neural networks'],\n",
       " ['cross entropy', 'cross-entropy'],\n",
       " ['cross entropy', 'cross-entropy'],\n",
       " ['decision tree', 'decision trees'],\n",
       " ['decision tree', 'decision trees'],\n",
       " ['deep generative model', 'deep generative models'],\n",
       " ['deep generative model', 'deep generative models'],\n",
       " ['deep learning', 'deep-learning'],\n",
       " ['deep learning', 'deep-learning'],\n",
       " ['deep learning', 'deeplearning'],\n",
       " ['deep learning', 'deeplearning'],\n",
       " ['deep network', 'deep networks'],\n",
       " ['deep network', 'deep networks'],\n",
       " ['deep neural network', 'deep neural networks'],\n",
       " ['deep neural network', 'deep neural networks'],\n",
       " ['deep neural networks', 'deep neural networks.'],\n",
       " ['deep neural networks', 'deep neural networks.'],\n",
       " ['deep rl', 'deeprl'],\n",
       " ['deep rl', 'deeprl'],\n",
       " ['deep-learning', 'deeplearning'],\n",
       " ['deep-learning', 'deeplearning'],\n",
       " ['defence', 'defense'],\n",
       " ['defence', 'defense'],\n",
       " ['denoising', 'denosing'],\n",
       " ['denoising', 'denosing'],\n",
       " ['differential equation', 'differential equations'],\n",
       " ['differential equation', 'differential equations'],\n",
       " ['discrete latent variable', 'discrete latent variables'],\n",
       " ['discrete latent variable', 'discrete latent variables'],\n",
       " ['disentangled representation', 'disentangled representations'],\n",
       " ['disentangled representation', 'disentangled representations'],\n",
       " ['dynamic network', 'dynamic networks'],\n",
       " ['dynamic network', 'dynamic networks'],\n",
       " ['dynamical system', 'dynamical systems'],\n",
       " ['dynamical system', 'dynamical systems'],\n",
       " ['embedding', 'embeddings'],\n",
       " ['embedding', 'embeddings'],\n",
       " ['ensemble', 'ensembles'],\n",
       " ['ensemble', 'ensembles'],\n",
       " ['evolutionary algorithm', 'evolutionary algorithms'],\n",
       " ['evolutionary algorithm', 'evolutionary algorithms'],\n",
       " ['extra-gradient', 'extragradient'],\n",
       " ['extra-gradient', 'extragradient'],\n",
       " ['face verification', 'fact verification'],\n",
       " ['face verification', 'fact verification'],\n",
       " ['feature attribution', 'feature attributions'],\n",
       " ['feature attribution', 'feature attributions'],\n",
       " ['few shot', 'few-shot'],\n",
       " ['few shot', 'few-shot'],\n",
       " ['few shot classification', 'few-shot classification'],\n",
       " ['few shot classification', 'few-shot classification'],\n",
       " ['few shot learning', 'few-shot learning'],\n",
       " ['few shot learning', 'few-shot learning'],\n",
       " ['fgsm', 'ifgsm'],\n",
       " ['fgsm', 'ifgsm'],\n",
       " ['finite state machine', 'finite state machines'],\n",
       " ['finite state machine', 'finite state machines'],\n",
       " ['first order logic', 'first-order logic'],\n",
       " ['first order logic', 'first-order logic'],\n",
       " ['forward model', 'forward models'],\n",
       " ['forward model', 'forward models'],\n",
       " ['game', 'games'],\n",
       " ['game', 'games'],\n",
       " ['gan', 'gnn'],\n",
       " ['gcn', 'gcnn'],\n",
       " ['gcn', 'gcnn'],\n",
       " ['gcn', 'gnn'],\n",
       " ['genearative adversarial network', 'generative adversarial network'],\n",
       " ['genearative adversarial network', 'generative adversarial network'],\n",
       " ['generalization bound', 'generalization bounds'],\n",
       " ['generalization bound', 'generalization bounds'],\n",
       " ['generatice models', 'generative models'],\n",
       " ['generatice models', 'generative models'],\n",
       " ['generative adversarial network', 'generative adversarial networks'],\n",
       " ['generative adversarial network', 'generative adversarial networks'],\n",
       " ['generative adversarial networks', 'generative adversarial networks.'],\n",
       " ['generative adversarial networks', 'generative adversarial networks.'],\n",
       " ['generative model', 'generative models'],\n",
       " ['generative model', 'generative models'],\n",
       " ['generative modeling', 'generative modelling'],\n",
       " ['generative modeling', 'generative modelling'],\n",
       " ['genetic algorithm', 'genetic algorithms'],\n",
       " ['genetic algorithm', 'genetic algorithms'],\n",
       " ['gradient', 'gradients'],\n",
       " ['gradient', 'gradients'],\n",
       " ['graph', 'graphs'],\n",
       " ['graph', 'graphs'],\n",
       " ['graph convolution', 'graph convolutions'],\n",
       " ['graph convolution', 'graph convolutions'],\n",
       " ['graph convolutional network', 'graph convolutional networks'],\n",
       " ['graph convolutional network', 'graph convolutional networks'],\n",
       " ['graph neural network', 'graph neural networks'],\n",
       " ['graph neural network', 'graph neural networks'],\n",
       " ['graphical model', 'graphical models'],\n",
       " ['graphical model', 'graphical models'],\n",
       " ['hierarchical model', 'hierarchical models'],\n",
       " ['hierarchical model', 'hierarchical models'],\n",
       " ['hyperbolic space', 'hyperbolic spaces'],\n",
       " ['hyperbolic space', 'hyperbolic spaces'],\n",
       " ['hypernetwork', 'hypernetworks'],\n",
       " ['hypernetwork', 'hypernetworks'],\n",
       " ['i-fgsm', 'ifgsm'],\n",
       " ['i-fgsm', 'ifgsm'],\n",
       " ['imitation learning', 'imitation-learning'],\n",
       " ['imitation learning', 'imitation-learning'],\n",
       " ['implicit probabilistic model', 'implicit probabilistic models'],\n",
       " ['implicit probabilistic model', 'implicit probabilistic models'],\n",
       " ['initialisation', 'initialization'],\n",
       " ['initialisation', 'initialization'],\n",
       " ['instruction following', 'instruction-following'],\n",
       " ['interpolation', 'interpolations'],\n",
       " ['interpolation', 'interpolations'],\n",
       " ['inverse problem', 'inverse problems'],\n",
       " ['inverse problem', 'inverse problems'],\n",
       " ['kernel method', 'kernel methods'],\n",
       " ['kernel method', 'kernel methods'],\n",
       " ['knowledge graph', 'knowledge graphs'],\n",
       " ['knowledge graph', 'knowledge graphs'],\n",
       " ['l1 regularization', 'l2 regularization'],\n",
       " ['l1 regularization', 'l2 regularization'],\n",
       " ['language model', 'langugage model'],\n",
       " ['language model', 'langugage model'],\n",
       " ['language modeling', 'language modelling'],\n",
       " ['language modeling', 'language modelling'],\n",
       " ['large batch training', 'large-batch training'],\n",
       " ['large batch training', 'large-batch training'],\n",
       " ['large scale', 'large-scale'],\n",
       " ['large scale', 'large-scale'],\n",
       " ['latent representation', 'latent representations'],\n",
       " ['latent representation', 'latent representations'],\n",
       " ['latent variable model', 'latent variable models'],\n",
       " ['latent variable model', 'latent variable models'],\n",
       " ['latent variable modeling', 'latent variable modelling'],\n",
       " ['latent variable modeling', 'latent variable modelling'],\n",
       " ['learning from demonstration', 'learning from demonstrations'],\n",
       " ['learning from demonstration', 'learning from demonstrations'],\n",
       " ['learning representation', 'learning representations'],\n",
       " ['learning representation', 'learning representations'],\n",
       " ['life-long learning', 'lifelong learning'],\n",
       " ['life-long learning', 'lifelong learning'],\n",
       " ['logic', 'logics'],\n",
       " ['logic', 'logics'],\n",
       " ['long short term memory', 'long short-term memory'],\n",
       " ['long short term memory', 'long short-term memory'],\n",
       " ['low precision', 'low-precision'],\n",
       " ['low precision', 'low-precision'],\n",
       " ['lstm', 'lstms'],\n",
       " ['lstm', 'lstms'],\n",
       " ['manifold', 'manifolds'],\n",
       " ['manifold', 'manifolds'],\n",
       " ['memory augmented neural networks', 'memory-augmented neural networks'],\n",
       " ['memory augmented neural networks', 'memory-augmented neural networks'],\n",
       " ['memory network', 'memory networks'],\n",
       " ['memory network', 'memory networks'],\n",
       " ['meta learning', 'meta-learning'],\n",
       " ['meta learning', 'meta-learning'],\n",
       " ['meta learning', 'metalearning'],\n",
       " ['meta learning', 'metalearning'],\n",
       " ['meta reinforcement learning', 'meta-reinforcement learning'],\n",
       " ['meta reinforcement learning', 'meta-reinforcement learning'],\n",
       " ['meta-learning', 'metalearning'],\n",
       " ['meta-learning', 'metalearning'],\n",
       " ['mini-batch', 'minibatch'],\n",
       " ['mini-batch', 'minibatch'],\n",
       " ['mixture model', 'mixture models'],\n",
       " ['mixture model', 'mixture models'],\n",
       " ['mode collapse', 'mode-collapse'],\n",
       " ['mode collapse', 'mode-collapse'],\n",
       " ['model based reinforcement learning', 'model-based reinforcement learning'],\n",
       " ['model based reinforcement learning', 'model-based reinforcement learning'],\n",
       " ['modular network', 'modular networks'],\n",
       " ['modular network', 'modular networks'],\n",
       " ['multi agent', 'multi-agent'],\n",
       " ['multi agent', 'multi-agent'],\n",
       " ['multi agent', 'multiagent'],\n",
       " ['multi agent', 'multiagent'],\n",
       " ['multi agent reinforcement learning', 'multi-agent reinforcement learning'],\n",
       " ['multi agent reinforcement learning', 'multi-agent reinforcement learning'],\n",
       " ['multi agent reinforcement learning', 'multiagent reinforcement learning'],\n",
       " ['multi agent reinforcement learning', 'multiagent reinforcement learning'],\n",
       " ['multi task', 'multi-task'],\n",
       " ['multi task', 'multi-task'],\n",
       " ['multi task', 'multitask'],\n",
       " ['multi task', 'multitask'],\n",
       " ['multi-agent', 'multiagent'],\n",
       " ['multi-agent', 'multiagent'],\n",
       " ['multi-agent reinforcement learning', 'multiagent reinforcement learning'],\n",
       " ['multi-agent reinforcement learning', 'multiagent reinforcement learning'],\n",
       " ['multi-armed bandit', 'multi-armed bandits'],\n",
       " ['multi-armed bandit', 'multi-armed bandits'],\n",
       " ['multi-modal generation', 'multimodal generation'],\n",
       " ['multi-modal generation', 'multimodal generation'],\n",
       " ['multi-task', 'multitask'],\n",
       " ['multi-task', 'multitask'],\n",
       " ['multi-task learning', 'multitask learning'],\n",
       " ['multi-task learning', 'multitask learning'],\n",
       " ['neural language model', 'neural language models'],\n",
       " ['neural language model', 'neural language models'],\n",
       " ['neural network', 'neural networks'],\n",
       " ['neural network', 'neural networks'],\n",
       " ['neural networks', 'neural-networks'],\n",
       " ['neural networks', 'neural-networks'],\n",
       " ['node embedding', 'node embeddings'],\n",
       " ['node embedding', 'node embeddings'],\n",
       " ['non convex optimization', 'non-convex optimization'],\n",
       " ['non convex optimization', 'non-convex optimization'],\n",
       " ['non convex optimization', 'nonconvex optimization'],\n",
       " ['non convex optimization', 'nonconvex optimization'],\n",
       " ['non-convex optimization', 'nonconvex optimization'],\n",
       " ['non-convex optimization', 'nonconvex optimization'],\n",
       " ['non-negative matrix factorisation', 'non-negative matrix factorization'],\n",
       " ['non-negative matrix factorisation', 'non-negative matrix factorization'],\n",
       " ['open domain question answering', 'open-domain question answering'],\n",
       " ['open domain question answering', 'open-domain question answering'],\n",
       " ['optimisation', 'optimization'],\n",
       " ['optimisation', 'optimization'],\n",
       " ['over-parameterization', 'over-parametrization'],\n",
       " ['over-parameterization', 'over-parametrization'],\n",
       " ['over-parameterization', 'overparameterization'],\n",
       " ['over-parameterization', 'overparameterization'],\n",
       " ['partial differential equation', 'partial differential equations'],\n",
       " ['partial differential equation', 'partial differential equations'],\n",
       " ['permutation invariant', 'permutation-invariant'],\n",
       " ['permutation invariant', 'permutation-invariant'],\n",
       " ['perturbation', 'perturbations'],\n",
       " ['perturbation', 'perturbations'],\n",
       " ['point cloud', 'point clouds'],\n",
       " ['point cloud', 'point clouds'],\n",
       " ['policy gradient', 'policy gradients'],\n",
       " ['policy gradient', 'policy gradients'],\n",
       " ['question answering', 'question-answering'],\n",
       " ['question answering', 'question-answering'],\n",
       " ['real nvp', 'realnvp'],\n",
       " ['real nvp', 'realnvp'],\n",
       " ['recurrent network', 'recurrent networks'],\n",
       " ['recurrent network', 'recurrent networks'],\n",
       " ['recurrent neural network', 'recurrent neural networks'],\n",
       " ['recurrent neural network', 'recurrent neural networks'],\n",
       " ['reinforcement learning', 'reinforcement-learning'],\n",
       " ['reinforcement learning', 'reinforcement-learning'],\n",
       " ['relu', 'relus'],\n",
       " ['relu', 'relus'],\n",
       " ['representation', 'representations'],\n",
       " ['representation', 'representations'],\n",
       " ['rna', 'rnn'],\n",
       " ['robust optimisation', 'robust optimization'],\n",
       " ['robust optimisation', 'robust optimization'],\n",
       " ['rotation', 'rotations'],\n",
       " ['rotation', 'rotations'],\n",
       " ['saliency map', 'saliency maps'],\n",
       " ['saliency map', 'saliency maps'],\n",
       " ['self attention', 'self-attention'],\n",
       " ['self attention', 'self-attention'],\n",
       " ['self play', 'self-play'],\n",
       " ['self play', 'self-play'],\n",
       " ['semantic representation', 'semantic representations'],\n",
       " ['semantic representation', 'semantic representations'],\n",
       " ['semi supervised learning', 'semi-supervised learning'],\n",
       " ['semi supervised learning', 'semi-supervised learning'],\n",
       " ['sentence embedding', 'sentence embeddings'],\n",
       " ['sentence embedding', 'sentence embeddings'],\n",
       " ['sentence representation', 'sentence representations'],\n",
       " ['sentence representation', 'sentence representations'],\n",
       " ['sequence model', 'sequence models'],\n",
       " ['sequence model', 'sequence models'],\n",
       " ['sequence modeling', 'sequence modelling'],\n",
       " ['sequence modeling', 'sequence modelling'],\n",
       " ['set', 'sets'],\n",
       " ['set', 'sets'],\n",
       " ['set function', 'set functions'],\n",
       " ['set function', 'set functions'],\n",
       " ['shapley value', 'shapley values'],\n",
       " ['shapley value', 'shapley values'],\n",
       " ['siamese network', 'siamese networks'],\n",
       " ['siamese network', 'siamese networks'],\n",
       " ['sparse reward', 'sparse rewards'],\n",
       " ['sparse reward', 'sparse rewards'],\n",
       " ['stochastic computation graph', 'stochastic computation graphs'],\n",
       " ['stochastic computation graph', 'stochastic computation graphs'],\n",
       " ['straight-through estimator', 'straight-through-estimator'],\n",
       " ['straight-through estimator', 'straight-through-estimator'],\n",
       " ['structure learning', 'structured learning'],\n",
       " ['structure learning', 'structured learning'],\n",
       " ['structured scene representation', 'structured scene representations'],\n",
       " ['structured scene representation', 'structured scene representations'],\n",
       " ['successor representation', 'successor representations'],\n",
       " ['successor representation', 'successor representations'],\n",
       " ['text embedding', 'text embeddings'],\n",
       " ['text embedding', 'text embeddings'],\n",
       " ['transformer', 'transformers'],\n",
       " ['transformer', 'transformers'],\n",
       " ['uncertainty  estimation', 'uncertainty estimation'],\n",
       " ['uncertainty  estimation', 'uncertainty estimation'],\n",
       " ['variational auto encoder', 'variational auto encoders'],\n",
       " ['variational auto encoder', 'variational auto encoders'],\n",
       " ['variational auto encoder', 'variational auto-encoder'],\n",
       " ['variational auto encoder', 'variational auto-encoder'],\n",
       " ['variational auto encoder', 'variational autoencoder'],\n",
       " ['variational auto encoder', 'variational autoencoder'],\n",
       " ['variational auto encoders', 'variational auto-encoders'],\n",
       " ['variational auto encoders', 'variational auto-encoders'],\n",
       " ['variational auto encoders', 'variational autoencoders'],\n",
       " ['variational auto encoders', 'variational autoencoders'],\n",
       " ['variational auto-encoder', 'variational auto-encoders'],\n",
       " ['variational auto-encoder', 'variational auto-encoders'],\n",
       " ['variational auto-encoder', 'variational autoencoder'],\n",
       " ['variational auto-encoder', 'variational autoencoder'],\n",
       " ['variational auto-encoders', 'variational autoencoders'],\n",
       " ['variational auto-encoders', 'variational autoencoders'],\n",
       " ['variational autoencoder', 'variational autoencoders'],\n",
       " ['variational autoencoder', 'variational autoencoders'],\n",
       " ['variational autoencoders', 'variational autoencoders.'],\n",
       " ['variational autoencoders', 'variational autoencoders.'],\n",
       " ['variational inference', 'variational inference.'],\n",
       " ['variational inference', 'variational inference.'],\n",
       " ['variational inference', 'variational lnference'],\n",
       " ['variational inference', 'variational lnference'],\n",
       " ['variational model', 'variational models'],\n",
       " ['variational model', 'variational models'],\n",
       " ['visual question answering', 'visual questions answering'],\n",
       " ['visual question answering', 'visual questions answering'],\n",
       " ['visualisation', 'visualization'],\n",
       " ['visualisation', 'visualization'],\n",
       " ['wasserstein distance', 'wasserstein distances'],\n",
       " ['wasserstein distance', 'wasserstein distances'],\n",
       " ['wavenet', 'wavnet'],\n",
       " ['wavenet', 'wavnet'],\n",
       " ['weakly supervised learning', 'weakly-supervised learning'],\n",
       " ['weakly supervised learning', 'weakly-supervised learning'],\n",
       " ['word embeddings', 'word-embeddings'],\n",
       " ['word embeddings', 'word-embeddings'],\n",
       " ['zero-short learning', 'zero-shot learning'],\n",
       " ['zero-short learning', 'zero-shot learning']]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = []\n",
    "for pair in sim:\n",
    "    if sim[pair] == 1:\n",
    "        l.append(sorted(pair))\n",
    "sorted(l)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((\"nesterov's method\", \"liapunov's method\"), 6)\n",
      "((\"nesterov's method\", 'variational models'), 15)\n",
      "((\"nesterov's method\", 'smoothed gradient'), 16)\n",
      "((\"nesterov's method\", 'generative models'), 13)\n",
      "((\"nesterov's method\", 'recommender systems'), 16)\n",
      "((\"nesterov's method\", 'adversarial methods'), 11)\n",
      "((\"nesterov's method\", 'kernel methods'), 9)\n",
      "(('state equation', 'data selection'), 7)\n",
      "(('state equation', 'set reconstruction'), 10)\n",
      "(('state equation', 'regression tree'), 13)\n",
      "(('state equation', 'sequence to sequence'), 15)\n"
     ]
    }
   ],
   "source": [
    "ix = 0 \n",
    "for item in sim.items():\n",
    "    print(item)\n",
    "    ix += 1\n",
    "    if ix > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cdate': 1538087978124,\n",
      " 'content': {'_bibtex': '@inproceedings{    \\n'\n",
      "                        'anonymous2019g-sgd:,    \\n'\n",
      "                        'title={G-SGD: Optimizing ReLU Neural Networks in its '\n",
      "                        'Positively Scale-Invariant Space},    \\n'\n",
      "                        'author={Anonymous},    \\n'\n",
      "                        'booktitle={Submitted to International Conference on '\n",
      "                        'Learning Representations},    \\n'\n",
      "                        'year={2019},    \\n'\n",
      "                        'url={https://openreview.net/forum?id=SyxfEn09Y7},    \\n'\n",
      "                        'note={under review}    \\n'\n",
      "                        '}',\n",
      "             'abstract': 'It is well known that neural networks with rectified '\n",
      "                         'linear units (ReLU) activation functions are '\n",
      "                         'positively scale-invariant. Conventional algorithms '\n",
      "                         'like stochastic gradient descent optimize the neural '\n",
      "                         'networks in the vector space of weights, which is, '\n",
      "                         'however, not positively scale-invariant. This '\n",
      "                         'mismatch may lead to problems during the '\n",
      "                         'optimization process. Then, a natural question is: '\n",
      "                         '\\\\emph{can we construct a new vector space that is '\n",
      "                         'positively scale-invariant and sufficient to '\n",
      "                         'represent ReLU neural networks so as to better '\n",
      "                         'facilitate the optimization process }? In this '\n",
      "                         'paper, we provide our positive answer to this '\n",
      "                         'question. First, we conduct a formal study on the '\n",
      "                         'positive scaling operators which forms a '\n",
      "                         'transformation group, denoted as $\\\\mathcal{G}$. We '\n",
      "                         'prove that the value of a path (i.e. the product of '\n",
      "                         'the weights along the path) in the neural network is '\n",
      "                         'invariant to positive scaling and the value vector '\n",
      "                         'of all the paths is sufficient to represent the '\n",
      "                         'neural networks under mild conditions. Second, we '\n",
      "                         'show that one can identify some basis paths out of '\n",
      "                         'all the paths and prove that the linear span of '\n",
      "                         'their value vectors (denoted as '\n",
      "                         '$\\\\mathcal{G}$-space) is an invariant space with '\n",
      "                         'lower dimension under the positive scaling group. '\n",
      "                         'Finally, we design stochastic gradient descent '\n",
      "                         'algorithm in $\\\\mathcal{G}$-space (abbreviated as '\n",
      "                         '$\\\\mathcal{G}$-SGD) to optimize the value vector of '\n",
      "                         'the basis paths of neural networks with little extra '\n",
      "                         'cost by leveraging back-propagation. Our experiments '\n",
      "                         'show that $\\\\mathcal{G}$-SGD significantly '\n",
      "                         'outperforms the conventional SGD algorithm in '\n",
      "                         'optimizing ReLU networks on benchmark datasets. ',\n",
      "             'authorids': ['ICLR.cc/2019/Conference/Paper1431/Authors'],\n",
      "             'authors': ['Anonymous'],\n",
      "             'keywords': ['optimization',\n",
      "                          'neural network',\n",
      "                          'irreducible positively scale-invariant space',\n",
      "                          'deep learning'],\n",
      "             'paperhash': 'anonymous|gsgd_optimizing_relu_neural_networks_in_its_positively_scaleinvariant_space',\n",
      "             'pdf': '/pdf/0c16bf3f6705cdad3918614136e9b3c8c85144f5.pdf',\n",
      "             'title': 'G-SGD: Optimizing ReLU Neural Networks in its '\n",
      "                      'Positively Scale-Invariant Space'},\n",
      " 'ddate': None,\n",
      " 'details': {'replyCount': 9},\n",
      " 'forum': 'SyxfEn09Y7',\n",
      " 'id': 'SyxfEn09Y7',\n",
      " 'invitation': 'ICLR.cc/2019/Conference/-/Blind_Submission',\n",
      " 'nonreaders': [],\n",
      " 'number': 1431,\n",
      " 'original': 'BklLeyEROQ',\n",
      " 'readers': ['everyone'],\n",
      " 'referent': None,\n",
      " 'replyto': None,\n",
      " 'signatures': ['ICLR.cc/2019/Conference'],\n",
      " 'tcdate': 1538087978124,\n",
      " 'tmdate': 1542287962892,\n",
      " 'writers': ['ICLR.cc/2019/Conference']}\n"
     ]
    }
   ],
   "source": [
    "pprint(papers[0].to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid.show_grid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings, confidence = ratings_and_confidence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1565, 1565)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings), len(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BklpOo09tQ', ['5', '6', '7'])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ratings.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = c.get_notes(invitation=\"ICLR.cc/2019/Conference/-/Paper.*/Public_Comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paper=  c.get_notes(forum=\"SyVU6s05K7\")\n",
    "ratings_and_confidence(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for n in notes:\n",
    "    print(n.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = add_ratings(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(c.get_notes(id='SyVU6s05K7')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "print(c.get_notes(id='r1g2QHW0h7')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('cro.features') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpl = []\n",
    "for split in text.split('|'):\n",
    "    if '101536' in split :\n",
    "        rpl.append(split.replace('101536', '-104356'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|1&-104356|100070&-104356|100128&-104356|100132&-104356|100145&-104356|100146&-104356|100164&-104356|100258&-104356|100259&-104356|100260&-104356|100282&-104356|100780&-104356|100783&-104356|100928&-104356|100929&-104356|100930&-104356|100931&-104356|100932&-104356|100933&-104356|100934&-104356|100935&-104356|100936&-104356|100937&-104356|100938&-104356|100939&-104356|100975&-104356|101131&-104356|101399&-104356|17&-104356|-104356&23|-104356&31|-104356&34|-104356&415|-104356&417|-104356&418|-104356&491|-104356&523|-104356&529|-104356&530|-104356&598|-104356&86|'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'|'+ '|'.join(rpl[:-1]) + '|'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00a6e2563e784165b19c8af85aacfe87": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.66667,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.66667,\"avg_confidence\":3.33333,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Complement Objective Training\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.66667,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.33333,\"avg_confidence\":4.66667,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.33333,\"avg_confidence\":4.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.25,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.5,\"avg_confidence\":4.5,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 8]\",\"confidence\":\"[5, 4]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":6.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[8, 5]\",\"confidence\":\"[4, 4]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Learning Entropic Wasserstein Embeddings\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Embedding\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\",\"ratings\":\"[7, 7, 3]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"sgd\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\",\"ratings\":\"[6, 6, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Invariance and Inverse Stability under ReLU\",\"avg_rating\":6.5,\"avg_confidence\":3.5,\"topic\":\"deep neural networks\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\",\"ratings\":\"[6, 7]\",\"confidence\":\"[4, 3]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"avg_rating\":6.0,\"avg_confidence\":4.5,\"topic\":\"VAE\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\",\"ratings\":\"[4, 8]\",\"confidence\":\"[4, 5]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep learning\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"avg_rating\":4.66667,\"avg_confidence\":4.0,\"topic\":\"GAN\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"avg_rating\":6.33333,\"avg_confidence\":3.33333,\"topic\":\"dialogue\",\"tldr\":\"\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Reward Constrained Policy Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\",\"ratings\":\"[6, 7, 5]\",\"confidence\":\"[4, 2, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.66667,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"avg_rating\":6.0,\"avg_confidence\":3.66667,\"topic\":\"rotation equivariance\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\",\"ratings\":\"[7, 3, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Graph\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Adaptive Neural Trees\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"neural networks\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"Phrase-Based Attentions\",\"avg_rating\":5.0,\"avg_confidence\":4.66667,\"topic\":\"neural machine translation\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Deep Layers as Stochastic Solvers\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep networks\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[4, 5, 1]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Sparse rewards\",\"tldr\":\"\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"avg_rating\":6.33333,\"avg_confidence\":4.66667,\"topic\":\"domain adaptation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"crowdsourcing\",\"tldr\":\"\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"unsupervised learning\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\",\"ratings\":\"[5, 3, 9]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"imitation learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[8, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"relation representations\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"avg_rating\":5.33333,\"avg_confidence\":4.33333,\"topic\":\"Empirical Bayes\",\"tldr\":\"\",\"ratings\":\"[6, 3, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Feature-Wise Bias Amplification\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"bias\",\"tldr\":\"\",\"ratings\":\"[6, 7, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"avg_rating\":3.66667,\"avg_confidence\":4.0,\"topic\":\"Neural Response Generation\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\",\"ratings\":\"[3, 7, 1]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Sorting out Lipschitz function approximation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"agent evaluation\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Interpretable Continual Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.0,\"topic\":\"Interpretability\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \",\"ratings\":\"[5, 6]\",\"confidence\":\"[3, 3]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"Implicit Autoencoders\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Unsupervised Learning\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\",\"ratings\":\"[2, 7, 6]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"avg_rating\":4.33333,\"avg_confidence\":4.0,\"topic\":\"Hierarchical reinforcement learning\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_rating\":3.66667,\"avg_confidence\":3.33333,\"topic\":\"visualization\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"ratings\":\"[4, 3, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"avg_rating\":5.66667,\"avg_confidence\":4.33333,\"topic\":\"cross-lingual transfer learning\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"word embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"VAE\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"preconditioner\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\",\"ratings\":\"[8, 4, 7]\",\"confidence\":\"[5, 5, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Model quantization\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\",\"ratings\":\"[8, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"avg_rating\":5.5,\"avg_confidence\":4.5,\"topic\":\"neural program repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\",\"ratings\":\"[6, 5]\",\"confidence\":\"[4, 5]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"unsupervised learning\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \",\"ratings\":\"[7, 5, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"positive-unlabeled learning\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 3, 3]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"DEEP GRAPH TRANSLATION\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[2, 4, 4]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "dc249ad1-8c6b-4e95-8833-ceb200dec529",
       "layout": "IPY_MODEL_68b181c55f354f5fb88357ea53a4360b",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "021c2a64c34f4e50a8ce37fbfc357115": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0284c31e50294b1783bf88e7f332c9c2": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"avg_confidence\":4.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"avg_confidence\":3.33333,\"avg_rating\":5.66667,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"avg_confidence\":3.66667,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"avg_confidence\":2.66667,\"avg_rating\":7.0,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"avg_confidence\":4.0,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"avg_confidence\":2.0,\"avg_rating\":6.66667,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"avg_confidence\":4.66667,\"avg_rating\":5.33333,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"avg_confidence\":3.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"avg_confidence\":4.33333,\"avg_rating\":4.33333,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"avg_confidence\":3.25,\"avg_rating\":4.0,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"avg_confidence\":4.5,\"avg_rating\":6.5,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"avg_confidence\":4.0,\"avg_rating\":7.33333,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"avg_confidence\":4.33333,\"avg_rating\":5.0,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"avg_confidence\":3.66667,\"avg_rating\":4.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"avg_confidence\":4.0,\"avg_rating\":6.5,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"avg_confidence\":3.0,\"avg_rating\":5.0,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"avg_confidence\":3.5,\"avg_rating\":5.5,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"avg_confidence\":4.66667,\"avg_rating\":7.66667,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"avg_confidence\":3.0,\"avg_rating\":3.5,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"avg_confidence\":3.5,\"avg_rating\":6.5,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"avg_confidence\":4.5,\"avg_rating\":6.0,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"avg_confidence\":4.0,\"avg_rating\":4.66667,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"avg_confidence\":3.33333,\"avg_rating\":6.33333,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"avg_confidence\":3.0,\"avg_rating\":6.0,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"avg_confidence\":4.66667,\"avg_rating\":7.0,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"avg_confidence\":3.66667,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"avg_confidence\":4.66667,\"avg_rating\":5.0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"avg_confidence\":4.66667,\"avg_rating\":6.33333,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"avg_confidence\":4.33333,\"avg_rating\":5.33333,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"avg_confidence\":4.0,\"avg_rating\":3.66667,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"avg_confidence\":3.0,\"avg_rating\":6.0,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"avg_confidence\":3.0,\"avg_rating\":5.5,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"avg_confidence\":4.0,\"avg_rating\":4.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"avg_confidence\":3.33333,\"avg_rating\":3.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"avg_confidence\":4.33333,\"avg_rating\":5.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"avg_confidence\":4.0,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"avg_confidence\":4.0,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"avg_confidence\":4.5,\"avg_rating\":5.5,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "a6301dbf-7617-4ece-a838-5cd5d15da8aa",
       "layout": "IPY_MODEL_f2937727cad843049f7d4e8f4cdda09f",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "03808918b6ac41e8b475040951e7af94": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":1017,\"qgrid_unfiltered_index\":1017,\"title\":\"Exploration by random distillation\",\"avg_rating\":8.7,\"avg_confidence\":4.3,\"topic\":\"reinforcement learning\",\"tldr\":\"A simple exploration bonus is introduced and achieves state of the art performance in 3 hard exploration Atari games.\",\"ratings\":\"[9, 10, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lJJnR5Ym\"},{\"Index\":648,\"qgrid_unfiltered_index\":648,\"title\":\"Benchmarking Neural Network Robustness to Common Corruptions and Perturbations\",\"avg_rating\":8.3,\"avg_confidence\":4.0,\"topic\":\"robustness\",\"tldr\":\"We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness\",\"ratings\":\"[7, 9, 9]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJz6tiCqYm\"},{\"Index\":707,\"qgrid_unfiltered_index\":707,\"title\":\"Large Scale GAN Training for High Fidelity Natural Image Synthesis\",\"avg_rating\":8.3,\"avg_confidence\":3.7,\"topic\":\"GANs\",\"tldr\":\"GANs benefit from scaling up.\",\"ratings\":\"[7, 8, 10]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1xsqj09Fm\"},{\"Index\":1304,\"qgrid_unfiltered_index\":1304,\"title\":\"ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"sparse recovery\",\"tldr\":\"\",\"ratings\":\"[10, 6, 8]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1lnzn0ctQ\"},{\"Index\":878,\"qgrid_unfiltered_index\":878,\"title\":\"GENERATING HIGH FIDELITY IMAGES WITH SUBSCALE PIXEL NETWORKS AND MULTIDIMENSIONAL UPSCALING\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"We show that autoregressive models can generate high fidelity images. \",\"ratings\":\"[10, 7, 7]\",\"confidence\":\"[5, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HylzTiC5Km\"},{\"Index\":717,\"qgrid_unfiltered_index\":717,\"title\":\"Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"Deep Learning\",\"tldr\":\"We introduce a new inductive bias that integrates tree structures in recurrent neural networks.\",\"ratings\":\"[9, 7, 8]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1l6qiR5F7\"},{\"Index\":950,\"qgrid_unfiltered_index\":950,\"title\":\"Slimmable Neural Networks\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"Slimmable neural networks\",\"tldr\":\"We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1gMCsAqY7\"},{\"Index\":1115,\"qgrid_unfiltered_index\":1115,\"title\":\"Temporal Difference Variational Auto-Encoder\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"generative models\",\"tldr\":\"Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1x4ghC9tQ\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\"},{\"Index\":1442,\"qgrid_unfiltered_index\":1442,\"title\":\"Posterior Attention Models for Sequence to Sequence Learning\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"posterior inference\",\"tldr\":\"Computing attention based on posterior distribution leads to more meaningful attention and better performance\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkltNhC9FX\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\"},{\"Index\":636,\"qgrid_unfiltered_index\":636,\"title\":\"Sparse Dictionary Learning by Dynamical Neural Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[6, 9, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1gstsCqt7\"},{\"Index\":1495,\"qgrid_unfiltered_index\":1495,\"title\":\"Composing Complex Skills by Learning Transition Policies with Proximity Reward Induction\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"reinforcement learning\",\"tldr\":\"Transition policies enable agents to execute learned skills smoothly to perform complex tasks.\",\"ratings\":\"[7, 9, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygrBhC5tQ\"},{\"Index\":1330,\"qgrid_unfiltered_index\":1330,\"title\":\"Adaptive Input Representations for Neural Language Modeling\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Neural language modeling\",\"tldr\":\"Variable capacity input word embeddings and SOTA on WikiText-103, Billion Word benchmarks.\",\"ratings\":\"[7, 8, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxZX20qFQ\"},{\"Index\":1454,\"qgrid_unfiltered_index\":1454,\"title\":\"A Variational Inequality Perspective on Generative Adversarial Networks\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"optimization\",\"tldr\":\"We cast GANs in the variational inequality framework and import techniques from this literature to optimize GANs better; we give algorithmic extensions and empirically test their performance for training GANs.\",\"ratings\":\"[8, 8, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1laEnA5Ym\"},{\"Index\":450,\"qgrid_unfiltered_index\":450,\"title\":\"Identifying and Controlling Important Neurons in Neural Machine Translation\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"neural machine translation\",\"tldr\":\"Unsupervised methods for finding, analyzing, and controlling important neurons in NMT\",\"ratings\":\"[7, 10, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1z-PsR5KX\"},{\"Index\":276,\"qgrid_unfiltered_index\":276,\"title\":\"ON RANDOM DEEP AUTOENCODERS: EXACT ASYMPTOTIC ANALYSIS, PHASE TRANSITIONS, AND IMPLICATIONS TO TRAINING\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Random Deep Autoencoders\",\"tldr\":\"We study the behavior of weight-tied multilayer vanilla autoencoders under the assumption of random weights. Via an exact characterization in the limit of large dimensions, our analysis reveals interesting phase transition phenomena.\",\"ratings\":\"[9, 6, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx54i05tX\"},{\"Index\":255,\"qgrid_unfiltered_index\":255,\"title\":\"Smoothing the Geometry of Probabilistic Box Embeddings\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"embeddings\",\"tldr\":\"Improve hierarchical embedding models using kernel smoothing\",\"ratings\":\"[8, 8, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xSNiRcF7\"},{\"Index\":661,\"qgrid_unfiltered_index\":661,\"title\":\"KnockoffGAN: Generating Knockoffs for Feature Selection using Generative Adversarial Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Knockoff model\",\"tldr\":\"\",\"ratings\":\"[6, 10, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByeZ5jC5YQ\"},{\"Index\":614,\"qgrid_unfiltered_index\":614,\"title\":\"Critical Learning Periods in Deep Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.3,\"topic\":\"Critical Period\",\"tldr\":\"Sensory deficits in early training phases can lead to irreversible performance loss in both artificial and neuronal networks, suggesting information phenomena as the common cause, and point to the importance of the initial transient and forgetting.\",\"ratings\":\"[9, 8, 6]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkeStsCcKQ\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\"},{\"Index\":1154,\"qgrid_unfiltered_index\":1154,\"title\":\"Pay Less Attention with Lightweight and Dynamic Convolutions\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Deep learning\",\"tldr\":\"Dynamic lightweight convolutions are competitive to self-attention on language tasks.\",\"ratings\":\"[8, 7, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkVhlh09tX\"},{\"Index\":778,\"qgrid_unfiltered_index\":778,\"title\":\"Learning Robust Representations by Projecting Superficial Statistics Out\",\"avg_rating\":7.7,\"avg_confidence\":3.7,\"topic\":\"domain generalization\",\"tldr\":\"Building on previous work on domain generalization, we hope to produce a classifier that will generalize to previously unseen domains, even when domain identifiers are not available during training.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJEjjoR9K7\"},{\"Index\":353,\"qgrid_unfiltered_index\":353,\"title\":\"Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware\",\"avg_rating\":7.7,\"avg_confidence\":3.0,\"topic\":\"Trusted hardware\",\"tldr\":\"We accelerate secure DNN inference in trusted execution environments (by a factor 4x-20x) by selectively outsourcing the computation of linear layers to a faster yet untrusted co-processor.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJVorjCcKQ\"},{\"Index\":762,\"qgrid_unfiltered_index\":762,\"title\":\"Learning Unsupervised Learning Rules\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"Meta-learning\",\"tldr\":\"We learn an unsupervised learning algorithm that produces useful representations from a set of supervised tasks. At test-time, we apply this algorithm to new tasks without any supervision and show performance comparable to a VAE.\",\"ratings\":\"[8, 7, 8]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkNDsiC9KQ\"},{\"Index\":1239,\"qgrid_unfiltered_index\":1239,\"title\":\"Supervised Community Detection with Line Graph Neural Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"community detection\",\"tldr\":\"We propose a novel graph neural network architecture based on the non-backtracking operator defined over edge adjacencies and demonstrate its effectiveness on community detection tasks on graphs.\",\"ratings\":\"[6, 9, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1g0Z3A9Fm\"},{\"Index\":348,\"qgrid_unfiltered_index\":348,\"title\":\"Diffusion Scattering Transforms on Graphs\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"graph neural networks\",\"tldr\":\"Stability of scattering transform representations of graph data to deformations of the underlying graph support.\",\"ratings\":\"[9, 6]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygqBiRcFQ\"},{\"Index\":662,\"qgrid_unfiltered_index\":662,\"title\":\"On the Minimal Supervision for Training Any Binary Classifier from Only Unlabeled Data\",\"avg_rating\":7.5,\"avg_confidence\":3.5,\"topic\":\"learning from only unlabeled data\",\"tldr\":\"Three class priors are all you need to train deep models from only U data, while any two should not be enough.\",\"ratings\":\"[8, 7]\",\"confidence\":\"[3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1xWcj0qYm\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\"},{\"Index\":1252,\"qgrid_unfiltered_index\":1252,\"title\":\"Towards Metamerism via Foveated Style Transfer\",\"avg_rating\":7.3,\"avg_confidence\":4.3,\"topic\":\"Metamerism\",\"tldr\":\"We introduce a novel feed-forward framework to generate visual metamers\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJzbG20cFQ\"},{\"Index\":1540,\"qgrid_unfiltered_index\":1540,\"title\":\"Visualizing and Understanding Generative Adversarial Networks\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"GANs\",\"tldr\":\"GAN representations are examined in detail, and sets of representation units are found that control the generation of semantic concepts in the output.\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hyg_X2C5FX\"},{\"Index\":957,\"qgrid_unfiltered_index\":957,\"title\":\"ProMP: Proximal Meta-Policy Search\",\"avg_rating\":7.3,\"avg_confidence\":3.0,\"topic\":\"Meta-Reinforcement Learning\",\"tldr\":\"A novel and theoretically grounded meta-reinforcement learning algorithm\",\"ratings\":\"[6, 7, 9]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxXCi0qFX\"},{\"Index\":548,\"qgrid_unfiltered_index\":548,\"title\":\"Evaluating Robustness of Neural Networks with Mixed Integer Programming\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"verification\",\"tldr\":\"We efficiently verify the robustness of deep neural models with over 100,000 ReLUs, certifying more samples than the state-of-the-art and finding more adversarial examples than a strong first-order attack.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[5, 5, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyGIdiRqtm\"},{\"Index\":997,\"qgrid_unfiltered_index\":997,\"title\":\"Efficient Training on Very Large Corpora via Gramian Estimation\",\"avg_rating\":7.3,\"avg_confidence\":2.7,\"topic\":\"similarity learning\",\"tldr\":\"We develop efficient methods to train neural embedding models with a dot-product structure, by reformulating the objective function in terms of generalized Gram matrices, and maintaining estimates of those matrices.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[4, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke20iA9Y7\"},{\"Index\":1509,\"qgrid_unfiltered_index\":1509,\"title\":\"Label super-resolution networks\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"weakly supervised segmentation\",\"tldr\":\"Super-resolving coarse labels into pixel-level labels, applied to aerial imagery and medical scans.\",\"ratings\":\"[7, 6, 9]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxwShA9Ym\"},{\"Index\":1253,\"qgrid_unfiltered_index\":1253,\"title\":\"Kernel Change-point Detection with Auxiliary Deep Generative Models\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"deep kernel learning\",\"tldr\":\"In this paper, we propose KL-CPD, a novel kernel learning framework for time series CPD that optimizes a lower bound of test power via an auxiliary generative model as a surrogate to the abnormal distribution. \",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1GbfhRqF7\"},{\"Index\":1204,\"qgrid_unfiltered_index\":1204,\"title\":\"Biologically-Plausible Learning Algorithms Can Scale to Large Datasets\",\"avg_rating\":7.3,\"avg_confidence\":4.3,\"topic\":\"biologically plausible learning algorithm\",\"tldr\":\"Biologically plausible learning algorithms, particularly sign-symmetry, works well on ImageNet\",\"ratings\":\"[9, 9, 4]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygvZ209F7\"},{\"Index\":861,\"qgrid_unfiltered_index\":861,\"title\":\"Diversity is All You Need: Learning Skills without a Reward Function\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"reinforcement learning\",\"tldr\":\"We propose an algorithm for learning useful skills without a reward function, and show how these skills can be used to solve downstream tasks.\",\"ratings\":\"[8, 7, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJx63jRqFm\"},{\"Index\":478,\"qgrid_unfiltered_index\":478,\"title\":\"Large-Scale Study of Curiosity-Driven Learning\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"exploration\",\"tldr\":\"An agent trained only with curiosity, and no extrinsic reward, does surprisingly well on 54 popular environments, including the suite of Atari games, Mario etc.\",\"ratings\":\"[6, 9, 7]\",\"confidence\":\"[4, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJNwDjAqYX\"},{\"Index\":372,\"qgrid_unfiltered_index\":372,\"title\":\"Differentiable Learning-to-Normalize via Switchable Normalization\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"normalization\",\"tldr\":\"\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryggIs0cYQ\"},{\"Index\":1094,\"qgrid_unfiltered_index\":1094,\"title\":\"Gradient descent aligns the layers of deep linear networks\",\"avg_rating\":7.3,\"avg_confidence\":4.3,\"topic\":\"implicit regularization\",\"tldr\":\"\",\"ratings\":\"[7, 9, 6]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJflg30qKX\"},{\"Index\":124,\"qgrid_unfiltered_index\":124,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylV-2C9KQ\"},{\"Index\":625,\"qgrid_unfiltered_index\":625,\"title\":\"Small nonlinearities in activation functions create bad local minima in neural networks\",\"avg_rating\":7.3,\"avg_confidence\":3.3,\"topic\":\"spurious local minima\",\"tldr\":\"We constructively prove that even the slightest nonlinear activation functions introduce spurious local minima, for general datasets and activation functions.\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke_YiRct7\"},{\"Index\":663,\"qgrid_unfiltered_index\":663,\"title\":\"Approximability of Discriminators Implies Diversity in GANs\",\"avg_rating\":7.3,\"avg_confidence\":2.7,\"topic\":\"Theory\",\"tldr\":\"GANs can in principle learn distributions sample-efficiently, if the discriminator class is compact and has strong distinguishing power against the particular generator class.\",\"ratings\":\"[8, 7, 7]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJfW5oA5KQ\"},{\"Index\":1286,\"qgrid_unfiltered_index\":1286,\"title\":\"LanczosNet: Multi-Scale Deep Graph Convolutional Networks\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedznAqKQ\"},{\"Index\":1268,\"qgrid_unfiltered_index\":1268,\"title\":\"Improving the Differentiable Neural Computer Through Memory Masking, De-allocation, and Link Distribution Sharpness Control\",\"avg_rating\":7.0,\"avg_confidence\":5.0,\"topic\":\"rnn\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyGEM3C9KQ\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\"},{\"Index\":1280,\"qgrid_unfiltered_index\":1280,\"title\":\"Lagging Inference Networks and Posterior Collapse in Variational Autoencoders\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"variational autoencoders\",\"tldr\":\"To address posterior collapse in VAEs, we propose a simple yet effective training algorithm that aggressively optimizes inference network with more updates\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylDfnCqF7\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\"},{\"Index\":100,\"qgrid_unfiltered_index\":100,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylCrnCcFX\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\"},{\"Index\":1232,\"qgrid_unfiltered_index\":1232,\"title\":\"Learning Neural PDE Solvers with Convergence Guarantees\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Partial differential equation\",\"tldr\":\"We learn a fast neural solver for PDEs that has convergence guarantees.\",\"ratings\":\"[7, 8, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rklaWn0qK7\"},{\"Index\":1337,\"qgrid_unfiltered_index\":1337,\"title\":\"Learning to Navigate the Web\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"navigating web pages\",\"tldr\":\"We train reinforcement learning policies using reward augmentation, curriculum learning, and meta-learning  to successfully navigate web pages.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJemQ209FQ\"},{\"Index\":102,\"qgrid_unfiltered_index\":102,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkxjYoCqKX\"},{\"Index\":1313,\"qgrid_unfiltered_index\":1313,\"title\":\"Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based RL\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"meta-learning\",\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxAfnA5tm\"},{\"Index\":383,\"qgrid_unfiltered_index\":383,\"title\":\"An analytic theory of generalization dynamics and transfer learning in deep linear networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Generalization\",\"tldr\":\"We provide many insights into neural network generalization from the theoretically tractable linear case.\",\"ratings\":\"[8, 7, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryfMLoCqtQ\"},{\"Index\":143,\"qgrid_unfiltered_index\":143,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJe9rh0cFX\"},{\"Index\":921,\"qgrid_unfiltered_index\":921,\"title\":\"How Powerful are Graph Neural Networks?\",\"avg_rating\":7.0,\"avg_confidence\":5.0,\"topic\":\"graph neural networks\",\"tldr\":\"We develop theoretical foundations for expressive power of GNNs and design a provably most powerful GNN.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryGs6iA5Km\"},{\"Index\":345,\"qgrid_unfiltered_index\":345,\"title\":\"DARTS: Differentiable Architecture Search\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"deep learning\",\"tldr\":\"We propose a differentiable architecture search algorithm for both convolutional and recurrent networks, achieving competitive performance with the state of the art using orders of magnitude less computation resources.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eYHoC5FX\"},{\"Index\":1119,\"qgrid_unfiltered_index\":1119,\"title\":\"What do you learn from context? Probing for sentence structure in contextualized word representations\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"natural language processing\",\"tldr\":\"We probe for sentence structure in ELMo and related contextual embedding models. We find existing models efficiently encode syntax and show evidence of long-range dependencies, but only offer small improvements on semantic tasks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJzSgnRcKX\"},{\"Index\":197,\"qgrid_unfiltered_index\":197,\"title\":\"Learning a SAT Solver from Single-Bit Supervision\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"sat\",\"tldr\":\"We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMC_iA5tm\"},{\"Index\":242,\"qgrid_unfiltered_index\":242,\"title\":\"Auxiliary Variational MCMC\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"MCMC\",\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1NJqsRctX\"},{\"Index\":304,\"qgrid_unfiltered_index\":304,\"title\":\"Deep, Skinny Neural Networks are not Universal Approximators\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"neural network\",\"tldr\":\"This paper proves that skinny neural networks cannot approximate certain functions, no matter how deep they are.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryGgSsAcFQ\"},{\"Index\":1108,\"qgrid_unfiltered_index\":1108,\"title\":\"Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word Vectors\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"word vectors\",\"tldr\":\"Max-pooled word vectors with fuzzy Jaccard set similarity are an extremely competitive baseline for semantic similarity; we propose a simple dynamic variant that performs even better.\",\"ratings\":\"[8, 8, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxXg2C5FX\"},{\"Index\":1103,\"qgrid_unfiltered_index\":1103,\"title\":\"The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"Neuro-Symbolic Representations\",\"tldr\":\"We present a Neuro-Symbolic Concept Learner to learn visual concepts, words, and semantic parsing of sentences without explicit annotations for any of them. \",\"ratings\":\"[7, 5, 9]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgMlhRctm\"},{\"Index\":1530,\"qgrid_unfiltered_index\":1530,\"title\":\"Global-to-local Memory Pointer Networks for Task-Oriented Dialogue\",\"avg_rating\":7.0,\"avg_confidence\":2.3,\"topic\":\"pointer networks\",\"tldr\":\"We propose a global memory encoder and a global memory decoder that share an external knowledge to strengthen task-oriented dialogue generation via sketch responses and pointer networks. \",\"ratings\":\"[8, 8, 5]\",\"confidence\":\"[2, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryxnHhRqFm\"},{\"Index\":1414,\"qgrid_unfiltered_index\":1414,\"title\":\"GANSynth: Adversarial Neural Audio Synthesis\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"GAN\",\"tldr\":\"High-quality audio synthesis with GANs\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xQVn09FX\"},{\"Index\":1138,\"qgrid_unfiltered_index\":1138,\"title\":\"Learning Implicitly Recurrent CNNs Through Parameter Sharing\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We propose a method that enables CNN folding to create recurrent connections\",\"ratings\":\"[8, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgYxn09Fm\"},{\"Index\":110,\"qgrid_unfiltered_index\":110,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.7,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syx72jC9tm\"},{\"Index\":999,\"qgrid_unfiltered_index\":999,\"title\":\"Unsupervised Domain Adaptation for Distance Metric Learning\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"domain adaptation\",\"tldr\":\"A new theory of unsupervised domain adaptation for distance metric learning and its application to face recognition across diverse ethnicity variations.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BklhAj09K7\"},{\"Index\":113,\"qgrid_unfiltered_index\":113,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkxStoC5F7\"},{\"Index\":1484,\"qgrid_unfiltered_index\":1484,\"title\":\"Learning to Screen for Fast Softmax  Inference on Large Vocabulary Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"fast inference\",\"tldr\":\"\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByeMB3Act7\"},{\"Index\":527,\"qgrid_unfiltered_index\":527,\"title\":\"Near-Optimal Representation Learning for Hierarchical Reinforcement Learning\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"representation hierarchy reinforcement learning\",\"tldr\":\"We translate a bound on sub-optimality of representations to a practical training objective in the context of hierarchical reinforcement learning.\",\"ratings\":\"[6, 6, 9]\",\"confidence\":\"[3, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1emus0qF7\"},{\"Index\":1020,\"qgrid_unfiltered_index\":1020,\"title\":\"Scalable Reversible Generative Models with Free-form Continuous Dynamics\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"generative models\",\"tldr\":\"We use continuous time dynamics to define a generative model with exact likelihoods and efficient sampling that is parameterized by unrestricted neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxgknCcK7\"},{\"Index\":1559,\"qgrid_unfiltered_index\":1559,\"title\":\"Learning sparse relational transition models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deictic reference\",\"tldr\":\"A new approach that learns a representation for describing transition models in complex uncertaindomains using relational rules. \",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJxsV2R5FQ\"},{\"Index\":642,\"qgrid_unfiltered_index\":642,\"title\":\"Greedy Attack and Gumbel Attack: Generating Adversarial Examples for Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"Adversarial Examples\",\"tldr\":\"We develop two methods for generating adversarial examples on discrete data under a probabilistic framework.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[4, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByghKiC5YX\"},{\"Index\":665,\"qgrid_unfiltered_index\":665,\"title\":\"SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"neural network pruning\",\"tldr\":\"We present a new approach, SNIP, that is simple, versatile and interpretable; it prunes irrelevant connections for a given task at single-shot prior to training and is applicable to a variety of neural network models without modifications.\",\"ratings\":\"[6, 6, 9]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1VZqjAcYX\"},{\"Index\":666,\"qgrid_unfiltered_index\":666,\"title\":\"Deep Graph Infomax\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Unsupervised Learning\",\"tldr\":\"A new method for unsupervised representation learning on graphs, relying on maximizing mutual information between local and global representations in a graph. State-of-the-art results, competitive with supervised learning.\",\"ratings\":\"[7, 9, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rklz9iAcKQ\"},{\"Index\":706,\"qgrid_unfiltered_index\":706,\"title\":\"Riemannian Adaptive Optimization Methods\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"Riemannian optimization\",\"tldr\":\"Adapting Adam, Amsgrad, Adagrad to Riemannian manifolds. \",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eiqi09K7\"},{\"Index\":1063,\"qgrid_unfiltered_index\":1063,\"title\":\"ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"text-to-speech\",\"tldr\":\"\",\"ratings\":\"[9, 5, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklY120cYm\"},{\"Index\":1025,\"qgrid_unfiltered_index\":1025,\"title\":\"Feature Intertwiners\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"feature learning\",\"tldr\":\"A feature intertwiner module to leverage features from one accurate set to help the learning of another less reliable set.\",\"ratings\":\"[7, 5, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxZJn05YX\"},{\"Index\":768,\"qgrid_unfiltered_index\":768,\"title\":\"How Important is a Neuron\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"attribution\",\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylKoo0cKm\"},{\"Index\":929,\"qgrid_unfiltered_index\":929,\"title\":\"The Comparative Power of ReLU Networks and Polynomial Kernels in the Presence of Sparse Latent Structure\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"theory\",\"tldr\":\"Beyond-worst-case analysis of the representational power of  ReLU nets & polynomial kernels  -- in particular in the presence of sparse latent structure.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTTjA9tX\"},{\"Index\":794,\"qgrid_unfiltered_index\":794,\"title\":\"Neural network gradient-based learning of black-box function interfaces\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"neural networks\",\"tldr\":\"Training DNNs to interface w\\\\ black box functions w\\\\o intermediate labels by using an estimator sub-network that can be replaced with the black box after training\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1e13s05YX\"},{\"Index\":1077,\"qgrid_unfiltered_index\":1077,\"title\":\"Local SGD Converges Fast and Communicates Little\",\"avg_rating\":7.0,\"avg_confidence\":4.7,\"topic\":\"optimization\",\"tldr\":\"We prove that parallel local SGD achieves linear speedup with much lesser communication than parallel mini-batch SGD.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1g2JnRcFX\"},{\"Index\":1180,\"qgrid_unfiltered_index\":1180,\"title\":\"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"Neural networks\",\"tldr\":\"Feedforward neural networks that can have weights pruned after training could have had the same weights pruned before training\",\"ratings\":\"[5, 8, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl-b3RcF7\"},{\"Index\":748,\"qgrid_unfiltered_index\":748,\"title\":\"Deep Learning 3D Shapes Using Alt-az Anisotropic 2-Sphere Convolution\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"Spherical Convolution\",\"tldr\":\"A method for applying deep learning to 3D surfaces using their spherical descriptors and alt-az anisotropic convolution on 2-sphere.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[3, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkeSiiA5Fm\"},{\"Index\":361,\"qgrid_unfiltered_index\":361,\"title\":\"ADVERSARIAL DOMAIN ADAPTATION FOR STABLE BRAIN-MACHINE INTERFACES\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"Brain-Machine Interfaces\",\"tldr\":\"We implement an adversarial domain adaptation network to stabilize a fixed Brain-Machine Interface against gradual changes in the recorded neural signals.\",\"ratings\":\"[9, 5, 7]\",\"confidence\":\"[4, 3, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hyx6Bi0qYm\"},{\"Index\":949,\"qgrid_unfiltered_index\":949,\"title\":\"Learning Self-Imitating Diverse Policies\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Reinforcement-learning\",\"tldr\":\"Policy optimization by using past good rollouts from the agent; learning shaped rewards via divergence minimization; SVPG with JS-kernel for population-based exploration.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxzRsR9Y7\"},{\"Index\":846,\"qgrid_unfiltered_index\":846,\"title\":\"The effects of neural resource constraints on early visual representations \",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"visual system\",\"tldr\":\"We reproduced neural representations found in biological visual systems by simulating their neural resource constraints in a deep convolutional model.\",\"ratings\":\"[5, 8, 8]\",\"confidence\":\"[5, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xq3oR5tQ\"},{\"Index\":814,\"qgrid_unfiltered_index\":814,\"title\":\"Wizard of Wikipedia: Knowledge-Powered Conversational Agents\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"dialogue\",\"tldr\":\"We build knowledgeable conversational agents by conditioning on Wikipedia + a new supervised task.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1l73iRqKm\"},{\"Index\":541,\"qgrid_unfiltered_index\":541,\"title\":\"Towards the first adversarially robust neural network model on MNIST\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"adversarial examples\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1EHOsC9tX\"},{\"Index\":509,\"qgrid_unfiltered_index\":509,\"title\":\"EMI: Exploration with Mutual Information Maximizing State and Action Embeddings\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[6, 7, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hylyui09tm\"},{\"Index\":562,\"qgrid_unfiltered_index\":562,\"title\":\"Off-Policy Evaluation and Learning from Logged Bandit Feedback: Error Reduction via Surrogate Policy\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"Causal inference\",\"tldr\":\"\",\"ratings\":\"[6, 8, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklKui0ct7\"},{\"Index\":569,\"qgrid_unfiltered_index\":569,\"title\":\"Meta-Learning For Stochastic Gradient MCMC\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"Meta Learning\",\"tldr\":\"This paper proposes a method to automate the design of stochastic gradient MCMC proposal using meta learning approach. \",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkeoOo09YX\"},{\"Index\":611,\"qgrid_unfiltered_index\":611,\"title\":\"Trellis Networks for Sequence Modeling\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"sequence modeling\",\"tldr\":\"Trellis networks are a new sequence modeling architecture that bridges recurrent and convolutional models and sets a new state of the art on word- and character-level language modeling.\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyeVtoRqtQ\"},{\"Index\":1359,\"qgrid_unfiltered_index\":1359,\"title\":\"A Mean Field Theory of Batch Normalization\",\"avg_rating\":6.7,\"avg_confidence\":2.3,\"topic\":\"theory\",\"tldr\":\"Batch normalization causes exploding gradients in vanilla feedforward networks.\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 1, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyMDXnCcF7\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": false,
       "_sort_field": "avg_rating",
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "8a23b896-52eb-4e51-b6d4-6e282dbbf02d",
       "layout": "IPY_MODEL_0394a3de581349bd9d423d6e9629dcf2",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "0394a3de581349bd9d423d6e9629dcf2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0773b82c026945628f00371177cd6731": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0eea5c828290485e9e035ea8d371b82c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "12cbd5b2f2c74993a3303a2e2b276b89": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "75939fe0-d9c4-4e73-a4a2-9f33c529ee99",
       "layout": "IPY_MODEL_fb05712c30f0424da3683bff032f0f96",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "13a391b142f948da9933d0e6c233bb7c": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "autoHeight": true,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "d159a497-fec6-4860-a6fa-2f0ed8666193",
       "layout": "IPY_MODEL_bf4f9216d3374e438b0e1761b01dec2c",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "13da80388a6941cca9a2eff12e254ffb": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":944,\"qgrid_unfiltered_index\":944,\"avg_confidence\":5.0,\"avg_rating\":1.66667,\"confidence\":\"[5, 5, 5]\",\"ratings\":\"[2, 2, 1]\",\"title\":\"Hierarchical Bayesian Modeling for Clustering Sparse Sequences in the Context of Group Profiling\",\"tldr\":\"Hierarchical Bayesian Modeling for Clustering Sparse Sequences ; user group modeling using behavioral data\"},{\"index\":384,\"qgrid_unfiltered_index\":384,\"avg_confidence\":5.0,\"avg_rating\":2.0,\"confidence\":\"[5, 5, 5, 5]\",\"ratings\":\"[1, 2, 1, 4]\",\"title\":\"Object detection deep learning networks for Optical Character Recognition\",\"tldr\":\"Yolo \\/ RCNN neural network for object detection adapted to the task of OCR\"},{\"index\":250,\"qgrid_unfiltered_index\":250,\"avg_confidence\":3.25,\"avg_rating\":2.25,\"confidence\":\"[4, 3, 3, 3]\",\"ratings\":\"[2, 3, 2, 2]\",\"title\":\"A Synaptic Neural Network and Synapse Learning\",\"tldr\":\"A synaptic neural network with synapse graph and learning that has the feature of Bose-Einstein distribution in surprisal space.  \"},{\"index\":522,\"qgrid_unfiltered_index\":522,\"avg_confidence\":3.33333,\"avg_rating\":2.33333,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[3, 3, 1]\",\"title\":\"Psychophysical vs. learnt texture representations in novelty detection\",\"tldr\":\"Comparison of psychophysical and CNN-encoded  texture representations in a one-class neural network novelty detection application.\"},{\"index\":1379,\"qgrid_unfiltered_index\":1379,\"avg_confidence\":3.33333,\"avg_rating\":2.33333,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[3, 2, 2]\",\"title\":\"Hierarchical Deep Reinforcement Learning Agent with Counter Self-play  on Competitive Games \",\"tldr\":\"We develop Hierarchical Agent with Self-play (HASP), a learning approach for obtaining hierarchically structured policies that can achieve high performance than conventional self-play on competitive real-time strategic games.\"},{\"index\":1289,\"qgrid_unfiltered_index\":1289,\"avg_confidence\":4.66667,\"avg_rating\":2.33333,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[1, 1, 5]\",\"title\":\"Advanced Neuroevolution: A gradient-free algorithm to train Deep Neural Networks\",\"tldr\":\"A new algorithm to train deep neural networks. Tested on optimization functions and MNIST.\"},{\"index\":557,\"qgrid_unfiltered_index\":557,\"avg_confidence\":4.66667,\"avg_rating\":2.33333,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[2, 2, 3]\",\"title\":\"VECTORIZATION METHODS IN RECOMMENDER SYSTEM\",\"tldr\":\"\"},{\"index\":524,\"qgrid_unfiltered_index\":524,\"avg_confidence\":4.33333,\"avg_rating\":2.33333,\"confidence\":\"[3, 5, 5]\",\"ratings\":\"[3, 1, 3]\",\"title\":\"Pixel Chem: A Representation for Predicting Material Properties with Neural Network\",\"tldr\":\"Proposed a unified, physics based representation of material structures to predict various properties with neural netwoek.\"},{\"index\":889,\"qgrid_unfiltered_index\":889,\"avg_confidence\":4.66667,\"avg_rating\":2.33333,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[2, 2, 3]\",\"title\":\"Deli-Fisher GAN: Stable and Efficient Image Generation With Structured Latent Generative Space\",\"tldr\":\"This paper proposes a new Generative Adversarial Network that is more stable, more efficient, and produces better images than those of status-quo \"},{\"index\":507,\"qgrid_unfiltered_index\":507,\"avg_confidence\":5.0,\"avg_rating\":2.33333,\"confidence\":\"[5, 5, 5]\",\"ratings\":\"[3, 1, 3]\",\"title\":\"Training Variational Auto Encoders with Discrete Latent Representations using Importance Sampling\",\"tldr\":\"We propose an easy method to train Variational Auto Encoders (VAE) with discrete latent representations, using importance sampling\"},{\"index\":198,\"qgrid_unfiltered_index\":198,\"avg_confidence\":5.0,\"avg_rating\":2.5,\"confidence\":\"[5, 5]\",\"ratings\":\"[1, 4]\",\"title\":\"Weak contraction mapping and optimization\",\"tldr\":\"A gradient-free method is proposed for non-convex optimization problem \"},{\"index\":537,\"qgrid_unfiltered_index\":537,\"avg_confidence\":3.5,\"avg_rating\":2.5,\"confidence\":\"[4, 3]\",\"ratings\":\"[3, 2]\",\"title\":\"A Solution to China Competitive Poker Using Deep Learning\",\"tldr\":\"This paper introduces a method to play China competitive poker using deep neural network, gets the state of the art performance.\"},{\"index\":963,\"qgrid_unfiltered_index\":963,\"avg_confidence\":4.0,\"avg_rating\":2.5,\"confidence\":\"[4, 4]\",\"ratings\":\"[3, 2]\",\"title\":\"Hierarchical Bayesian Modeling for Clustering Sparse Sequences in the Context of Group Profiling\",\"tldr\":\"Hierarchical Bayesian Modeling for Clustering Sparse Sequences; User group modeling\"},{\"index\":556,\"qgrid_unfiltered_index\":556,\"avg_confidence\":4.66667,\"avg_rating\":2.66667,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[3, 2, 3]\",\"title\":\"Decoupling Gating from Linearity\",\"tldr\":\"We propose Gated Linear Unit networks \\u2014 a model that performs similarly to ReLU networks on real data while being much easier to analyze theoretically.\"},{\"index\":449,\"qgrid_unfiltered_index\":449,\"avg_confidence\":4.0,\"avg_rating\":2.66667,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[4, 2, 2]\",\"title\":\"VARIATIONAL SGD: DROPOUT , GENERALIZATION AND CRITICAL POINT AT THE END OF CONVEXITY\",\"tldr\":\"Proposed method for finding the most generalizable solution that is stable w.r.t. perturbations of trainig data.\"},{\"index\":239,\"qgrid_unfiltered_index\":239,\"avg_confidence\":4.33333,\"avg_rating\":2.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[2, 2, 4]\",\"title\":\"Multiple Encoder-Decoders Net for Lane Detection\",\"tldr\":\"\"},{\"index\":852,\"qgrid_unfiltered_index\":852,\"avg_confidence\":4.0,\"avg_rating\":2.66667,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[3, 3, 2]\",\"title\":\"End-to-End Learning of Video Compression Using Spatio-Temporal Autoencoders\",\"tldr\":\"\"},{\"index\":1519,\"qgrid_unfiltered_index\":1519,\"avg_confidence\":2.33333,\"avg_rating\":2.66667,\"confidence\":\"[3, 2, 2]\",\"ratings\":\"[3, 3, 2]\",\"title\":\"A CASE STUDY ON OPTIMAL DEEP LEARNING MODEL FOR UAVS\",\"tldr\":\"case study on optimal deep learning model for UAVs\"},{\"index\":256,\"qgrid_unfiltered_index\":256,\"avg_confidence\":3.66667,\"avg_rating\":2.66667,\"confidence\":\"[4, 2, 5]\",\"ratings\":\"[3, 3, 2]\",\"title\":\"Explaining Adversarial Examples with Knowledge Representation\",\"tldr\":\"Hybird storage and representation of learned knowledge may be a reason for adversarial examples.\"},{\"index\":341,\"qgrid_unfiltered_index\":341,\"avg_confidence\":4.33333,\"avg_rating\":2.66667,\"confidence\":\"[5, 3, 5]\",\"ratings\":\"[3, 3, 2]\",\"title\":\"Exponentially Decaying Flows for Optimization in Deep Learning\",\"tldr\":\"Introduction of a new optimization method and its application to deep learning.\"},{\"index\":552,\"qgrid_unfiltered_index\":552,\"avg_confidence\":4.33333,\"avg_rating\":2.66667,\"confidence\":\"[5, 3, 5]\",\"ratings\":\"[3, 3, 2]\",\"title\":\"Faster Training by Selecting Samples Using Embeddings\",\"tldr\":\"Training is sped up by using a dataset that has been subsampled through embedding analysis.\"},{\"index\":1056,\"qgrid_unfiltered_index\":1056,\"avg_confidence\":4.33333,\"avg_rating\":2.66667,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[2, 3, 3]\",\"title\":\"HAPPIER: Hierarchical Polyphonic Music Generative RNN\",\"tldr\":\"\"},{\"index\":919,\"qgrid_unfiltered_index\":919,\"avg_confidence\":4.0,\"avg_rating\":2.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 2, 4]\",\"title\":\"A bird's eye view on coherence, and a worm's eye view on cohesion\",\"tldr\":\"We encode linguistic properties, such as, coherence and cohesion, into expert discriminators and improve text generation.\"},{\"index\":180,\"qgrid_unfiltered_index\":180,\"avg_confidence\":3.66667,\"avg_rating\":2.66667,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 1, 3]\",\"title\":\"Learning Goal-Conditioned Value Functions with one-step Path rewards rather than Goal-Rewards\",\"tldr\":\"Do Goal-Conditioned Value Functions need Goal-Rewards to Learn?\"},{\"index\":1175,\"qgrid_unfiltered_index\":1175,\"avg_confidence\":4.25,\"avg_rating\":2.75,\"confidence\":\"[4, 3, 5, 5]\",\"ratings\":\"[2, 3, 2, 4]\",\"title\":\"Predictive Local Smoothness for Stochastic Gradient Methods\",\"tldr\":\"\"},{\"index\":665,\"qgrid_unfiltered_index\":665,\"avg_confidence\":4.33333,\"avg_rating\":3.0,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[3, 2, 4]\",\"title\":\"Calibration of neural network logit vectors to combat adversarial attacks\",\"tldr\":\"This paper uses principles from the field of calibration in machine learning on the logits of a neural network to defend against adversarial attacks\"},{\"index\":423,\"qgrid_unfiltered_index\":423,\"avg_confidence\":4.33333,\"avg_rating\":3.0,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[3, 4, 2]\",\"title\":\"ReNeg and Backseat Driver: Learning from demonstration with continuous human feedback\",\"tldr\":\"We introduce a novel framework for learning from demonstration that uses continuous human feedback; we evaluate this framework on continuous control for autonomous vehicles.\"},{\"index\":1150,\"qgrid_unfiltered_index\":1150,\"avg_confidence\":4.33333,\"avg_rating\":3.0,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[3, 3, 3]\",\"title\":\"Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference\",\"tldr\":\"\"},{\"index\":1255,\"qgrid_unfiltered_index\":1255,\"avg_confidence\":4.33333,\"avg_rating\":3.0,\"confidence\":\"[3, 5, 5]\",\"ratings\":\"[4, 3, 2]\",\"title\":\"Classification in the dark using tactile exploration\",\"tldr\":\"In this work, we study the problem of learning representations to identify novel objects by exploring objects using tactile sensing. Key point here is that the query is provided in image domain.\"},{\"index\":206,\"qgrid_unfiltered_index\":206,\"avg_confidence\":3.33333,\"avg_rating\":3.0,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 2]\",\"title\":\"A Rate-Distortion Theory of Adversarial Examples\",\"tldr\":\"We argue that excess capacity is a significant cause of susceptibility to adversarial examples.\"},{\"index\":227,\"qgrid_unfiltered_index\":227,\"avg_confidence\":4.33333,\"avg_rating\":3.0,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 4, 2]\",\"title\":\"ATTENTION INCORPORATE NETWORK: A NETWORK CAN ADAPT VARIOUS DATA SIZE\",\"tldr\":\"\"},{\"index\":814,\"qgrid_unfiltered_index\":814,\"avg_confidence\":3.0,\"avg_rating\":3.0,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[3, 3, 3]\",\"title\":\"Dopamine: A Research Framework for Deep Reinforcement Learning\",\"tldr\":\"In this paper we introduce Dopamine, a new research framework for deep RL that is open-source, TensorFlow-based, and provides compact yet reliable implementations of some state-of-the-art deep RL agents.\"},{\"index\":1286,\"qgrid_unfiltered_index\":1286,\"avg_confidence\":4.33333,\"avg_rating\":3.0,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[3, 3, 3]\",\"title\":\"End-to-End Multi-Lingual Multi-Speaker Speech Recognition\",\"tldr\":\"\"},{\"index\":1170,\"qgrid_unfiltered_index\":1170,\"avg_confidence\":4.33333,\"avg_rating\":3.0,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[4, 3, 2]\",\"title\":\"HR-TD: A Regularized TD Method to Avoid Over-Generalization\",\"tldr\":\"A regularization technique for TD learning that avoids temporal over-generalization, especially in Deep Networks\"},{\"index\":335,\"qgrid_unfiltered_index\":335,\"avg_confidence\":4.33333,\"avg_rating\":3.0,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 4, 2]\",\"title\":\"An Exhaustive Analysis of Lazy vs. Eager Learning Methods for Real-Estate Property Investment\",\"tldr\":\"\"},{\"index\":1199,\"qgrid_unfiltered_index\":1199,\"avg_confidence\":3.0,\"avg_rating\":3.0,\"confidence\":\"[1, 4, 4]\",\"ratings\":\"[2, 3, 4]\",\"title\":\"HANDLING CONCEPT DRIFT  IN WIFI-BASED INDOOR LOCALIZATION USING REPRESENTATION LEARNING\",\"tldr\":\"We introduce an augmented robust feature space for streaming wifi data that is capable of tackling concept drift for indoor localization\"},{\"index\":946,\"qgrid_unfiltered_index\":946,\"avg_confidence\":4.0,\"avg_rating\":3.0,\"confidence\":\"[4]\",\"ratings\":\"[3]\",\"title\":\"LSH Microbatches for Stochastic Gradients:  Value in Rearrangement\",\"tldr\":\"Accelerating SGD by arranging examples differently\"},{\"index\":927,\"qgrid_unfiltered_index\":927,\"avg_confidence\":3.33333,\"avg_rating\":3.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[3, 3, 3]\",\"title\":\"A NON-LINEAR  THEORY FOR SENTENCE EMBEDDING\",\"tldr\":\"\"},{\"index\":461,\"qgrid_unfiltered_index\":461,\"avg_confidence\":3.33333,\"avg_rating\":3.0,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[3, 3, 3]\",\"title\":\"Real-time Neural-based Input Method\",\"tldr\":\"\"},{\"index\":912,\"qgrid_unfiltered_index\":912,\"avg_confidence\":3.66667,\"avg_rating\":3.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[2, 3, 4]\",\"title\":\"Evaluation Methodology for Attacks Against Confidence Thresholding Models\",\"tldr\":\"We present metrics and an optimal attack for evaluating models that defend against adversarial examples using confidence thresholding\"},{\"index\":1404,\"qgrid_unfiltered_index\":1404,\"avg_confidence\":3.66667,\"avg_rating\":3.0,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 3, 2]\",\"title\":\"ATTENTIVE EXPLAINABILITY FOR PATIENT TEMPO- RAL EMBEDDING\",\"tldr\":\"\"},{\"index\":751,\"qgrid_unfiltered_index\":751,\"avg_confidence\":3.33333,\"avg_rating\":3.0,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[3, 4, 2]\",\"title\":\"Probabilistic Program Induction for Intuitive Physics Game Play\",\"tldr\":\"The paper describes a method imitating human cognition about the physical world to play games in environments of physical interactions.\"},{\"index\":368,\"qgrid_unfiltered_index\":368,\"avg_confidence\":5.0,\"avg_rating\":3.0,\"confidence\":\"[5, 5, 5]\",\"ratings\":\"[3, 4, 2]\",\"title\":\"Stacking for Transfer Learning\",\"tldr\":\"How to use stacked generalization to improve the performance of existing transfer learning algorithms when limited labeled data is available.\"},{\"index\":854,\"qgrid_unfiltered_index\":854,\"avg_confidence\":4.0,\"avg_rating\":3.0,\"confidence\":\"[3, 5, 4]\",\"ratings\":\"[4, 4, 1]\",\"title\":\"Variational Autoencoders for Text Modeling without Weakening the Decoder\",\"tldr\":\"We propose a model of variational autoencoders for text modeling without weakening the decoder, which improves the quality of text generation and interpretability of acquired representations.\"},{\"index\":986,\"qgrid_unfiltered_index\":986,\"avg_confidence\":4.0,\"avg_rating\":3.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[3, 3, 3]\",\"title\":\"One Bit Matters: Understanding Adversarial Examples as the Abuse of Redundancy\",\"tldr\":\"A new theoretical explanation for the existence of adversarial examples\"},{\"index\":1004,\"qgrid_unfiltered_index\":1004,\"avg_confidence\":3.0,\"avg_rating\":3.0,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[2, 3, 4]\",\"title\":\"Feature quantization for parsimonious and meaningful predictive models\",\"tldr\":\"We tackle discretization of continuous features and grouping of factor levels as a representation learning problem and provide a rigorous way of estimating the best quantization to yield good performance and interpretability.\"},{\"index\":962,\"qgrid_unfiltered_index\":962,\"avg_confidence\":4.0,\"avg_rating\":3.0,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[2, 3, 4]\",\"title\":\"Learn From Neighbour: A Curriculum That Train Low Weighted Samples By Imitating\",\"tldr\":\"\"},{\"index\":797,\"qgrid_unfiltered_index\":797,\"avg_confidence\":3.0,\"avg_rating\":3.0,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[3, 3, 3]\",\"title\":\"An Analysis of Composite Neural Network Performance from Function Composition Perspective\",\"tldr\":\"\"},{\"index\":832,\"qgrid_unfiltered_index\":832,\"avg_confidence\":4.0,\"avg_rating\":3.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 2, 3]\",\"title\":\"Learning with Reflective Likelihoods\",\"tldr\":\"We identify a peculiarity in maximum likelihood learning that causes input collapse and propose a new learning criterion for better representation learning.\"},{\"index\":673,\"qgrid_unfiltered_index\":673,\"avg_confidence\":4.0,\"avg_rating\":3.0,\"confidence\":\"[3, 5, 4]\",\"ratings\":\"[5, 1, 3]\",\"title\":\"KNOWLEDGE DISTILL VIA LEARNING NEURON MANIFOLD\",\"tldr\":\"A new knowledge distill method for transfer learning\"},{\"index\":403,\"qgrid_unfiltered_index\":403,\"avg_confidence\":4.0,\"avg_rating\":3.0,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 3, 3]\",\"title\":\"Mapping the hyponymy relation of wordnet onto vector Spaces\",\"tldr\":\"We investigate mapping the hyponymy relation of wordnet to feature vectors\"},{\"index\":303,\"qgrid_unfiltered_index\":303,\"avg_confidence\":4.0,\"avg_rating\":3.0,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[3, 3, 3]\",\"title\":\"Nonlinear Channels Aggregation Networks for Deep Action Recognition\",\"tldr\":\"An architecture enables CNN trained on the video sequences converging rapidly \"},{\"index\":283,\"qgrid_unfiltered_index\":283,\"avg_confidence\":4.0,\"avg_rating\":3.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[3, 3, 3]\",\"title\":\"SpaMHMM: Sparse Mixture of Hidden Markov Models for Graph Connected Entities\",\"tldr\":\"A method to model the generative distribution of sequences coming from graph connected entities.\"},{\"index\":1276,\"qgrid_unfiltered_index\":1276,\"avg_confidence\":3.33333,\"avg_rating\":3.0,\"confidence\":\"[5, 2, 3]\",\"ratings\":\"[3, 2, 4]\",\"title\":\"Learning powerful policies and better generative models by interaction\",\"tldr\":\"In this paper, we formulate a way to ensure consistency between the predictions of dynamics model and the real observations from the environment. Thus allowing us to learn powerful policies, as well as better dynamics models.\"},{\"index\":304,\"qgrid_unfiltered_index\":304,\"avg_confidence\":4.66667,\"avg_rating\":3.0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[3, 2, 4]\",\"title\":\"Hybrid Policies Using Inverse Rewards for Reinforcement Learning\",\"tldr\":\"A broad-spectrum improvement for reinforcement learning algorithms, which combines the policies using original rewards and inverse (negative) rewards\"},{\"index\":486,\"qgrid_unfiltered_index\":486,\"avg_confidence\":2.33333,\"avg_rating\":3.0,\"confidence\":\"[1, 2, 4]\",\"ratings\":\"[3, 2, 4]\",\"title\":\"Learning of Sophisticated Curriculums by viewing them as Graphs over Tasks\",\"tldr\":\"We present a new algorithm for learning by curriculum based on the notion of mastering rate that outperforms previous algorithms.\"},{\"index\":1292,\"qgrid_unfiltered_index\":1292,\"avg_confidence\":4.66667,\"avg_rating\":3.0,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 3, 2]\",\"title\":\"A Self-Supervised Method for Mapping Human Instructions to Robot Policies\",\"tldr\":\"\"},{\"index\":494,\"qgrid_unfiltered_index\":494,\"avg_confidence\":4.66667,\"avg_rating\":3.0,\"confidence\":\"[5, 4, 5]\",\"ratings\":\"[3, 3, 3]\",\"title\":\"iRDA Method for Sparse Convolutional Neural Networks\",\"tldr\":\"A sparse optimization algorithm for deep CNN models.\"},{\"index\":1455,\"qgrid_unfiltered_index\":1455,\"avg_confidence\":4.66667,\"avg_rating\":3.0,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[3, 3, 3]\",\"title\":\"From Amortised to Memoised Inference: Combining Wake-Sleep and Variational-Bayes for Unsupervised Few-Shot Program Learning\",\"tldr\":\"We extend the wake-sleep algorithm and use it to learn to learn structured models from few examples, \"},{\"index\":528,\"qgrid_unfiltered_index\":528,\"avg_confidence\":4.66667,\"avg_rating\":3.0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[4, 3, 2]\",\"title\":\"A Forensic Representation to Detect Non-Trivial Image Duplicates, and How it Applies to Semantic Segmentation\",\"tldr\":\"A forensic metric to determine if a given image is a copy (with possible manipulation) of another image from a given dataset.\"},{\"index\":481,\"qgrid_unfiltered_index\":481,\"avg_confidence\":4.5,\"avg_rating\":3.0,\"confidence\":\"[4, 5]\",\"ratings\":\"[2, 4]\",\"title\":\"REVERSED NEURAL NETWORK - AUTOMATICALLY FINDING NASH EQUILIBRIUM\",\"tldr\":\"REVERSED NEURAL NETWORK - A PRIMAL\"},{\"index\":1006,\"qgrid_unfiltered_index\":1006,\"avg_confidence\":4.0,\"avg_rating\":3.33333,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[3, 3, 4]\",\"title\":\"Beyond Games: Bringing Exploration to Robots in Real-world\",\"tldr\":\"\"},{\"index\":266,\"qgrid_unfiltered_index\":266,\"avg_confidence\":4.0,\"avg_rating\":3.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 3, 3]\",\"title\":\"Accidental explorationa through value predictors\",\"tldr\":\"We study the biases introduced in common value predictors by the fact that trajectories are, in practice, finite.\"},{\"index\":257,\"qgrid_unfiltered_index\":257,\"avg_confidence\":4.0,\"avg_rating\":3.33333,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[4, 2, 4]\",\"title\":\"IEA: Inner Ensemble Average within a convolutional neural network\",\"tldr\":\"We inner ensemble the features of a convolutional neural layer, it increases the network accuracy and generates distinct features.\"},{\"index\":498,\"qgrid_unfiltered_index\":498,\"avg_confidence\":4.66667,\"avg_rating\":3.33333,\"confidence\":\"[5, 4, 5]\",\"ratings\":\"[4, 3, 3]\",\"title\":\"MAJOR-MINOR LSTMS FOR WORD-LEVEL LANGUAGE MODEL\",\"tldr\":\"\"},{\"index\":1017,\"qgrid_unfiltered_index\":1017,\"avg_confidence\":4.66667,\"avg_rating\":3.33333,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[3, 4, 3]\",\"title\":\"Learning Spatio-Temporal Representations Using Spike-Based Backpropagation\",\"tldr\":\"\"},{\"index\":354,\"qgrid_unfiltered_index\":354,\"avg_confidence\":4.0,\"avg_rating\":3.33333,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 3, 3]\",\"title\":\"SHE2: Stochastic Hamiltonian Exploration and Exploitation for Derivative-Free Optimization\",\"tldr\":\"a new derivative-free optimization algorithms derived from Nesterov's accelerated gradient methods and Hamiltonian dynamics\"},{\"index\":867,\"qgrid_unfiltered_index\":867,\"avg_confidence\":4.33333,\"avg_rating\":3.33333,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[4, 4, 2]\",\"title\":\"Detecting Topological Defects in 2D Active Nematics Using Convolutional Neural Networks\",\"tldr\":\"An interesting application of CNN in soft condensed matter physics experiments.\"},{\"index\":390,\"qgrid_unfiltered_index\":390,\"avg_confidence\":4.33333,\"avg_rating\":3.33333,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[3, 4, 3]\",\"title\":\"Encoder Discriminator Networks for Unsupervised Representation Learning\",\"tldr\":\"\"},{\"index\":1340,\"qgrid_unfiltered_index\":1340,\"avg_confidence\":4.66667,\"avg_rating\":3.33333,\"confidence\":\"[5, 4, 5]\",\"ratings\":\"[3, 5, 2]\",\"title\":\"Associate Normalization\",\"tldr\":\"\"},{\"index\":1157,\"qgrid_unfiltered_index\":1157,\"avg_confidence\":4.33333,\"avg_rating\":3.33333,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[3, 3, 4]\",\"title\":\"Neural Network Regression with Beta, Dirichlet, and Dirichlet-Multinomial Outputs\",\"tldr\":\"Neural network regression should use Dirichlet output distribution when targets are probabilities in order to quantify uncertainty of predictions.\"},{\"index\":1542,\"qgrid_unfiltered_index\":1542,\"avg_confidence\":4.33333,\"avg_rating\":3.33333,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 3, 3]\",\"title\":\"Human Action Recognition Based on Spatial-Temporal Attention\",\"tldr\":\"\"},{\"index\":429,\"qgrid_unfiltered_index\":429,\"avg_confidence\":4.33333,\"avg_rating\":3.33333,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 4]\",\"title\":\"Understanding and Improving Sequence-Labeling NER with Self-Attentive LSTMs\",\"tldr\":\"We provide insightful understanding of sequence-labeling NER and propose to use two types of cross structures, both of which bring theoretical and empirical improvements.\"},{\"index\":1338,\"qgrid_unfiltered_index\":1338,\"avg_confidence\":4.33333,\"avg_rating\":3.33333,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[3, 2, 5]\",\"title\":\"Uncertainty in Multitask Transfer Learning\",\"tldr\":\"A scalable method for learning an expressive prior over neural networks across multiple tasks.\"},{\"index\":650,\"qgrid_unfiltered_index\":650,\"avg_confidence\":4.33333,\"avg_rating\":3.33333,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 4, 3]\",\"title\":\"Step-wise Sensitivity Analysis: Identifying Partially Distributed Representations for Interpretable Deep Learning\",\"tldr\":\"We find dependency graphs between learned representations as a first step towards building decision trees to interpret the representation manifold.\"},{\"index\":225,\"qgrid_unfiltered_index\":225,\"avg_confidence\":3.66667,\"avg_rating\":3.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[3, 3, 4]\",\"title\":\"Linearizing Visual Processes with Deep Generative Models\",\"tldr\":\"We model non-linear visual processes as autoregressive noise via generative deep learning.\"},{\"index\":228,\"qgrid_unfiltered_index\":228,\"avg_confidence\":3.66667,\"avg_rating\":3.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 3, 3]\",\"title\":\"Interpreting Layered Neural Networks via Hierarchical Modular Representation\",\"tldr\":\"A method for obtaining a hierarchical cluster structure of a trained layered neural network\"},{\"index\":188,\"qgrid_unfiltered_index\":188,\"avg_confidence\":3.66667,\"avg_rating\":3.33333,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[4, 5, 1]\",\"title\":\"Deterministic Policy Gradients with General State Transitions\",\"tldr\":\"\"},{\"index\":900,\"qgrid_unfiltered_index\":900,\"avg_confidence\":5.0,\"avg_rating\":3.33333,\"confidence\":\"[5, 5, 5]\",\"ratings\":\"[3, 5, 2]\",\"title\":\"Logit Regularization Methods for Adversarial Robustness\",\"tldr\":\"Logit regularization methods help explain and improve state of the art adversarial defenses\"},{\"index\":603,\"qgrid_unfiltered_index\":603,\"avg_confidence\":4.0,\"avg_rating\":3.33333,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 5, 2]\",\"title\":\"Gradient Acceleration in Activation Functions\",\"tldr\":\"\"},{\"index\":440,\"qgrid_unfiltered_index\":440,\"avg_confidence\":4.66667,\"avg_rating\":3.33333,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[2, 5, 3]\",\"title\":\"Geometric Operator Convolutional Neural Network\",\"tldr\":\"Traditional image processing algorithms are combined with Convolutional Neural Networks\\uff0ca new neural network.\"},{\"index\":288,\"qgrid_unfiltered_index\":288,\"avg_confidence\":4.0,\"avg_rating\":3.33333,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[4, 3, 3]\",\"title\":\"Learning and Data Selection in Big Datasets\",\"tldr\":\"\"},{\"index\":1419,\"qgrid_unfiltered_index\":1419,\"avg_confidence\":3.33333,\"avg_rating\":3.33333,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[3, 3, 4]\",\"title\":\"Combining adaptive algorithms and hypergradient method: a performance and robustness study\",\"tldr\":\"We provide a study trying to see how the recent online learning rate adaptation extends the conclusion made by Wilson et al. 2018 about adaptive gradient methods, along with comparison and sensitivity analysis.\"},{\"index\":616,\"qgrid_unfiltered_index\":616,\"avg_confidence\":4.66667,\"avg_rating\":3.33333,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[3, 3, 4]\",\"title\":\"BEHAVIOR MODULE IN NEURAL NETWORKS\",\"tldr\":\"Extendable Modular Architecture is proposed for developing of variety of Agent Behaviors in DQN.\"},{\"index\":560,\"qgrid_unfiltered_index\":560,\"avg_confidence\":3.66667,\"avg_rating\":3.33333,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[2, 4, 4]\",\"title\":\"BIGSAGE: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating\",\"tldr\":\"For unsupervised and inductive network embedding, we propose a novel approach to explore most relevant neighbors and preserve previously learnt knowledge of nodes by utilizing bi-attention architecture and introducing global bias, respectively\"},{\"index\":1296,\"qgrid_unfiltered_index\":1296,\"avg_confidence\":4.0,\"avg_rating\":3.33333,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 4, 3]\",\"title\":\"Non-Synergistic Variational Autoencoders\",\"tldr\":\"Minimising the synergistic mutual information within the latents and the data for the task of disentanglement using the VAE framework.\"},{\"index\":215,\"qgrid_unfiltered_index\":215,\"avg_confidence\":4.66667,\"avg_rating\":3.33333,\"confidence\":\"[5, 4, 5]\",\"ratings\":\"[3, 4, 3]\",\"title\":\"Multi-Scale Stacked Hourglass Network for Human Pose Estimation\",\"tldr\":\"Differentiated inputs cause functional differentiation of the network, and the interaction of loss functions between networks can affect the optimization process.\"},{\"index\":475,\"qgrid_unfiltered_index\":475,\"avg_confidence\":4.66667,\"avg_rating\":3.33333,\"confidence\":\"[5, 4, 5]\",\"ratings\":\"[3, 4, 3]\",\"title\":\"A quantifiable testing of global translational invariance in Convolutional and Capsule Networks\",\"tldr\":\"Testing of global translational invariance in Convolutional and Capsule Networks\"},{\"index\":942,\"qgrid_unfiltered_index\":942,\"avg_confidence\":4.0,\"avg_rating\":3.33333,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[4, 3, 3]\",\"title\":\"Neural Distribution Learning for generalized time-to-event prediction\",\"tldr\":\"We present a general solution to event prediction that has been there all along; Discrete Time Parametric Survival Analysis.\"},{\"index\":1068,\"qgrid_unfiltered_index\":1068,\"avg_confidence\":4.33333,\"avg_rating\":3.33333,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[3, 4, 3]\",\"title\":\"Empirical Study of Easy and Hard Examples in CNN Training\",\"tldr\":\"Unknown properties of easy and hard examples are shown, and they come from biases in a dataset and SGD.\"},{\"index\":404,\"qgrid_unfiltered_index\":404,\"avg_confidence\":4.33333,\"avg_rating\":3.33333,\"confidence\":\"[3, 5, 5]\",\"ratings\":\"[5, 2, 3]\",\"title\":\"Discrete Structural Planning for Generating Diverse Translations\",\"tldr\":\"Learning discrete structural representation to control sentence generation and obtain diverse outputs\"},{\"index\":538,\"qgrid_unfiltered_index\":538,\"avg_confidence\":4.0,\"avg_rating\":3.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 3, 3]\",\"title\":\"Deep models calibration with bayesian neural networks\",\"tldr\":\"We apply bayesian neural networks to improve calibration\"},{\"index\":1223,\"qgrid_unfiltered_index\":1223,\"avg_confidence\":3.66667,\"avg_rating\":3.33333,\"confidence\":\"[2, 5, 4]\",\"ratings\":\"[5, 2, 3]\",\"title\":\"Generative model based on minimizing exact empirical Wasserstein distance\",\"tldr\":\"We have proposed a flexible generative model that learns stably by directly minimizing exact empirical Wasserstein distance.\"},{\"index\":732,\"qgrid_unfiltered_index\":732,\"avg_confidence\":3.66667,\"avg_rating\":3.33333,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[4, 4, 2]\",\"title\":\"Deconfounding Reinforcement Learning\",\"tldr\":\"This is the first attempt to build a bridge between confounding and the full reinforcement learning problem.\"},{\"index\":1192,\"qgrid_unfiltered_index\":1192,\"avg_confidence\":3.0,\"avg_rating\":3.33333,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[4, 3, 3]\",\"title\":\"ATTACK GRAPH CONVOLUTIONAL NETWORKS BY ADDING FAKE NODES\",\"tldr\":\"non-targeted and targeted attack on GCN by adding fake nodes\"},{\"index\":638,\"qgrid_unfiltered_index\":638,\"avg_confidence\":3.66667,\"avg_rating\":3.33333,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[3, 4, 3]\",\"title\":\"Neural Random Projections for Language Modelling\",\"tldr\":\"Neural language models can be trained with a compressed embedding space, by using sparse random projections, created incrementally for each unique discrete input.\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"avg_confidence\":3.0,\"avg_rating\":3.5,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":1085,\"qgrid_unfiltered_index\":1085,\"avg_confidence\":4.0,\"avg_rating\":3.5,\"confidence\":\"[5, 3]\",\"ratings\":\"[4, 3]\",\"title\":\"Controlling Over-generalization and its Effect on Adversarial Examples Detection and Generation\",\"tldr\":\"Properly training CNNs with dustbin class increase their robustness to adversarial attacks and their capacity to deal with out-distribution samples.\"},{\"index\":1012,\"qgrid_unfiltered_index\":1012,\"avg_confidence\":4.0,\"avg_rating\":3.5,\"confidence\":\"[3, 5]\",\"ratings\":\"[4, 3]\",\"title\":\"Bamboo: Ball-Shape Data Augmentation Against Adversarial Attacks from All Directions\",\"tldr\":\"The first data augmentation method specially designed for improving the general robustness of DNN without any hypothesis on the attacking algorithms.\"},{\"index\":702,\"qgrid_unfiltered_index\":702,\"avg_confidence\":3.0,\"avg_rating\":3.5,\"confidence\":\"[2, 4]\",\"ratings\":\"[3, 4]\",\"title\":\"Using Deep Siamese Neural Networks to Speed up Natural Products Research\",\"tldr\":\"We learn a direct mapping from NMR spectra of small molecules to a molecular structure based cluster space. \"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": "avg_rating",
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "e402eaaa-a065-4b1a-9f2d-6f09d7f72e29",
       "layout": "IPY_MODEL_f12d7b90a86143099fedc0de1143b21f",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "17a77799e8bf455eb5ecde7857bde805": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1979318889254ad4ae5e6394a6ddb2a1": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "maxWidth": null,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "maxWidth": null,
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "maxWidth": null,
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 100
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "maxWidth": null,
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "maxWidth": null,
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "maxWidth": null,
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "maxWidth": null,
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": null
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "maxWidth": null,
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": null
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "maxWidth": null,
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxfEn09Y7\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"Adversarial examples\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4dFjR5K7\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"Generative Model\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke4KsA5FX\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgYl205tQ\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.3,\"avg_confidence\":3.0,\"topic\":\"Model Interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1E3Ko09F7\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"Information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJg8yhAqKm\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJGtFoC5Fm\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.8,\"topic\":\"adversarial examples\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgVRiC9Km\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.7,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTciR9tm\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Artificial Intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl42iA5t7\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.3,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylKB3A9Fm\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlxm30cKm\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Neural Machine Translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eEdj0cK7\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygqqsA9KX\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.2,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygn2o0qKX\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1GLm2R9Km\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke-JhA9Y7\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJlmHoR5tQ\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygfghAcYX\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"Network Compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xLN3C9YX\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"PU learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJzLciCqKm\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1MAJhR5YX\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xsSjC9Ym\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"Maximum Mean Discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkG5SjR5YQ\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"neural network\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eJssCqY7\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"embeddings\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJxeWnCcF7\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.7,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1grRoR9tQ\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgnmhA5KQ\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxnvsAqFm\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.3,\"avg_confidence\":4.3,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxcHnRqYQ\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"adversarial examples\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJl2niR9KQ\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxt8oC9FQ\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"Lifelong Learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hkf2_sC5FX\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.7,\"topic\":\"Model free RL\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HygsfnR9Ym\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"Deep Learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl0r3R9KX\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"Adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlk6iRqKX\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"Dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklSf3CqKm\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"CNN\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMHpjC9Ym\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJf_YjCqYX\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlEojAqFm\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bye9LiR9YX\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgToo0qFm\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygxb2CqKm\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl2E3AcF7\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4fpoA5Km\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.3,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxBFsRqYm\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyVU6s05K7\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"NLP\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xtAjR5tX\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.7,\"avg_confidence\":4.7,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJf7ts0cFm\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.7,\"avg_confidence\":3.3,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SklcFsAcKX\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByGuynAct7\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJfRpoA9YX\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syxt2jC5FX\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkE6PjC9KX\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyM7AiA5YX\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.7,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1ebTsActm\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJeXSo09FQ\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.3,\"avg_confidence\":4.7,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx38iC5KX\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.7,\"avg_confidence\":3.3,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklnzhR9YQ\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx7l309Fm\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzjBiR9t7\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1MB-3RcF7\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.3,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkgnpiR9Y7\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.2,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1e7hs05Km\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.3,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyePrhR5KX\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylPMnR9Ym\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyehMhC9Y7\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygm8jC9FQ\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJedV3R5tm\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke96sC5tm\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryf6Fs09YX\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.3,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke4HiAcY7\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl6As0cF7\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkNksoRctQ\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkemqsC9Fm\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rk4Qso0cKm\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJeQbnA5tm\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xEtoRqtQ\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgK6iA5KX\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygHGnRqK7\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.3,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryMQ5sRqYX\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedwoC5t7\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1My6sR9tX\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1erHoR5t7\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyNvti09KQ\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkGiPoC5FX\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syfz6sC9tQ\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByMVTsR5KQ\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlaYi05tm\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlgNh0qKQ\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "250d4222-b6ba-484a-8961-bad3b4ce59e0",
       "layout": "IPY_MODEL_c311a7a496db474ba621950475f6c4bc",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "1bbce23f6eae4eff863d2c1294dc878c": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 100
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":1017,\"qgrid_unfiltered_index\":1017,\"title\":\"Exploration by random distillation\",\"avg_rating\":8.7,\"avg_confidence\":4.3,\"topic\":\"reinforcement learning\",\"tldr\":\"A simple exploration bonus is introduced and achieves state of the art performance in 3 hard exploration Atari games.\",\"ratings\":\"[9, 10, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lJJnR5Ym\"},{\"Index\":648,\"qgrid_unfiltered_index\":648,\"title\":\"Benchmarking Neural Network Robustness to Common Corruptions and Perturbations\",\"avg_rating\":8.3,\"avg_confidence\":4.0,\"topic\":\"robustness\",\"tldr\":\"We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness\",\"ratings\":\"[7, 9, 9]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJz6tiCqYm\"},{\"Index\":707,\"qgrid_unfiltered_index\":707,\"title\":\"Large Scale GAN Training for High Fidelity Natural Image Synthesis\",\"avg_rating\":8.3,\"avg_confidence\":3.7,\"topic\":\"GANs\",\"tldr\":\"GANs benefit from scaling up.\",\"ratings\":\"[7, 8, 10]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1xsqj09Fm\"},{\"Index\":1304,\"qgrid_unfiltered_index\":1304,\"title\":\"ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"sparse recovery\",\"tldr\":\"\",\"ratings\":\"[10, 6, 8]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1lnzn0ctQ\"},{\"Index\":878,\"qgrid_unfiltered_index\":878,\"title\":\"GENERATING HIGH FIDELITY IMAGES WITH SUBSCALE PIXEL NETWORKS AND MULTIDIMENSIONAL UPSCALING\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"We show that autoregressive models can generate high fidelity images. \",\"ratings\":\"[10, 7, 7]\",\"confidence\":\"[5, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HylzTiC5Km\"},{\"Index\":717,\"qgrid_unfiltered_index\":717,\"title\":\"Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"Deep Learning\",\"tldr\":\"We introduce a new inductive bias that integrates tree structures in recurrent neural networks.\",\"ratings\":\"[9, 7, 8]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1l6qiR5F7\"},{\"Index\":950,\"qgrid_unfiltered_index\":950,\"title\":\"Slimmable Neural Networks\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"Slimmable neural networks\",\"tldr\":\"We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1gMCsAqY7\"},{\"Index\":1115,\"qgrid_unfiltered_index\":1115,\"title\":\"Temporal Difference Variational Auto-Encoder\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"generative models\",\"tldr\":\"Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1x4ghC9tQ\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\"},{\"Index\":1442,\"qgrid_unfiltered_index\":1442,\"title\":\"Posterior Attention Models for Sequence to Sequence Learning\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"posterior inference\",\"tldr\":\"Computing attention based on posterior distribution leads to more meaningful attention and better performance\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkltNhC9FX\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\"},{\"Index\":636,\"qgrid_unfiltered_index\":636,\"title\":\"Sparse Dictionary Learning by Dynamical Neural Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[6, 9, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1gstsCqt7\"},{\"Index\":1495,\"qgrid_unfiltered_index\":1495,\"title\":\"Composing Complex Skills by Learning Transition Policies with Proximity Reward Induction\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"reinforcement learning\",\"tldr\":\"Transition policies enable agents to execute learned skills smoothly to perform complex tasks.\",\"ratings\":\"[7, 9, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygrBhC5tQ\"},{\"Index\":1330,\"qgrid_unfiltered_index\":1330,\"title\":\"Adaptive Input Representations for Neural Language Modeling\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Neural language modeling\",\"tldr\":\"Variable capacity input word embeddings and SOTA on WikiText-103, Billion Word benchmarks.\",\"ratings\":\"[7, 8, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxZX20qFQ\"},{\"Index\":1454,\"qgrid_unfiltered_index\":1454,\"title\":\"A Variational Inequality Perspective on Generative Adversarial Networks\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"optimization\",\"tldr\":\"We cast GANs in the variational inequality framework and import techniques from this literature to optimize GANs better; we give algorithmic extensions and empirically test their performance for training GANs.\",\"ratings\":\"[8, 8, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1laEnA5Ym\"},{\"Index\":450,\"qgrid_unfiltered_index\":450,\"title\":\"Identifying and Controlling Important Neurons in Neural Machine Translation\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"neural machine translation\",\"tldr\":\"Unsupervised methods for finding, analyzing, and controlling important neurons in NMT\",\"ratings\":\"[7, 10, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1z-PsR5KX\"},{\"Index\":276,\"qgrid_unfiltered_index\":276,\"title\":\"ON RANDOM DEEP AUTOENCODERS: EXACT ASYMPTOTIC ANALYSIS, PHASE TRANSITIONS, AND IMPLICATIONS TO TRAINING\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Random Deep Autoencoders\",\"tldr\":\"We study the behavior of weight-tied multilayer vanilla autoencoders under the assumption of random weights. Via an exact characterization in the limit of large dimensions, our analysis reveals interesting phase transition phenomena.\",\"ratings\":\"[9, 6, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx54i05tX\"},{\"Index\":255,\"qgrid_unfiltered_index\":255,\"title\":\"Smoothing the Geometry of Probabilistic Box Embeddings\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"embeddings\",\"tldr\":\"Improve hierarchical embedding models using kernel smoothing\",\"ratings\":\"[8, 8, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xSNiRcF7\"},{\"Index\":661,\"qgrid_unfiltered_index\":661,\"title\":\"KnockoffGAN: Generating Knockoffs for Feature Selection using Generative Adversarial Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Knockoff model\",\"tldr\":\"\",\"ratings\":\"[6, 10, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByeZ5jC5YQ\"},{\"Index\":614,\"qgrid_unfiltered_index\":614,\"title\":\"Critical Learning Periods in Deep Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.3,\"topic\":\"Critical Period\",\"tldr\":\"Sensory deficits in early training phases can lead to irreversible performance loss in both artificial and neuronal networks, suggesting information phenomena as the common cause, and point to the importance of the initial transient and forgetting.\",\"ratings\":\"[9, 8, 6]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkeStsCcKQ\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\"},{\"Index\":1154,\"qgrid_unfiltered_index\":1154,\"title\":\"Pay Less Attention with Lightweight and Dynamic Convolutions\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Deep learning\",\"tldr\":\"Dynamic lightweight convolutions are competitive to self-attention on language tasks.\",\"ratings\":\"[8, 7, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkVhlh09tX\"},{\"Index\":778,\"qgrid_unfiltered_index\":778,\"title\":\"Learning Robust Representations by Projecting Superficial Statistics Out\",\"avg_rating\":7.7,\"avg_confidence\":3.7,\"topic\":\"domain generalization\",\"tldr\":\"Building on previous work on domain generalization, we hope to produce a classifier that will generalize to previously unseen domains, even when domain identifiers are not available during training.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJEjjoR9K7\"},{\"Index\":353,\"qgrid_unfiltered_index\":353,\"title\":\"Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware\",\"avg_rating\":7.7,\"avg_confidence\":3.0,\"topic\":\"Trusted hardware\",\"tldr\":\"We accelerate secure DNN inference in trusted execution environments (by a factor 4x-20x) by selectively outsourcing the computation of linear layers to a faster yet untrusted co-processor.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJVorjCcKQ\"},{\"Index\":762,\"qgrid_unfiltered_index\":762,\"title\":\"Learning Unsupervised Learning Rules\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"Meta-learning\",\"tldr\":\"We learn an unsupervised learning algorithm that produces useful representations from a set of supervised tasks. At test-time, we apply this algorithm to new tasks without any supervision and show performance comparable to a VAE.\",\"ratings\":\"[8, 7, 8]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkNDsiC9KQ\"},{\"Index\":1239,\"qgrid_unfiltered_index\":1239,\"title\":\"Supervised Community Detection with Line Graph Neural Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"community detection\",\"tldr\":\"We propose a novel graph neural network architecture based on the non-backtracking operator defined over edge adjacencies and demonstrate its effectiveness on community detection tasks on graphs.\",\"ratings\":\"[6, 9, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1g0Z3A9Fm\"},{\"Index\":348,\"qgrid_unfiltered_index\":348,\"title\":\"Diffusion Scattering Transforms on Graphs\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"graph neural networks\",\"tldr\":\"Stability of scattering transform representations of graph data to deformations of the underlying graph support.\",\"ratings\":\"[9, 6]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygqBiRcFQ\"},{\"Index\":662,\"qgrid_unfiltered_index\":662,\"title\":\"On the Minimal Supervision for Training Any Binary Classifier from Only Unlabeled Data\",\"avg_rating\":7.5,\"avg_confidence\":3.5,\"topic\":\"learning from only unlabeled data\",\"tldr\":\"Three class priors are all you need to train deep models from only U data, while any two should not be enough.\",\"ratings\":\"[8, 7]\",\"confidence\":\"[3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1xWcj0qYm\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\"},{\"Index\":1252,\"qgrid_unfiltered_index\":1252,\"title\":\"Towards Metamerism via Foveated Style Transfer\",\"avg_rating\":7.3,\"avg_confidence\":4.3,\"topic\":\"Metamerism\",\"tldr\":\"We introduce a novel feed-forward framework to generate visual metamers\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJzbG20cFQ\"},{\"Index\":1540,\"qgrid_unfiltered_index\":1540,\"title\":\"Visualizing and Understanding Generative Adversarial Networks\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"GANs\",\"tldr\":\"GAN representations are examined in detail, and sets of representation units are found that control the generation of semantic concepts in the output.\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hyg_X2C5FX\"},{\"Index\":957,\"qgrid_unfiltered_index\":957,\"title\":\"ProMP: Proximal Meta-Policy Search\",\"avg_rating\":7.3,\"avg_confidence\":3.0,\"topic\":\"Meta-Reinforcement Learning\",\"tldr\":\"A novel and theoretically grounded meta-reinforcement learning algorithm\",\"ratings\":\"[6, 7, 9]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxXCi0qFX\"},{\"Index\":548,\"qgrid_unfiltered_index\":548,\"title\":\"Evaluating Robustness of Neural Networks with Mixed Integer Programming\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"verification\",\"tldr\":\"We efficiently verify the robustness of deep neural models with over 100,000 ReLUs, certifying more samples than the state-of-the-art and finding more adversarial examples than a strong first-order attack.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[5, 5, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyGIdiRqtm\"},{\"Index\":997,\"qgrid_unfiltered_index\":997,\"title\":\"Efficient Training on Very Large Corpora via Gramian Estimation\",\"avg_rating\":7.3,\"avg_confidence\":2.7,\"topic\":\"similarity learning\",\"tldr\":\"We develop efficient methods to train neural embedding models with a dot-product structure, by reformulating the objective function in terms of generalized Gram matrices, and maintaining estimates of those matrices.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[4, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke20iA9Y7\"},{\"Index\":1509,\"qgrid_unfiltered_index\":1509,\"title\":\"Label super-resolution networks\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"weakly supervised segmentation\",\"tldr\":\"Super-resolving coarse labels into pixel-level labels, applied to aerial imagery and medical scans.\",\"ratings\":\"[7, 6, 9]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxwShA9Ym\"},{\"Index\":1253,\"qgrid_unfiltered_index\":1253,\"title\":\"Kernel Change-point Detection with Auxiliary Deep Generative Models\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"deep kernel learning\",\"tldr\":\"In this paper, we propose KL-CPD, a novel kernel learning framework for time series CPD that optimizes a lower bound of test power via an auxiliary generative model as a surrogate to the abnormal distribution. \",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1GbfhRqF7\"},{\"Index\":1204,\"qgrid_unfiltered_index\":1204,\"title\":\"Biologically-Plausible Learning Algorithms Can Scale to Large Datasets\",\"avg_rating\":7.3,\"avg_confidence\":4.3,\"topic\":\"biologically plausible learning algorithm\",\"tldr\":\"Biologically plausible learning algorithms, particularly sign-symmetry, works well on ImageNet\",\"ratings\":\"[9, 9, 4]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygvZ209F7\"},{\"Index\":861,\"qgrid_unfiltered_index\":861,\"title\":\"Diversity is All You Need: Learning Skills without a Reward Function\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"reinforcement learning\",\"tldr\":\"We propose an algorithm for learning useful skills without a reward function, and show how these skills can be used to solve downstream tasks.\",\"ratings\":\"[8, 7, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJx63jRqFm\"},{\"Index\":478,\"qgrid_unfiltered_index\":478,\"title\":\"Large-Scale Study of Curiosity-Driven Learning\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"exploration\",\"tldr\":\"An agent trained only with curiosity, and no extrinsic reward, does surprisingly well on 54 popular environments, including the suite of Atari games, Mario etc.\",\"ratings\":\"[6, 9, 7]\",\"confidence\":\"[4, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJNwDjAqYX\"},{\"Index\":372,\"qgrid_unfiltered_index\":372,\"title\":\"Differentiable Learning-to-Normalize via Switchable Normalization\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"normalization\",\"tldr\":\"\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryggIs0cYQ\"},{\"Index\":1094,\"qgrid_unfiltered_index\":1094,\"title\":\"Gradient descent aligns the layers of deep linear networks\",\"avg_rating\":7.3,\"avg_confidence\":4.3,\"topic\":\"implicit regularization\",\"tldr\":\"\",\"ratings\":\"[7, 9, 6]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJflg30qKX\"},{\"Index\":124,\"qgrid_unfiltered_index\":124,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylV-2C9KQ\"},{\"Index\":625,\"qgrid_unfiltered_index\":625,\"title\":\"Small nonlinearities in activation functions create bad local minima in neural networks\",\"avg_rating\":7.3,\"avg_confidence\":3.3,\"topic\":\"spurious local minima\",\"tldr\":\"We constructively prove that even the slightest nonlinear activation functions introduce spurious local minima, for general datasets and activation functions.\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke_YiRct7\"},{\"Index\":663,\"qgrid_unfiltered_index\":663,\"title\":\"Approximability of Discriminators Implies Diversity in GANs\",\"avg_rating\":7.3,\"avg_confidence\":2.7,\"topic\":\"Theory\",\"tldr\":\"GANs can in principle learn distributions sample-efficiently, if the discriminator class is compact and has strong distinguishing power against the particular generator class.\",\"ratings\":\"[8, 7, 7]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJfW5oA5KQ\"},{\"Index\":1286,\"qgrid_unfiltered_index\":1286,\"title\":\"LanczosNet: Multi-Scale Deep Graph Convolutional Networks\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedznAqKQ\"},{\"Index\":1268,\"qgrid_unfiltered_index\":1268,\"title\":\"Improving the Differentiable Neural Computer Through Memory Masking, De-allocation, and Link Distribution Sharpness Control\",\"avg_rating\":7.0,\"avg_confidence\":5.0,\"topic\":\"rnn\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyGEM3C9KQ\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\"},{\"Index\":1280,\"qgrid_unfiltered_index\":1280,\"title\":\"Lagging Inference Networks and Posterior Collapse in Variational Autoencoders\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"variational autoencoders\",\"tldr\":\"To address posterior collapse in VAEs, we propose a simple yet effective training algorithm that aggressively optimizes inference network with more updates\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylDfnCqF7\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\"},{\"Index\":100,\"qgrid_unfiltered_index\":100,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylCrnCcFX\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\"},{\"Index\":1232,\"qgrid_unfiltered_index\":1232,\"title\":\"Learning Neural PDE Solvers with Convergence Guarantees\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Partial differential equation\",\"tldr\":\"We learn a fast neural solver for PDEs that has convergence guarantees.\",\"ratings\":\"[7, 8, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rklaWn0qK7\"},{\"Index\":1337,\"qgrid_unfiltered_index\":1337,\"title\":\"Learning to Navigate the Web\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"navigating web pages\",\"tldr\":\"We train reinforcement learning policies using reward augmentation, curriculum learning, and meta-learning  to successfully navigate web pages.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJemQ209FQ\"},{\"Index\":102,\"qgrid_unfiltered_index\":102,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkxjYoCqKX\"},{\"Index\":1313,\"qgrid_unfiltered_index\":1313,\"title\":\"Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based RL\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"meta-learning\",\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxAfnA5tm\"},{\"Index\":383,\"qgrid_unfiltered_index\":383,\"title\":\"An analytic theory of generalization dynamics and transfer learning in deep linear networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Generalization\",\"tldr\":\"We provide many insights into neural network generalization from the theoretically tractable linear case.\",\"ratings\":\"[8, 7, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryfMLoCqtQ\"},{\"Index\":143,\"qgrid_unfiltered_index\":143,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJe9rh0cFX\"},{\"Index\":921,\"qgrid_unfiltered_index\":921,\"title\":\"How Powerful are Graph Neural Networks?\",\"avg_rating\":7.0,\"avg_confidence\":5.0,\"topic\":\"graph neural networks\",\"tldr\":\"We develop theoretical foundations for expressive power of GNNs and design a provably most powerful GNN.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryGs6iA5Km\"},{\"Index\":345,\"qgrid_unfiltered_index\":345,\"title\":\"DARTS: Differentiable Architecture Search\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"deep learning\",\"tldr\":\"We propose a differentiable architecture search algorithm for both convolutional and recurrent networks, achieving competitive performance with the state of the art using orders of magnitude less computation resources.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eYHoC5FX\"},{\"Index\":1119,\"qgrid_unfiltered_index\":1119,\"title\":\"What do you learn from context? Probing for sentence structure in contextualized word representations\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"natural language processing\",\"tldr\":\"We probe for sentence structure in ELMo and related contextual embedding models. We find existing models efficiently encode syntax and show evidence of long-range dependencies, but only offer small improvements on semantic tasks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJzSgnRcKX\"},{\"Index\":197,\"qgrid_unfiltered_index\":197,\"title\":\"Learning a SAT Solver from Single-Bit Supervision\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"sat\",\"tldr\":\"We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMC_iA5tm\"},{\"Index\":242,\"qgrid_unfiltered_index\":242,\"title\":\"Auxiliary Variational MCMC\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"MCMC\",\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1NJqsRctX\"},{\"Index\":304,\"qgrid_unfiltered_index\":304,\"title\":\"Deep, Skinny Neural Networks are not Universal Approximators\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"neural network\",\"tldr\":\"This paper proves that skinny neural networks cannot approximate certain functions, no matter how deep they are.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryGgSsAcFQ\"},{\"Index\":1108,\"qgrid_unfiltered_index\":1108,\"title\":\"Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word Vectors\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"word vectors\",\"tldr\":\"Max-pooled word vectors with fuzzy Jaccard set similarity are an extremely competitive baseline for semantic similarity; we propose a simple dynamic variant that performs even better.\",\"ratings\":\"[8, 8, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxXg2C5FX\"},{\"Index\":1103,\"qgrid_unfiltered_index\":1103,\"title\":\"The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"Neuro-Symbolic Representations\",\"tldr\":\"We present a Neuro-Symbolic Concept Learner to learn visual concepts, words, and semantic parsing of sentences without explicit annotations for any of them. \",\"ratings\":\"[7, 5, 9]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgMlhRctm\"},{\"Index\":1530,\"qgrid_unfiltered_index\":1530,\"title\":\"Global-to-local Memory Pointer Networks for Task-Oriented Dialogue\",\"avg_rating\":7.0,\"avg_confidence\":2.3,\"topic\":\"pointer networks\",\"tldr\":\"We propose a global memory encoder and a global memory decoder that share an external knowledge to strengthen task-oriented dialogue generation via sketch responses and pointer networks. \",\"ratings\":\"[8, 8, 5]\",\"confidence\":\"[2, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryxnHhRqFm\"},{\"Index\":1414,\"qgrid_unfiltered_index\":1414,\"title\":\"GANSynth: Adversarial Neural Audio Synthesis\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"GAN\",\"tldr\":\"High-quality audio synthesis with GANs\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xQVn09FX\"},{\"Index\":1138,\"qgrid_unfiltered_index\":1138,\"title\":\"Learning Implicitly Recurrent CNNs Through Parameter Sharing\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We propose a method that enables CNN folding to create recurrent connections\",\"ratings\":\"[8, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgYxn09Fm\"},{\"Index\":110,\"qgrid_unfiltered_index\":110,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.7,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syx72jC9tm\"},{\"Index\":999,\"qgrid_unfiltered_index\":999,\"title\":\"Unsupervised Domain Adaptation for Distance Metric Learning\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"domain adaptation\",\"tldr\":\"A new theory of unsupervised domain adaptation for distance metric learning and its application to face recognition across diverse ethnicity variations.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BklhAj09K7\"},{\"Index\":113,\"qgrid_unfiltered_index\":113,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkxStoC5F7\"},{\"Index\":1484,\"qgrid_unfiltered_index\":1484,\"title\":\"Learning to Screen for Fast Softmax  Inference on Large Vocabulary Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"fast inference\",\"tldr\":\"\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByeMB3Act7\"},{\"Index\":527,\"qgrid_unfiltered_index\":527,\"title\":\"Near-Optimal Representation Learning for Hierarchical Reinforcement Learning\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"representation hierarchy reinforcement learning\",\"tldr\":\"We translate a bound on sub-optimality of representations to a practical training objective in the context of hierarchical reinforcement learning.\",\"ratings\":\"[6, 6, 9]\",\"confidence\":\"[3, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1emus0qF7\"},{\"Index\":1020,\"qgrid_unfiltered_index\":1020,\"title\":\"Scalable Reversible Generative Models with Free-form Continuous Dynamics\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"generative models\",\"tldr\":\"We use continuous time dynamics to define a generative model with exact likelihoods and efficient sampling that is parameterized by unrestricted neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxgknCcK7\"},{\"Index\":1559,\"qgrid_unfiltered_index\":1559,\"title\":\"Learning sparse relational transition models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deictic reference\",\"tldr\":\"A new approach that learns a representation for describing transition models in complex uncertaindomains using relational rules. \",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJxsV2R5FQ\"},{\"Index\":642,\"qgrid_unfiltered_index\":642,\"title\":\"Greedy Attack and Gumbel Attack: Generating Adversarial Examples for Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"Adversarial Examples\",\"tldr\":\"We develop two methods for generating adversarial examples on discrete data under a probabilistic framework.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[4, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByghKiC5YX\"},{\"Index\":665,\"qgrid_unfiltered_index\":665,\"title\":\"SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"neural network pruning\",\"tldr\":\"We present a new approach, SNIP, that is simple, versatile and interpretable; it prunes irrelevant connections for a given task at single-shot prior to training and is applicable to a variety of neural network models without modifications.\",\"ratings\":\"[6, 6, 9]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1VZqjAcYX\"},{\"Index\":666,\"qgrid_unfiltered_index\":666,\"title\":\"Deep Graph Infomax\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Unsupervised Learning\",\"tldr\":\"A new method for unsupervised representation learning on graphs, relying on maximizing mutual information between local and global representations in a graph. State-of-the-art results, competitive with supervised learning.\",\"ratings\":\"[7, 9, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rklz9iAcKQ\"},{\"Index\":706,\"qgrid_unfiltered_index\":706,\"title\":\"Riemannian Adaptive Optimization Methods\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"Riemannian optimization\",\"tldr\":\"Adapting Adam, Amsgrad, Adagrad to Riemannian manifolds. \",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eiqi09K7\"},{\"Index\":1063,\"qgrid_unfiltered_index\":1063,\"title\":\"ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"text-to-speech\",\"tldr\":\"\",\"ratings\":\"[9, 5, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklY120cYm\"},{\"Index\":1025,\"qgrid_unfiltered_index\":1025,\"title\":\"Feature Intertwiners\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"feature learning\",\"tldr\":\"A feature intertwiner module to leverage features from one accurate set to help the learning of another less reliable set.\",\"ratings\":\"[7, 5, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxZJn05YX\"},{\"Index\":768,\"qgrid_unfiltered_index\":768,\"title\":\"How Important is a Neuron\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"attribution\",\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylKoo0cKm\"},{\"Index\":929,\"qgrid_unfiltered_index\":929,\"title\":\"The Comparative Power of ReLU Networks and Polynomial Kernels in the Presence of Sparse Latent Structure\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"theory\",\"tldr\":\"Beyond-worst-case analysis of the representational power of  ReLU nets & polynomial kernels  -- in particular in the presence of sparse latent structure.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTTjA9tX\"},{\"Index\":794,\"qgrid_unfiltered_index\":794,\"title\":\"Neural network gradient-based learning of black-box function interfaces\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"neural networks\",\"tldr\":\"Training DNNs to interface w\\\\ black box functions w\\\\o intermediate labels by using an estimator sub-network that can be replaced with the black box after training\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1e13s05YX\"},{\"Index\":1077,\"qgrid_unfiltered_index\":1077,\"title\":\"Local SGD Converges Fast and Communicates Little\",\"avg_rating\":7.0,\"avg_confidence\":4.7,\"topic\":\"optimization\",\"tldr\":\"We prove that parallel local SGD achieves linear speedup with much lesser communication than parallel mini-batch SGD.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1g2JnRcFX\"},{\"Index\":1180,\"qgrid_unfiltered_index\":1180,\"title\":\"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"Neural networks\",\"tldr\":\"Feedforward neural networks that can have weights pruned after training could have had the same weights pruned before training\",\"ratings\":\"[5, 8, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl-b3RcF7\"},{\"Index\":748,\"qgrid_unfiltered_index\":748,\"title\":\"Deep Learning 3D Shapes Using Alt-az Anisotropic 2-Sphere Convolution\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"Spherical Convolution\",\"tldr\":\"A method for applying deep learning to 3D surfaces using their spherical descriptors and alt-az anisotropic convolution on 2-sphere.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[3, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkeSiiA5Fm\"},{\"Index\":361,\"qgrid_unfiltered_index\":361,\"title\":\"ADVERSARIAL DOMAIN ADAPTATION FOR STABLE BRAIN-MACHINE INTERFACES\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"Brain-Machine Interfaces\",\"tldr\":\"We implement an adversarial domain adaptation network to stabilize a fixed Brain-Machine Interface against gradual changes in the recorded neural signals.\",\"ratings\":\"[9, 5, 7]\",\"confidence\":\"[4, 3, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hyx6Bi0qYm\"},{\"Index\":949,\"qgrid_unfiltered_index\":949,\"title\":\"Learning Self-Imitating Diverse Policies\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Reinforcement-learning\",\"tldr\":\"Policy optimization by using past good rollouts from the agent; learning shaped rewards via divergence minimization; SVPG with JS-kernel for population-based exploration.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxzRsR9Y7\"},{\"Index\":846,\"qgrid_unfiltered_index\":846,\"title\":\"The effects of neural resource constraints on early visual representations \",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"visual system\",\"tldr\":\"We reproduced neural representations found in biological visual systems by simulating their neural resource constraints in a deep convolutional model.\",\"ratings\":\"[5, 8, 8]\",\"confidence\":\"[5, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xq3oR5tQ\"},{\"Index\":814,\"qgrid_unfiltered_index\":814,\"title\":\"Wizard of Wikipedia: Knowledge-Powered Conversational Agents\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"dialogue\",\"tldr\":\"We build knowledgeable conversational agents by conditioning on Wikipedia + a new supervised task.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1l73iRqKm\"},{\"Index\":541,\"qgrid_unfiltered_index\":541,\"title\":\"Towards the first adversarially robust neural network model on MNIST\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"adversarial examples\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1EHOsC9tX\"},{\"Index\":509,\"qgrid_unfiltered_index\":509,\"title\":\"EMI: Exploration with Mutual Information Maximizing State and Action Embeddings\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[6, 7, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hylyui09tm\"},{\"Index\":562,\"qgrid_unfiltered_index\":562,\"title\":\"Off-Policy Evaluation and Learning from Logged Bandit Feedback: Error Reduction via Surrogate Policy\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"Causal inference\",\"tldr\":\"\",\"ratings\":\"[6, 8, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklKui0ct7\"},{\"Index\":569,\"qgrid_unfiltered_index\":569,\"title\":\"Meta-Learning For Stochastic Gradient MCMC\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"Meta Learning\",\"tldr\":\"This paper proposes a method to automate the design of stochastic gradient MCMC proposal using meta learning approach. \",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkeoOo09YX\"},{\"Index\":611,\"qgrid_unfiltered_index\":611,\"title\":\"Trellis Networks for Sequence Modeling\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"sequence modeling\",\"tldr\":\"Trellis networks are a new sequence modeling architecture that bridges recurrent and convolutional models and sets a new state of the art on word- and character-level language modeling.\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyeVtoRqtQ\"},{\"Index\":1359,\"qgrid_unfiltered_index\":1359,\"title\":\"A Mean Field Theory of Batch Normalization\",\"avg_rating\":6.7,\"avg_confidence\":2.3,\"topic\":\"theory\",\"tldr\":\"Batch normalization causes exploding gradients in vanilla feedforward networks.\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 1, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyMDXnCcF7\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": false,
       "_sort_field": "avg_rating",
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "2eb1ca66-c129-4c41-8ec4-f7d67d082923",
       "layout": "IPY_MODEL_ad1dc4c7b35647c980764bcc15e71e9b",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "1cb9343528a84397adf2d99eafb28f96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1d177234936b4e7cbe46a1c024207d5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1ec3e4489bd046a6a0aa587ed10338d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1f6f587234fd4cdeb6b12e23f5d0b45e": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"State-Regularized Recurrent Networks\",\"avg_confidence\":4.66667,\"avg_rating\":5.66667,\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_confidence\":3.33333,\"avg_rating\":5.66667,\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"The Deep Weight Prior\",\"avg_confidence\":3.66667,\"avg_rating\":6.33333,\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_confidence\":2.66667,\"avg_rating\":7.0,\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"Adversarial Information Factorization\",\"avg_confidence\":4.0,\"avg_rating\":6.0,\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"Attentive Neural Processes\",\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Complement Objective Training\",\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"tldr\":\"\",\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"tldr\":\"\",\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_confidence\":2.0,\"avg_rating\":6.66667,\"tldr\":\"\",\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_confidence\":4.66667,\"avg_rating\":5.33333,\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_confidence\":3.33333,\"avg_rating\":4.66667,\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"tldr\":\"\",\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_confidence\":4.33333,\"avg_rating\":4.33333,\"tldr\":\"\",\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_confidence\":3.25,\"avg_rating\":4.0,\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_confidence\":4.5,\"avg_rating\":6.5,\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learning what you can do before doing anything\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_confidence\":4.0,\"avg_rating\":7.33333,\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_confidence\":4.33333,\"avg_rating\":5.0,\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"tldr\":\"\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_confidence\":3.0,\"avg_rating\":7.0,\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_confidence\":3.66667,\"avg_rating\":4.66667,\"tldr\":\"\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_confidence\":4.0,\"avg_rating\":6.5,\"tldr\":\"\",\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_confidence\":3.0,\"avg_rating\":5.0,\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_confidence\":3.5,\"avg_rating\":5.5,\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"The Problem of Model Completion\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_confidence\":3.0,\"avg_rating\":7.0,\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"tldr\":\"\",\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"tldr\":\"\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_confidence\":4.66667,\"avg_rating\":7.66667,\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Generative Feature Matching Networks\",\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Adversarial Audio Synthesis\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_confidence\":3.0,\"avg_rating\":3.5,\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"tldr\":\"\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Learning Entropic Wasserstein Embeddings\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\",\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Invariance and Inverse Stability under ReLU\",\"avg_confidence\":3.5,\"avg_rating\":6.5,\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\",\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"avg_confidence\":4.5,\"avg_rating\":6.0,\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\",\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\",\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"avg_confidence\":4.0,\"avg_rating\":4.66667,\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\",\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"avg_confidence\":3.33333,\"avg_rating\":6.33333,\"tldr\":\"\",\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Reward Constrained Policy Optimization\",\"avg_confidence\":3.0,\"avg_rating\":6.0,\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\",\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_confidence\":4.66667,\"avg_rating\":7.0,\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"avg_confidence\":3.66667,\"avg_rating\":6.0,\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Adaptive Neural Trees\",\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\",\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"Phrase-Based Attentions\",\"avg_confidence\":4.66667,\"avg_rating\":5.0,\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\",\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Deep Layers as Stochastic Solvers\",\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\",\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\",\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"tldr\":\"\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"avg_confidence\":4.66667,\"avg_rating\":6.33333,\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\",\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"tldr\":\"\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"tldr\":\"\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \",\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"avg_confidence\":4.33333,\"avg_rating\":5.33333,\"tldr\":\"\",\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Feature-Wise Bias Amplification\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"avg_confidence\":4.0,\"avg_rating\":3.66667,\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\",\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Sorting out Lipschitz function approximation\",\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\",\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"avg_confidence\":3.0,\"avg_rating\":6.0,\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\",\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Interpretable Continual Learning\",\"avg_confidence\":3.0,\"avg_rating\":5.5,\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \",\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"Implicit Autoencoders\",\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\",\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"avg_confidence\":4.0,\"avg_rating\":4.33333,\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_confidence\":3.33333,\"avg_rating\":3.66667,\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"avg_confidence\":4.33333,\"avg_rating\":5.66667,\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\",\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"avg_confidence\":4.0,\"avg_rating\":6.0,\"tldr\":\"\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\",\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"avg_confidence\":4.0,\"avg_rating\":6.0,\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"avg_confidence\":4.5,\"avg_rating\":5.5,\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\",\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\",\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \",\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_confidence\":3.0,\"avg_rating\":7.0,\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\",\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"DEEP GRAPH TRANSLATION\",\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"tldr\":\"\",\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "f9871956-91dd-4513-8940-c339774344cf",
       "layout": "IPY_MODEL_b39870dc9c9848488d95a8b39d66ee04",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "241993d79f634fdc9f27a54145c11277": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2513e703316a4a6ea805eaf9ecbd05ac": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 100
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 1000
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 200
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 300
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxfEn09Y7\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"adversarial example\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4dFjR5K7\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"generative models\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke4KsA5FX\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"generative adversarial network\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgYl205tQ\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.3,\"avg_confidence\":3.0,\"topic\":\"model interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1E3Ko09F7\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJg8yhAqKm\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJGtFoC5Fm\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.8,\"topic\":\"adversarial example\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgVRiC9Km\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.7,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTciR9tm\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"artificial intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl42iA5t7\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.3,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylKB3A9Fm\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlxm30cKm\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"neural machine translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eEdj0cK7\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygqqsA9KX\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.2,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygn2o0qKX\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1GLm2R9Km\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke-JhA9Y7\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"inverse reinforcement learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJlmHoR5tQ\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygfghAcYX\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"network compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xLN3C9YX\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"pu learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJzLciCqKm\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1MAJhR5YX\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xsSjC9Ym\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"maximum mean discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkG5SjR5YQ\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"neural networks\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eJssCqY7\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"embedding\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJxeWnCcF7\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.7,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1grRoR9tQ\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgnmhA5KQ\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxnvsAqFm\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.3,\"avg_confidence\":4.3,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxcHnRqYQ\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"adversarial example\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJl2niR9KQ\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxt8oC9FQ\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"life-long learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hkf2_sC5FX\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.7,\"topic\":\"model free rl\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HygsfnR9Ym\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl0r3R9KX\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlk6iRqKX\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklSf3CqKm\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"cnn\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMHpjC9Ym\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJf_YjCqYX\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlEojAqFm\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bye9LiR9YX\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgToo0qFm\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygxb2CqKm\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl2E3AcF7\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4fpoA5Km\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.3,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxBFsRqYm\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyVU6s05K7\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"nlp\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xtAjR5tX\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.7,\"avg_confidence\":4.7,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJf7ts0cFm\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.7,\"avg_confidence\":3.3,\"topic\":\"non convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SklcFsAcKX\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByGuynAct7\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"generative models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representation\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJfRpoA9YX\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syxt2jC5FX\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"neural processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkE6PjC9KX\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyM7AiA5YX\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.7,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1ebTsActm\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"gan\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJeXSo09FQ\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.3,\"avg_confidence\":4.7,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx38iC5KX\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.7,\"avg_confidence\":3.3,\"topic\":\"cnn\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklnzhR9YQ\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"multi agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx7l309Fm\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzjBiR9t7\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"generative adversarial network\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1MB-3RcF7\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.3,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkgnpiR9Y7\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.2,\"topic\":\"deep rl\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1e7hs05Km\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.3,\"topic\":\"dynamic graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyePrhR5KX\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylPMnR9Ym\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyehMhC9Y7\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygm8jC9FQ\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"relgan\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJedV3R5tm\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"model based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke96sC5tm\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryf6Fs09YX\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.3,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke4HiAcY7\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl6As0cF7\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkNksoRctQ\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkemqsC9Fm\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rk4Qso0cKm\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJeQbnA5tm\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xEtoRqtQ\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial example\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"meta learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgK6iA5KX\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bayesian nonparametric\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygHGnRqK7\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.3,\"topic\":\"gans\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryMQ5sRqYX\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedwoC5t7\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1My6sR9tX\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"ai\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1erHoR5t7\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyNvti09KQ\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"direct feedback alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkGiPoC5FX\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"generative deep neural networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syfz6sC9tQ\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByMVTsR5KQ\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional network\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlaYi05tm\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlgNh0qKQ\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 100,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": false,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "8fa70e56-e85c-46b8-af16-09cf7343accc",
       "layout": "IPY_MODEL_4296e5fab9dd4146807813be6b1e047e",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "271b2d7491c94a82adaa4124757c70ab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "29320387796a4b1ab00a8a5be977272e": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "autoHeight": true,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "92bd6c20-05d1-4f92-a1f0-cbf85701c2cf",
       "layout": "IPY_MODEL_e51e07e38bbb4a5392a4e3cdf929ce0b",
       "precision": 5,
       "show_toolbar": true
      }
     },
     "2a14582ab6e8497588878876bec8e92b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2c8132a6733249bb9a02a6a622c27945": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":741,\"qgrid_unfiltered_index\":741,\"confidence\":\"[3, 5, 4]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"Knowledge Flow: Improve Upon Your Teachers\",\"tldr\":\"\\u2018Knowledge Flow\\u2019 trains a deep net (student) by injecting information from multiple nets (teachers). The student is independent upon training and performs very well on learned tasks irrespective of the setting (reinforcement or supervised learning).\"},{\"index\":485,\"qgrid_unfiltered_index\":485,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[4, 4, 3]\",\"title\":\"Encoding Category Trees Into Word-Embeddings Using Geometric Approach\",\"tldr\":\"we show a geometric method to perfectly encode categroy tree information into pre-trained word-embeddings.\"},{\"index\":1180,\"qgrid_unfiltered_index\":1180,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 6]\",\"title\":\"Dimension-Free Bounds for Low-Precision Training\",\"tldr\":\"we proved dimension-independent bounds for low-precision training algorithms\"},{\"index\":1311,\"qgrid_unfiltered_index\":1311,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Contextual Recurrent Convolutional Model for Robust Visual Learning\",\"tldr\":\"we proposed a novel contextual recurrent convolutional network with robust property of visual learning \"},{\"index\":431,\"qgrid_unfiltered_index\":431,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 4, 3]\",\"title\":\"RETHINKING SELF-DRIVING : MULTI -TASK KNOWLEDGE FOR BETTER GENERALIZATION AND ACCIDENT EXPLANATION ABILITY\",\"tldr\":\"we proposed a new self-driving model which is composed of perception module for see and think and driving module for behave to acquire better generalization  and accident explanation ability.\"},{\"index\":1024,\"qgrid_unfiltered_index\":1024,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Wasserstein Barycenter Model Ensembling\",\"tldr\":\"we propose to use Wasserstein barycenters for semantic model ensembling\"},{\"index\":407,\"qgrid_unfiltered_index\":407,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"PRUNING IN TRAINING: LEARNING AND RANKING SPARSE CONNECTIONS IN DEEP CONVOLUTIONAL NETWORKS\",\"tldr\":\"we propose an algorithm of learning to prune network by enforcing structure sparsity penalties\"},{\"index\":1115,\"qgrid_unfiltered_index\":1115,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"Information Regularized Neural Networks\",\"tldr\":\"we propose a regularizer that improves the classification performance of neural networks\"},{\"index\":222,\"qgrid_unfiltered_index\":222,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"Adaptive Convolutional ReLUs\",\"tldr\":\"we propose a novel activation function, ConvReLU, that can better mimic brain neuron activation behaviors and overcome the dying ReLU problem.\"},{\"index\":285,\"qgrid_unfiltered_index\":285,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 4, 4]\",\"title\":\"Stop memorizing: A data-dependent regularization framework for intrinsic pattern learning\",\"tldr\":\"we propose a new framework for data-dependent DNN regularization that can prevent DNNs from overfitting random data or random labels.\"},{\"index\":1543,\"qgrid_unfiltered_index\":1543,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Select Via Proxy: Efficient Data Selection For Training Deep Networks\",\"tldr\":\"we develop an efficient method for selecting training data to quickly and efficiently learn large machine learning models.\"},{\"index\":1547,\"qgrid_unfiltered_index\":1547,\"confidence\":\"[4]\",\"ratings\":\"[5]\",\"title\":\"A Main\\/Subsidiary Network Framework for Simplifying Binary Neural Networks\",\"tldr\":\"we define the filter-level pruning problem for binary neural networks for the first time and propose method to solve it.\"},{\"index\":1287,\"qgrid_unfiltered_index\":1287,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Transferring SLU Models in Novel Domains\",\"tldr\":\"v1\"},{\"index\":1321,\"qgrid_unfiltered_index\":1321,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 5, 3]\",\"title\":\"Learning to Control Visual Abstractions for Structured Exploration in Deep Reinforcement Learning\",\"tldr\":\"structured exploration in deep reinforcement learning via unsupervised visual abstraction discovery and control\"},{\"index\":1524,\"qgrid_unfiltered_index\":1524,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Single Shot Neural Architecture Search Via Direct Sparse Optimization\",\"tldr\":\"single shot neural architecture search via direct sparse optimization\"},{\"index\":331,\"qgrid_unfiltered_index\":331,\"confidence\":\"[3, 5, 3]\",\"ratings\":\"[6, 2, 5]\",\"title\":\"q-Neurons: Neuron Activations based on Stochastic Jackson's Derivative Operators\",\"tldr\":\"q-calculus helps build simple and scalable neural activation functions\"},{\"index\":236,\"qgrid_unfiltered_index\":236,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Precision Highway for Ultra Low-precision Quantization\",\"tldr\":\"precision highway; a generalized concept of high-precision information flow for sub 4-bit quantization \"},{\"index\":1318,\"qgrid_unfiltered_index\":1318,\"confidence\":\"[4, 4, 1]\",\"ratings\":\"[5, 6, 3]\",\"title\":\"Pix2Scene: Learning Implicit 3D Representations from Images\",\"tldr\":\"pix2scene: a deep generative based approach for implicitly modelling the geometrical properties of a 3D scene from images\"},{\"index\":1192,\"qgrid_unfiltered_index\":1192,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[4, 3, 3]\",\"title\":\"ATTACK GRAPH CONVOLUTIONAL NETWORKS BY ADDING FAKE NODES\",\"tldr\":\"non-targeted and targeted attack on GCN by adding fake nodes\"},{\"index\":1395,\"qgrid_unfiltered_index\":1395,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[7, 3, 7]\",\"title\":\"Small steps and giant leaps: Minimal Newton solvers for Deep Learning\",\"tldr\":\"minimal newton solver for deep learning\"},{\"index\":1360,\"qgrid_unfiltered_index\":1360,\"confidence\":\"[4, 4]\",\"ratings\":\"[4, 7]\",\"title\":\"Causal Reasoning from Meta-learning\",\"tldr\":\"meta-learn a learning algorithm capable of causal reasoning\"},{\"index\":1242,\"qgrid_unfiltered_index\":1242,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[6, 4, 7]\",\"title\":\"NECST: Neural Joint Source-Channel Coding\",\"tldr\":\"jointly learn compression + error correcting codes with deep learning\"},{\"index\":853,\"qgrid_unfiltered_index\":853,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Guided Exploration in Deep Reinforcement Learning\",\"tldr\":\"introduces a guided action exploration mechanism that drastically speed up RL training\"},{\"index\":1485,\"qgrid_unfiltered_index\":1485,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Modeling the Long Term Future in Model-Based Reinforcement Learning\",\"tldr\":\"incorporating, in the model, latent variables that encode future content improves the long-term prediction accuracy, which is critical for better planning in model-based RL.\"},{\"index\":410,\"qgrid_unfiltered_index\":410,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 6]\",\"title\":\"DELTA: DEEP LEARNING TRANSFER USING FEATURE MAP WITH ATTENTION FOR CONVOLUTIONAL NETWORKS\",\"tldr\":\"improving deep transfer learning with regularization using attention based feature maps\"},{\"index\":1501,\"qgrid_unfiltered_index\":1501,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[6, 3, 3]\",\"title\":\"Improving machine classification using human uncertainty measurements\",\"tldr\":\"improving classifiers using human uncertainty measurements\"},{\"index\":470,\"qgrid_unfiltered_index\":470,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"S3TA: A Soft, Spatial, Sequential, Top-Down Attention Model\",\"tldr\":\"http:\\/\\/sites.google.com\\/view\\/s3ta\"},{\"index\":324,\"qgrid_unfiltered_index\":324,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[9, 3, 6]\",\"title\":\"SUPERVISED POLICY UPDATE\",\"tldr\":\"first posing and solving the sample efficiency optimization problem in the non-parameterized policy space, and then solving a supervised regression problem to find a parameterized policy that is near the optimal non-parameterized policy.\"},{\"index\":811,\"qgrid_unfiltered_index\":811,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 5]\",\"title\":\"The Case for Full-Matrix Adaptive Regularization\",\"tldr\":\"fast, truly scalable full-matrix AdaGrad\\/Adam, with theory for adaptive stochastic non-convex optimization\"},{\"index\":1197,\"qgrid_unfiltered_index\":1197,\"confidence\":\"[1, 4, 3]\",\"ratings\":\"[6, 5, 9]\",\"title\":\"Dimensionality Reduction for Representing the Knowledge of Probabilistic Models\",\"tldr\":\"dimensionality reduction for cases where examples can be represented as soft probability distributions\"},{\"index\":1519,\"qgrid_unfiltered_index\":1519,\"confidence\":\"[3, 2, 2]\",\"ratings\":\"[3, 3, 2]\",\"title\":\"A CASE STUDY ON OPTIMAL DEEP LEARNING MODEL FOR UAVS\",\"tldr\":\"case study on optimal deep learning model for UAVs\"},{\"index\":301,\"qgrid_unfiltered_index\":301,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Identifying Generalization Properties in Neural Networks\",\"tldr\":\"a theory connecting Hessian of the solution and the generalization power of the model\"},{\"index\":949,\"qgrid_unfiltered_index\":949,\"confidence\":\"[4, 2, 5]\",\"ratings\":\"[5, 4, 6]\",\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\"},{\"index\":1371,\"qgrid_unfiltered_index\":1371,\"confidence\":\"[4, 4, 4, 5]\",\"ratings\":\"[5, 7, 6, 7]\",\"title\":\"Competitive experience replay\",\"tldr\":\"a novel method to learn with sparse reward using adversarial reward re-labeling\"},{\"index\":354,\"qgrid_unfiltered_index\":354,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 3, 3]\",\"title\":\"SHE2: Stochastic Hamiltonian Exploration and Exploitation for Derivative-Free Optimization\",\"tldr\":\"a new derivative-free optimization algorithms derived from Nesterov's accelerated gradient methods and Hamiltonian dynamics\"},{\"index\":1373,\"qgrid_unfiltered_index\":1373,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 3, 4]\",\"title\":\"Pearl: Prototype lEArning via Rule Lists\",\"tldr\":\"a method combining rule list learning and prototype learning \"},{\"index\":1305,\"qgrid_unfiltered_index\":1305,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[4, 4, 3]\",\"title\":\"Efficient Federated Learning via Variational Dropout\",\"tldr\":\"a joint model and gradient sparsification method for federated learning\"},{\"index\":148,\"qgrid_unfiltered_index\":148,\"confidence\":\"[5, 5, 5, 3]\",\"ratings\":\"[5, 4, 5, 6]\",\"title\":\"TTS-GAN: a generative adversarial network for style modeling in a text-to-speech system\",\"tldr\":\"a generative adversarial network for style modeling in a text-to-speech system\"},{\"index\":1334,\"qgrid_unfiltered_index\":1334,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"TENSOR RING NETS ADAPTED DEEP MULTI-TASK LEARNING\",\"tldr\":\"a deep multi-task learning model adapting tensor ring representation\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":384,\"qgrid_unfiltered_index\":384,\"confidence\":\"[5, 5, 5, 5]\",\"ratings\":\"[1, 2, 1, 4]\",\"title\":\"Object detection deep learning networks for Optical Character Recognition\",\"tldr\":\"Yolo \\/ RCNN neural network for object detection adapted to the task of OCR\"},{\"index\":282,\"qgrid_unfiltered_index\":282,\"confidence\":\"[3, 5, 3]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Neural Variational Inference For Embedding Knowledge Graphs\",\"tldr\":\"Working toward generative knowledge graph models to better estimate predictive uncertainty in knowledge inference. \"},{\"index\":756,\"qgrid_unfiltered_index\":756,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[5, 5, 7]\",\"title\":\"signSGD with Majority Vote is Communication Efficient and Byzantine Fault Tolerant\",\"tldr\":\"Workers send gradient signs to the server, and the update is decided by majority vote. We show that this algorithm is convergent, communication efficient and adversarially robust, both in theory and in practice.\"},{\"index\":974,\"qgrid_unfiltered_index\":974,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Inferring Reward Functions from Demonstrators with Unknown Biases\",\"tldr\":\"When we infer preferences from behavior, we can try to improve accuracy by jointly learning a bias model and preferences, though this requires new assumptions to make progress.\"},{\"index\":1272,\"qgrid_unfiltered_index\":1272,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[6, 7, 5, 7]\",\"title\":\"The Implicit Information in an Initial State\",\"tldr\":\"When a robot is deployed in an environment that humans have been acting in, the state of the environment is already optimized for what humans want, and we can use this to infer human preferences.\"},{\"index\":1408,\"qgrid_unfiltered_index\":1408,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 4, 7]\",\"title\":\"Beyond Greedy Ranking: Slate Optimization via List-CVAE\",\"tldr\":\"We used a CVAE type model structure to learn to directly generate slates\\/whole pages for recommendation systems.\"},{\"index\":948,\"qgrid_unfiltered_index\":948,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[5, 4, 9]\",\"title\":\"Detecting Memorization in ReLU Networks\",\"tldr\":\"We use the non-negative rank of ReLU activation matrices as a complexity measure and show it (negatively) correlates with good generalization.\"},{\"index\":1454,\"qgrid_unfiltered_index\":1454,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"Modulating transfer between tasks in gradient-based meta-learning\",\"tldr\":\"We use the connection between gradient-based meta-learning and hierarchical Bayes to learn a mixture of meta-learners that is appropriate for a heterogeneous and evolving task distribution.\"},{\"index\":634,\"qgrid_unfiltered_index\":634,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"Bias-Reduced Uncertainty Estimation for Deep Neural Classifiers\",\"tldr\":\"We use snapshots from the training process to improve any uncertainty estimation method of a DNN classifier.\"},{\"index\":238,\"qgrid_unfiltered_index\":238,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[5, 7, 4]\",\"title\":\"Convolutional Neural Networks on Non-uniform Geometrical Signals Using Euclidean Spectral Transformation\",\"tldr\":\"We use non-Euclidean Fourier Transformation of shapes defined by a simplicial complex for deep learning, achieving significantly better results than point-based sampling techiques used in current 3D learning literature.\"},{\"index\":567,\"qgrid_unfiltered_index\":567,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[3, 3, 6]\",\"title\":\"microGAN: Promoting Variety through Microbatch Discrimination\",\"tldr\":\"We use microbatch discrimination on multi-adversarial GANs to mitigate mode collapse.\"},{\"index\":1142,\"qgrid_unfiltered_index\":1142,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Adversarial Attacks on Graph Neural Networks via Meta Learning\",\"tldr\":\"We use meta-gradients to attack the training procedure of deep neural networks for graphs.\"},{\"index\":952,\"qgrid_unfiltered_index\":952,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[4, 4, 7]\",\"title\":\"Generative Ensembles for Robust Anomaly Detection\",\"tldr\":\"We use generative models to perform out-of-distribution detection, and improve their robustness with uncertainty estimation.\"},{\"index\":500,\"qgrid_unfiltered_index\":500,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 7, 6]\",\"title\":\"A Closer Look at Deep Learning Heuristics: Learning rate restarts, Warmup and Distillation\",\"tldr\":\"We use empirical tools of mode connectivity and SVCCA to investigate neural network training heuristics of learning rate restarts, warmup and knowledge distillation.\"},{\"index\":870,\"qgrid_unfiltered_index\":870,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"A Data-Driven and Distributed Approach to Sparse Signal Representation and Recovery\",\"tldr\":\"We use deep learning techniques to solve the sparse signal representation and recovery problem.\"},{\"index\":1005,\"qgrid_unfiltered_index\":1005,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Scalable Reversible Generative Models with Free-form Continuous Dynamics\",\"tldr\":\"We use continuous time dynamics to define a generative model with exact likelihoods and efficient sampling that is parameterized by unrestricted neural networks.\"},{\"index\":788,\"qgrid_unfiltered_index\":788,\"confidence\":\"[3, 5, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Combining Learned Representations for Combinatorial Optimization\",\"tldr\":\"We use combinations of RBMs to solve number factorization and combinatorial optimization problems.\"},{\"index\":1061,\"qgrid_unfiltered_index\":1061,\"confidence\":\"[5, 4, 3, 3]\",\"ratings\":\"[6, 7, 7, 5]\",\"title\":\"Learning Protein Structure with a Differentiable Simulator\",\"tldr\":\"We use an unrolled simulator of a neural energy function as an end-to-end differentiable model of protein structure and show it can hierarchically generalize to unseen fold types.\"},{\"index\":1146,\"qgrid_unfiltered_index\":1146,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Inducing Cooperation via Learning to reshape rewards in semi-cooperative multi-agent reinforcement learning\",\"tldr\":\"We use an peer evaluation mechanism to make semi-cooperative agents learn collaborative strategies in multiagent reinforcement learning settings\"},{\"index\":1257,\"qgrid_unfiltered_index\":1257,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions\",\"tldr\":\"We use a hypernetwork to predict optimal weights given hyperparameters, and jointly train everything together.\"},{\"index\":1029,\"qgrid_unfiltered_index\":1029,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[4, 4, 4]\",\"title\":\"HyperGAN:  Exploring the Manifold of Neural Networks\",\"tldr\":\"We use a GAN to generate parameters of a neural network in one forward pass.\"},{\"index\":182,\"qgrid_unfiltered_index\":182,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 6, 6]\",\"title\":\"Discriminator Rejection Sampling\",\"tldr\":\"We use a GAN discriminator to perform an approximate rejection sampling scheme on the output of the GAN generator.\"},{\"index\":1249,\"qgrid_unfiltered_index\":1249,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"An Alarm System for Segmentation Algorithm Based on Shape Model\",\"tldr\":\"We use VAE to capture the shape feature for automatic segmentation evaluation\"},{\"index\":1229,\"qgrid_unfiltered_index\":1229,\"confidence\":\"[4, 3, 4, 4]\",\"ratings\":\"[4, 4, 5, 4]\",\"title\":\"Unlabeled Disentangling of GANs with Guided Siamese Networks\",\"tldr\":\"We use Siamese Networks to control and disentangle the generation process in GANs without labeled data.\"},{\"index\":1320,\"qgrid_unfiltered_index\":1320,\"confidence\":\"[3, 5, 2]\",\"ratings\":\"[6, 4, 4]\",\"title\":\"A Proposed Hierarchy of Deep Learning Tasks\",\"tldr\":\"We use 50 GPU years of compute time to study how deep learning scales with more data, and propose a new way to organize the space of problems by difficulty.\"},{\"index\":328,\"qgrid_unfiltered_index\":328,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[4, 4, 6]\",\"title\":\"Like What You Like: Knowledge Distill via Neuron Selectivity Transfer\",\"tldr\":\"We treat knowledge distill as a distribution matching problem and adopt Maximum Mean Discrepancy to minimize the distances between student features and teacher features.\"},{\"index\":491,\"qgrid_unfiltered_index\":491,\"confidence\":\"[3, 5, 5]\",\"ratings\":\"[6, 6, 9]\",\"title\":\"Near-Optimal Representation Learning for Hierarchical Reinforcement Learning\",\"tldr\":\"We translate a bound on sub-optimality of representations to a practical training objective in the context of hierarchical reinforcement learning.\"},{\"index\":595,\"qgrid_unfiltered_index\":595,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Quantile Regression Reinforcement Learning with State Aligned Vector Rewards\",\"tldr\":\"We train with state aligned vector rewards an agent predicting state changes from action distributions, using a new reinforcement learning technique inspired by quantile regression.\"},{\"index\":784,\"qgrid_unfiltered_index\":784,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[6, 4, 7]\",\"title\":\"Integer Networks for Data Compression with Latent-Variable Models\",\"tldr\":\"We train variational models with quantized networks for computational determinism. This enables using them for cross-platform data compression.\"},{\"index\":1332,\"qgrid_unfiltered_index\":1332,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Learning to Navigate the Web\",\"tldr\":\"We train reinforcement learning policies using reward augmentation, curriculum learning, and meta-learning  to successfully navigate web pages.\"},{\"index\":851,\"qgrid_unfiltered_index\":851,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 4, 6]\",\"title\":\"Reliable Uncertainty Estimates in Deep Neural Networks using Noise Contrastive Priors\",\"tldr\":\"We train neural networks to be uncertain on noisy inputs to avoid overconfident predictions outside of the training distribution.\"},{\"index\":1350,\"qgrid_unfiltered_index\":1350,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[3, 4, 4]\",\"title\":\"Unsupervised  one-to-many image translation\",\"tldr\":\"We train an image to image translation network that take as input the source image and a sample from a prior distribution to generate a sample from the target distribution\"},{\"index\":200,\"qgrid_unfiltered_index\":200,\"confidence\":\"[5, 2, 4]\",\"ratings\":\"[8, 8, 8]\",\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\"},{\"index\":154,\"qgrid_unfiltered_index\":154,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Learning a SAT Solver from Single-Bit Supervision\",\"tldr\":\"We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.\"},{\"index\":418,\"qgrid_unfiltered_index\":418,\"confidence\":\"[3, 5, 5]\",\"ratings\":\"[3, 8, 4]\",\"title\":\"Initialized Equilibrium Propagation for Backprop-Free Training\",\"tldr\":\"We train a feedforward network without backprop by using an energy-based model to provide local targets\"},{\"index\":427,\"qgrid_unfiltered_index\":427,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 7]\",\"title\":\"Language Modeling Teaches You More Syntax than Translation Does: Lessons Learned Through Auxiliary Task Analysis\",\"tldr\":\"We throughly compare several pretraining tasks on their ability to induce syntactic information and find that representations from language models consistently perform best, even when trained on relatively small amounts of data.\"},{\"index\":825,\"qgrid_unfiltered_index\":825,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Learning with Random Learning Rates.\",\"tldr\":\"We test stochastic gradient descent with random per-feature learning rates in neural networks, and find performance comparable to using SGD with the optimal learning rate, alleviating the need for learning rate tuning.\"},{\"index\":1155,\"qgrid_unfiltered_index\":1155,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[4, 4, 8]\",\"title\":\"Deep Anomaly Detection with Outlier Exposure\",\"tldr\":\"We teach anomaly detection methods to learn heuristics for spotting new anomalies; experiments are in NLP and vision settings\"},{\"index\":535,\"qgrid_unfiltered_index\":535,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Graph Matching Networks for Learning the Similarity of Graph Structured Objects\",\"tldr\":\"We tackle the problem of similarity learning for structured objects with applications in particular in computer security, and propose a new model graph matching networks that excels on this task.\"},{\"index\":1004,\"qgrid_unfiltered_index\":1004,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[2, 3, 4]\",\"title\":\"Feature quantization for parsimonious and meaningful predictive models\",\"tldr\":\"We tackle discretization of continuous features and grouping of factor levels as a representation learning problem and provide a rigorous way of estimating the best quantization to yield good performance and interpretability.\"},{\"index\":654,\"qgrid_unfiltered_index\":654,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Capacity of Deep Neural Networks under Parameter Quantization\",\"tldr\":\"We suggest the sufficient number of bits for representing weights of DNNs and the optimum bits are conservative when solving real problems.\"},{\"index\":574,\"qgrid_unfiltered_index\":574,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Ada-Boundary: Accelerating the DNN Training via Adaptive Boundary Batch Selection\",\"tldr\":\"We suggest a smart batch selection technique called Ada-Boundary.\"},{\"index\":1091,\"qgrid_unfiltered_index\":1091,\"confidence\":\"[5, 3]\",\"ratings\":\"[5, 7]\",\"title\":\"The role of over-parametrization in generalization of neural networks\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\"},{\"index\":275,\"qgrid_unfiltered_index\":275,\"confidence\":\"[3, 5, 3]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"Stochastic Gradient Descent Learns State Equations with Nonlinear Activations\",\"tldr\":\"We study the state equation of a recurrent neural network. We show that SGD can efficiently learn the unknown dynamics from few input\\/output observations under proper assumptions.\"},{\"index\":155,\"qgrid_unfiltered_index\":155,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 4]\",\"title\":\"Stackelberg GAN: Towards Provable Minimax Equilibrium via Multi-Generator Architectures\",\"tldr\":\"We study the problem of alleviating the instability issue in the GAN training procedure via new architecture design, with theoretical guarantees.\"},{\"index\":957,\"qgrid_unfiltered_index\":957,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[5, 4, 5]\",\"title\":\"When Will Gradient Methods Converge to Max-margin Classifier under ReLU Models?\",\"tldr\":\"We study the implicit bias of gradient methods in solving a binary classification problem with nonlinear ReLU models.\"},{\"index\":1460,\"qgrid_unfiltered_index\":1460,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"What Is in a Translation Unit?  Comparing Character and Subword Representations Beyond Translation\",\"tldr\":\"We study the impact of using different kinds of subword units on the quality of the resulting representations when used to model syntax, semantics, and morphology.\"},{\"index\":422,\"qgrid_unfiltered_index\":422,\"confidence\":\"[3, 5, 5]\",\"ratings\":\"[6, 5, 5]\",\"title\":\"Generalization and Regularization in DQN\",\"tldr\":\"We study the generalization capabilities of DQN using the new modes and difficulties of Atari games. We show how regularization can improve DQN's ability to generalize across tasks, something it often fails to do.\"},{\"index\":266,\"qgrid_unfiltered_index\":266,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 3, 3]\",\"title\":\"Accidental explorationa through value predictors\",\"tldr\":\"We study the biases introduced in common value predictors by the fact that trajectories are, in practice, finite.\"},{\"index\":237,\"qgrid_unfiltered_index\":237,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[9, 6, 8]\",\"title\":\"ON RANDOM DEEP AUTOENCODERS: EXACT ASYMPTOTIC ANALYSIS, PHASE TRANSITIONS, AND IMPLICATIONS TO TRAINING\",\"tldr\":\"We study the behavior of weight-tied multilayer vanilla autoencoders under the assumption of random weights. Via an exact characterization in the limit of large dimensions, our analysis reveals interesting phase transition phenomena.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":1412,\"qgrid_unfiltered_index\":1412,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[3, 5, 6]\",\"title\":\"Text Infilling\",\"tldr\":\"We study a general task of text infilling that fills missing portions of given text; an self-attention model is developed.\"},{\"index\":1345,\"qgrid_unfiltered_index\":1345,\"confidence\":\"[4, 4]\",\"ratings\":\"[5, 4]\",\"title\":\"Fast Exploration with Simplified Models and Approximately Optimistic Planning in Model Based Reinforcement Learning\",\"tldr\":\"We studied exploration with imperfect planning and used object representation to learn simple models and introduced a new sample efficient RL algorithm that achieves state of the art results on Pitfall!\"},{\"index\":837,\"qgrid_unfiltered_index\":837,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 6, 7]\",\"title\":\"Solving the Rubik's Cube with Approximate Policy Iteration\",\"tldr\":\"We solve the Rubik's Cube with pure reinforcement learning\"},{\"index\":1134,\"qgrid_unfiltered_index\":1134,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[5, 7, 4]\",\"title\":\"Random mesh projectors for inverse problems\",\"tldr\":\"We solve ill-posed inverse problems with scarce ground truth examples by estimating an ensemble of random projections of the model instead of the model itself.\"},{\"index\":1488,\"qgrid_unfiltered_index\":1488,\"confidence\":\"[4, 4, 4, 3]\",\"ratings\":\"[5, 4, 4, 5]\",\"title\":\"Music Transformer\",\"tldr\":\"We show the first successful use of Transformer in generating music that exhibits long-term structure. \"},{\"index\":1032,\"qgrid_unfiltered_index\":1032,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 5, 6]\",\"title\":\"Understand the dynamics of GANs via Primal-Dual Optimization\",\"tldr\":\"We show that, with a proper stepsize choice, the widely used first-order iterative algorithm in training GANs would in fact converge to a stationary solution with a sublinear rate.\"},{\"index\":1449,\"qgrid_unfiltered_index\":1449,\"confidence\":\"[5, 4, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Experience replay for continual learning\",\"tldr\":\"We show that, in continual learning settings, catastrophic forgetting can be avoided by applying off-policy RL to a mixture of new and replay experience, with a behavioral cloning loss.\"},{\"index\":599,\"qgrid_unfiltered_index\":599,\"confidence\":\"[4, 4, 3, 3]\",\"ratings\":\"[5, 5, 5, 7]\",\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\"},{\"index\":504,\"qgrid_unfiltered_index\":504,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"On the Turing Completeness of Modern Neural Network Architectures\",\"tldr\":\"We show that the Transformer architecture and the Neural GPU are Turing complete.\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": false,
       "_sort_field": "tldr",
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "c5fd986e-c07a-460c-a2c3-c246d3f5e66f",
       "layout": "IPY_MODEL_7224a25b9bd94c2ca61a9f360b32a8e5",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "3558b52bbc184d678d0e2dacf2a5b57e": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":152,\"qgrid_unfiltered_index\":152,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 4, 5]\",\"title\":\"Partially Mutual Exclusive Softmax for Positive and Unlabeled data\",\"tldr\":\"Defining a partially mutual exclusive softmax loss for postive data and implementing a cooperative based sampling scheme\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1,
       "_row_styles": {},
       "_sort_ascending": false,
       "_sort_field": "tldr",
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "23ef31b3-8b47-4214-ac3f-d6cea2f3cec1",
       "layout": "IPY_MODEL_c2d951eb3eef4603a2b9b1174ee18b8a",
       "precision": 5,
       "show_toolbar": true
      }
     },
     "3c9857800a7c4486a22794da79812055": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "40287962a59a496989be4cf28518825d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "40c00d35953f4805b0b9b34e977cce57": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data. We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "54c1d7ff-7677-4615-a9b1-4185b8f230b1",
       "layout": "IPY_MODEL_cf747af030174adf9a15074e55f21918",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "40dd31db837d4c0b92c17fef3258202c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4219011e71cf4685bac9a9b7ca68fa44": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "maxWidth": null,
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": null
        },
        "index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "maxWidth": null,
         "minWidth": 30,
         "name": "index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "maxWidth": null,
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": null
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "maxWidth": null,
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": null
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "maxWidth": null,
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": null
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "f68a2277-1894-48c4-8a64-ccd2625460d0",
       "layout": "IPY_MODEL_ff001664432c4430ade9e899f5fcafdb",
       "precision": 5,
       "show_toolbar": true
      }
     },
     "42948613ac244d5794755156626dfde1": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "autoHeight": true,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 35,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "fc9a160f-606e-40ae-bb69-3eea6e737d7f",
       "layout": "IPY_MODEL_021c2a64c34f4e50a8ce37fbfc357115",
       "precision": 5,
       "show_toolbar": true
      }
     },
     "4296e5fab9dd4146807813be6b1e047e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "42d19e35314b4ae5a4392c136262358f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "46aea3c4ba914ebf83d9adfbaa56f3d1": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 100
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 1000
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxfEn09Y7\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"adversarial example\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4dFjR5K7\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"generative models\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke4KsA5FX\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"generative adversarial network\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgYl205tQ\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.3,\"avg_confidence\":3.0,\"topic\":\"model interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1E3Ko09F7\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJg8yhAqKm\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJGtFoC5Fm\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.8,\"topic\":\"adversarial example\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgVRiC9Km\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.7,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTciR9tm\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"artificial intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl42iA5t7\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.3,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylKB3A9Fm\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlxm30cKm\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"neural machine translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eEdj0cK7\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygqqsA9KX\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.2,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygn2o0qKX\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1GLm2R9Km\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke-JhA9Y7\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"inverse reinforcement learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJlmHoR5tQ\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygfghAcYX\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"network compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xLN3C9YX\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"pu learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJzLciCqKm\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1MAJhR5YX\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xsSjC9Ym\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"maximum mean discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkG5SjR5YQ\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"neural networks\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eJssCqY7\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"embedding\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJxeWnCcF7\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.7,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1grRoR9tQ\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgnmhA5KQ\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxnvsAqFm\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.3,\"avg_confidence\":4.3,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxcHnRqYQ\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"adversarial example\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJl2niR9KQ\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxt8oC9FQ\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"life-long learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hkf2_sC5FX\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.7,\"topic\":\"model free rl\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HygsfnR9Ym\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl0r3R9KX\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlk6iRqKX\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklSf3CqKm\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"cnn\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMHpjC9Ym\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJf_YjCqYX\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlEojAqFm\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bye9LiR9YX\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgToo0qFm\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygxb2CqKm\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl2E3AcF7\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4fpoA5Km\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.3,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxBFsRqYm\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyVU6s05K7\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"nlp\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xtAjR5tX\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.7,\"avg_confidence\":4.7,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJf7ts0cFm\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.7,\"avg_confidence\":3.3,\"topic\":\"non convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SklcFsAcKX\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByGuynAct7\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"generative models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representation\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJfRpoA9YX\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syxt2jC5FX\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"neural processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkE6PjC9KX\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyM7AiA5YX\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.7,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1ebTsActm\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"gan\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJeXSo09FQ\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.3,\"avg_confidence\":4.7,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx38iC5KX\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.7,\"avg_confidence\":3.3,\"topic\":\"cnn\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklnzhR9YQ\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"multi agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx7l309Fm\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzjBiR9t7\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"generative adversarial network\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1MB-3RcF7\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.3,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkgnpiR9Y7\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.2,\"topic\":\"deep rl\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1e7hs05Km\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.3,\"topic\":\"dynamic graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyePrhR5KX\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylPMnR9Ym\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyehMhC9Y7\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygm8jC9FQ\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"relgan\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJedV3R5tm\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"model based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke96sC5tm\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryf6Fs09YX\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.3,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke4HiAcY7\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl6As0cF7\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkNksoRctQ\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkemqsC9Fm\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rk4Qso0cKm\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJeQbnA5tm\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xEtoRqtQ\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial example\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"meta learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgK6iA5KX\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bayesian nonparametric\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygHGnRqK7\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.3,\"topic\":\"gans\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryMQ5sRqYX\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedwoC5t7\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1My6sR9tX\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"ai\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1erHoR5t7\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyNvti09KQ\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"direct feedback alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkGiPoC5FX\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"generative deep neural networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syfz6sC9tQ\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByMVTsR5KQ\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional network\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlaYi05tm\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlgNh0qKQ\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        16
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 100,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": false,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "7ae3dcb1-93ab-48b5-9591-7f81a61fd2ab",
       "layout": "IPY_MODEL_42d19e35314b4ae5a4392c136262358f",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "46f24c0f312542deab9b2c90c4b99ceb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "471430b6f7b74d53af2850015060c4ce": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 100
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 1000
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 200
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 300
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"},{\"name\":\"topic_qgrid_sort_column\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":1017,\"qgrid_unfiltered_index\":1017,\"title\":\"Exploration by random distillation\",\"avg_rating\":8.7,\"avg_confidence\":4.3,\"topic\":\"reinforcement learning\",\"tldr\":\"A simple exploration bonus is introduced and achieves state of the art performance in 3 hard exploration Atari games.\",\"ratings\":\"[9, 10, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lJJnR5Ym\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":648,\"qgrid_unfiltered_index\":648,\"title\":\"Benchmarking Neural Network Robustness to Common Corruptions and Perturbations\",\"avg_rating\":8.3,\"avg_confidence\":4.0,\"topic\":\"robustness\",\"tldr\":\"We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness\",\"ratings\":\"[7, 9, 9]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJz6tiCqYm\",\"topic_qgrid_sort_column\":\"robustness\"},{\"Index\":707,\"qgrid_unfiltered_index\":707,\"title\":\"Large Scale GAN Training for High Fidelity Natural Image Synthesis\",\"avg_rating\":8.3,\"avg_confidence\":3.7,\"topic\":\"gans\",\"tldr\":\"GANs benefit from scaling up.\",\"ratings\":\"[7, 8, 10]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1xsqj09Fm\",\"topic_qgrid_sort_column\":\"gans\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":950,\"qgrid_unfiltered_index\":950,\"title\":\"Slimmable Neural Networks\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"slimmable neural networks\",\"tldr\":\"We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1gMCsAqY7\",\"topic_qgrid_sort_column\":\"slimmable neural networks\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\",\"topic_qgrid_sort_column\":\"music\"},{\"Index\":1304,\"qgrid_unfiltered_index\":1304,\"title\":\"ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"sparse recovery\",\"tldr\":\"\",\"ratings\":\"[10, 6, 8]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1lnzn0ctQ\",\"topic_qgrid_sort_column\":\"sparse recovery\"},{\"Index\":1442,\"qgrid_unfiltered_index\":1442,\"title\":\"Posterior Attention Models for Sequence to Sequence Learning\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"posterior inference\",\"tldr\":\"Computing attention based on posterior distribution leads to more meaningful attention and better performance\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkltNhC9FX\",\"topic_qgrid_sort_column\":\"posterior inference\"},{\"Index\":878,\"qgrid_unfiltered_index\":878,\"title\":\"GENERATING HIGH FIDELITY IMAGES WITH SUBSCALE PIXEL NETWORKS AND MULTIDIMENSIONAL UPSCALING\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"We show that autoregressive models can generate high fidelity images. \",\"ratings\":\"[10, 7, 7]\",\"confidence\":\"[5, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HylzTiC5Km\",\"topic_qgrid_sort_column\":\"None\"},{\"Index\":717,\"qgrid_unfiltered_index\":717,\"title\":\"Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We introduce a new inductive bias that integrates tree structures in recurrent neural networks.\",\"ratings\":\"[9, 7, 8]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1l6qiR5F7\",\"topic_qgrid_sort_column\":\"deep learning\"},{\"Index\":1115,\"qgrid_unfiltered_index\":1115,\"title\":\"Temporal Difference Variational Auto-Encoder\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"generative models\",\"tldr\":\"Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1x4ghC9tQ\",\"topic_qgrid_sort_column\":\"generative models\"},{\"Index\":1239,\"qgrid_unfiltered_index\":1239,\"title\":\"Supervised Community Detection with Line Graph Neural Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"community detection\",\"tldr\":\"We propose a novel graph neural network architecture based on the non-backtracking operator defined over edge adjacencies and demonstrate its effectiveness on community detection tasks on graphs.\",\"ratings\":\"[6, 9, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1g0Z3A9Fm\",\"topic_qgrid_sort_column\":\"community detection\"},{\"Index\":762,\"qgrid_unfiltered_index\":762,\"title\":\"Learning Unsupervised Learning Rules\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"meta learning\",\"tldr\":\"We learn an unsupervised learning algorithm that produces useful representations from a set of supervised tasks. At test-time, we apply this algorithm to new tasks without any supervision and show performance comparable to a VAE.\",\"ratings\":\"[8, 7, 8]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkNDsiC9KQ\",\"topic_qgrid_sort_column\":\"meta learning\"},{\"Index\":1330,\"qgrid_unfiltered_index\":1330,\"title\":\"Adaptive Input Representations for Neural Language Modeling\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"neural language modeling\",\"tldr\":\"Variable capacity input word embeddings and SOTA on WikiText-103, Billion Word benchmarks.\",\"ratings\":\"[7, 8, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxZX20qFQ\",\"topic_qgrid_sort_column\":\"neural language modeling\"},{\"Index\":614,\"qgrid_unfiltered_index\":614,\"title\":\"Critical Learning Periods in Deep Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.3,\"topic\":\"critical period\",\"tldr\":\"Sensory deficits in early training phases can lead to irreversible performance loss in both artificial and neuronal networks, suggesting information phenomena as the common cause, and point to the importance of the initial transient and forgetting.\",\"ratings\":\"[9, 8, 6]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkeStsCcKQ\",\"topic_qgrid_sort_column\":\"critical period\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\",\"topic_qgrid_sort_column\":\"asynchronous\"},{\"Index\":636,\"qgrid_unfiltered_index\":636,\"title\":\"Sparse Dictionary Learning by Dynamical Neural Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[6, 9, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1gstsCqt7\",\"topic_qgrid_sort_column\":\"None\"},{\"Index\":1154,\"qgrid_unfiltered_index\":1154,\"title\":\"Pay Less Attention with Lightweight and Dynamic Convolutions\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"deep learning\",\"tldr\":\"Dynamic lightweight convolutions are competitive to self-attention on language tasks.\",\"ratings\":\"[8, 7, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkVhlh09tX\",\"topic_qgrid_sort_column\":\"deep learning\"},{\"Index\":450,\"qgrid_unfiltered_index\":450,\"title\":\"Identifying and Controlling Important Neurons in Neural Machine Translation\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"neural machine translation\",\"tldr\":\"Unsupervised methods for finding, analyzing, and controlling important neurons in NMT\",\"ratings\":\"[7, 10, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1z-PsR5KX\",\"topic_qgrid_sort_column\":\"neural machine translation\"},{\"Index\":778,\"qgrid_unfiltered_index\":778,\"title\":\"Learning Robust Representations by Projecting Superficial Statistics Out\",\"avg_rating\":7.7,\"avg_confidence\":3.7,\"topic\":\"domain generalization\",\"tldr\":\"Building on previous work on domain generalization, we hope to produce a classifier that will generalize to previously unseen domains, even when domain identifiers are not available during training.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJEjjoR9K7\",\"topic_qgrid_sort_column\":\"domain generalization\"},{\"Index\":661,\"qgrid_unfiltered_index\":661,\"title\":\"KnockoffGAN: Generating Knockoffs for Feature Selection using Generative Adversarial Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"knockoff model\",\"tldr\":\"\",\"ratings\":\"[6, 10, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByeZ5jC5YQ\",\"topic_qgrid_sort_column\":\"knockoff model\"},{\"Index\":1454,\"qgrid_unfiltered_index\":1454,\"title\":\"A Variational Inequality Perspective on Generative Adversarial Networks\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"optimisation\",\"tldr\":\"We cast GANs in the variational inequality framework and import techniques from this literature to optimize GANs better; we give algorithmic extensions and empirically test their performance for training GANs.\",\"ratings\":\"[8, 8, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1laEnA5Ym\",\"topic_qgrid_sort_column\":\"optimisation\"},{\"Index\":353,\"qgrid_unfiltered_index\":353,\"title\":\"Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware\",\"avg_rating\":7.7,\"avg_confidence\":3.0,\"topic\":\"trusted hardware\",\"tldr\":\"We accelerate secure DNN inference in trusted execution environments (by a factor 4x-20x) by selectively outsourcing the computation of linear layers to a faster yet untrusted co-processor.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJVorjCcKQ\",\"topic_qgrid_sort_column\":\"trusted hardware\"},{\"Index\":1495,\"qgrid_unfiltered_index\":1495,\"title\":\"Composing Complex Skills by Learning Transition Policies with Proximity Reward Induction\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"reinforcement learning\",\"tldr\":\"Transition policies enable agents to execute learned skills smoothly to perform complex tasks.\",\"ratings\":\"[7, 9, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygrBhC5tQ\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":276,\"qgrid_unfiltered_index\":276,\"title\":\"ON RANDOM DEEP AUTOENCODERS: EXACT ASYMPTOTIC ANALYSIS, PHASE TRANSITIONS, AND IMPLICATIONS TO TRAINING\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"random deep autoencoders\",\"tldr\":\"We study the behavior of weight-tied multilayer vanilla autoencoders under the assumption of random weights. Via an exact characterization in the limit of large dimensions, our analysis reveals interesting phase transition phenomena.\",\"ratings\":\"[9, 6, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx54i05tX\",\"topic_qgrid_sort_column\":\"random deep autoencoders\"},{\"Index\":255,\"qgrid_unfiltered_index\":255,\"title\":\"Smoothing the Geometry of Probabilistic Box Embeddings\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"embedding\",\"tldr\":\"Improve hierarchical embedding models using kernel smoothing\",\"ratings\":\"[8, 8, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xSNiRcF7\",\"topic_qgrid_sort_column\":\"embedding\"},{\"Index\":348,\"qgrid_unfiltered_index\":348,\"title\":\"Diffusion Scattering Transforms on Graphs\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"graph neural network\",\"tldr\":\"Stability of scattering transform representations of graph data to deformations of the underlying graph support.\",\"ratings\":\"[9, 6]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygqBiRcFQ\",\"topic_qgrid_sort_column\":\"graph neural network\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\",\"topic_qgrid_sort_column\":\"memory augmented neural networks\"},{\"Index\":662,\"qgrid_unfiltered_index\":662,\"title\":\"On the Minimal Supervision for Training Any Binary Classifier from Only Unlabeled Data\",\"avg_rating\":7.5,\"avg_confidence\":3.5,\"topic\":\"learning from only unlabeled data\",\"tldr\":\"Three class priors are all you need to train deep models from only U data, while any two should not be enough.\",\"ratings\":\"[8, 7]\",\"confidence\":\"[3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1xWcj0qYm\",\"topic_qgrid_sort_column\":\"learning from only unlabeled data\"},{\"Index\":861,\"qgrid_unfiltered_index\":861,\"title\":\"Diversity is All You Need: Learning Skills without a Reward Function\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"reinforcement learning\",\"tldr\":\"We propose an algorithm for learning useful skills without a reward function, and show how these skills can be used to solve downstream tasks.\",\"ratings\":\"[8, 7, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJx63jRqFm\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":1094,\"qgrid_unfiltered_index\":1094,\"title\":\"Gradient descent aligns the layers of deep linear networks\",\"avg_rating\":7.3,\"avg_confidence\":4.3,\"topic\":\"implicit regularization\",\"tldr\":\"\",\"ratings\":\"[7, 9, 6]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJflg30qKX\",\"topic_qgrid_sort_column\":\"implicit regularization\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\",\"topic_qgrid_sort_column\":\"autoencoders\"},{\"Index\":997,\"qgrid_unfiltered_index\":997,\"title\":\"Efficient Training on Very Large Corpora via Gramian Estimation\",\"avg_rating\":7.3,\"avg_confidence\":2.7,\"topic\":\"similarity learning\",\"tldr\":\"We develop efficient methods to train neural embedding models with a dot-product structure, by reformulating the objective function in terms of generalized Gram matrices, and maintaining estimates of those matrices.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[4, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke20iA9Y7\",\"topic_qgrid_sort_column\":\"similarity learning\"},{\"Index\":957,\"qgrid_unfiltered_index\":957,\"title\":\"ProMP: Proximal Meta-Policy Search\",\"avg_rating\":7.3,\"avg_confidence\":3.0,\"topic\":\"meta reinforcement learning\",\"tldr\":\"A novel and theoretically grounded meta-reinforcement learning algorithm\",\"ratings\":\"[6, 7, 9]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxXCi0qFX\",\"topic_qgrid_sort_column\":\"meta reinforcement learning\"},{\"Index\":663,\"qgrid_unfiltered_index\":663,\"title\":\"Approximability of Discriminators Implies Diversity in GANs\",\"avg_rating\":7.3,\"avg_confidence\":2.7,\"topic\":\"theory\",\"tldr\":\"GANs can in principle learn distributions sample-efficiently, if the discriminator class is compact and has strong distinguishing power against the particular generator class.\",\"ratings\":\"[8, 7, 7]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJfW5oA5KQ\",\"topic_qgrid_sort_column\":\"theory\"},{\"Index\":1204,\"qgrid_unfiltered_index\":1204,\"title\":\"Biologically-Plausible Learning Algorithms Can Scale to Large Datasets\",\"avg_rating\":7.3,\"avg_confidence\":4.3,\"topic\":\"biologically plausible learning algorithm\",\"tldr\":\"Biologically plausible learning algorithms, particularly sign-symmetry, works well on ImageNet\",\"ratings\":\"[9, 9, 4]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygvZ209F7\",\"topic_qgrid_sort_column\":\"biologically plausible learning algorithm\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\",\"topic_qgrid_sort_column\":\"visual prediction\"},{\"Index\":478,\"qgrid_unfiltered_index\":478,\"title\":\"Large-Scale Study of Curiosity-Driven Learning\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"exploration\",\"tldr\":\"An agent trained only with curiosity, and no extrinsic reward, does surprisingly well on 54 popular environments, including the suite of Atari games, Mario etc.\",\"ratings\":\"[6, 9, 7]\",\"confidence\":\"[4, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJNwDjAqYX\",\"topic_qgrid_sort_column\":\"exploration\"},{\"Index\":1540,\"qgrid_unfiltered_index\":1540,\"title\":\"Visualizing and Understanding Generative Adversarial Networks\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"gans\",\"tldr\":\"GAN representations are examined in detail, and sets of representation units are found that control the generation of semantic concepts in the output.\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hyg_X2C5FX\",\"topic_qgrid_sort_column\":\"gans\"},{\"Index\":124,\"qgrid_unfiltered_index\":124,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylV-2C9KQ\",\"topic_qgrid_sort_column\":\"natural image model\"},{\"Index\":548,\"qgrid_unfiltered_index\":548,\"title\":\"Evaluating Robustness of Neural Networks with Mixed Integer Programming\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"verification\",\"tldr\":\"We efficiently verify the robustness of deep neural models with over 100,000 ReLUs, certifying more samples than the state-of-the-art and finding more adversarial examples than a strong first-order attack.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[5, 5, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyGIdiRqtm\",\"topic_qgrid_sort_column\":\"verification\"},{\"Index\":1509,\"qgrid_unfiltered_index\":1509,\"title\":\"Label super-resolution networks\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"weakly supervised segmentation\",\"tldr\":\"Super-resolving coarse labels into pixel-level labels, applied to aerial imagery and medical scans.\",\"ratings\":\"[7, 6, 9]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxwShA9Ym\",\"topic_qgrid_sort_column\":\"weakly supervised segmentation\"},{\"Index\":625,\"qgrid_unfiltered_index\":625,\"title\":\"Small nonlinearities in activation functions create bad local minima in neural networks\",\"avg_rating\":7.3,\"avg_confidence\":3.3,\"topic\":\"spurious local minima\",\"tldr\":\"We constructively prove that even the slightest nonlinear activation functions introduce spurious local minima, for general datasets and activation functions.\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke_YiRct7\",\"topic_qgrid_sort_column\":\"spurious local minima\"},{\"Index\":1286,\"qgrid_unfiltered_index\":1286,\"title\":\"LanczosNet: Multi-Scale Deep Graph Convolutional Networks\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedznAqKQ\",\"topic_qgrid_sort_column\":\"None\"},{\"Index\":1253,\"qgrid_unfiltered_index\":1253,\"title\":\"Kernel Change-point Detection with Auxiliary Deep Generative Models\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"deep kernel learning\",\"tldr\":\"In this paper, we propose KL-CPD, a novel kernel learning framework for time series CPD that optimizes a lower bound of test power via an auxiliary generative model as a surrogate to the abnormal distribution. \",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1GbfhRqF7\",\"topic_qgrid_sort_column\":\"deep kernel learning\"},{\"Index\":1252,\"qgrid_unfiltered_index\":1252,\"title\":\"Towards Metamerism via Foveated Style Transfer\",\"avg_rating\":7.3,\"avg_confidence\":4.3,\"topic\":\"metamerism\",\"tldr\":\"We introduce a novel feed-forward framework to generate visual metamers\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJzbG20cFQ\",\"topic_qgrid_sort_column\":\"metamerism\"},{\"Index\":372,\"qgrid_unfiltered_index\":372,\"title\":\"Differentiable Learning-to-Normalize via Switchable Normalization\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"normalization\",\"tldr\":\"\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryggIs0cYQ\",\"topic_qgrid_sort_column\":\"normalization\"},{\"Index\":197,\"qgrid_unfiltered_index\":197,\"title\":\"Learning a SAT Solver from Single-Bit Supervision\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"sat\",\"tldr\":\"We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMC_iA5tm\",\"topic_qgrid_sort_column\":\"sat\"},{\"Index\":242,\"qgrid_unfiltered_index\":242,\"title\":\"Auxiliary Variational MCMC\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"mcmc\",\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1NJqsRctX\",\"topic_qgrid_sort_column\":\"mcmc\"},{\"Index\":929,\"qgrid_unfiltered_index\":929,\"title\":\"The Comparative Power of ReLU Networks and Polynomial Kernels in the Presence of Sparse Latent Structure\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"theory\",\"tldr\":\"Beyond-worst-case analysis of the representational power of  ReLU nets & polynomial kernels  -- in particular in the presence of sparse latent structure.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTTjA9tX\",\"topic_qgrid_sort_column\":\"theory\"},{\"Index\":794,\"qgrid_unfiltered_index\":794,\"title\":\"Neural network gradient-based learning of black-box function interfaces\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"neural networks\",\"tldr\":\"Training DNNs to interface w\\\\ black box functions w\\\\o intermediate labels by using an estimator sub-network that can be replaced with the black box after training\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1e13s05YX\",\"topic_qgrid_sort_column\":\"neural networks\"},{\"Index\":143,\"qgrid_unfiltered_index\":143,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"quantized neural networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJe9rh0cFX\",\"topic_qgrid_sort_column\":\"quantized neural networks\"},{\"Index\":304,\"qgrid_unfiltered_index\":304,\"title\":\"Deep, Skinny Neural Networks are not Universal Approximators\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"neural networks\",\"tldr\":\"This paper proves that skinny neural networks cannot approximate certain functions, no matter how deep they are.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryGgSsAcFQ\",\"topic_qgrid_sort_column\":\"neural networks\"},{\"Index\":345,\"qgrid_unfiltered_index\":345,\"title\":\"DARTS: Differentiable Architecture Search\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"deep learning\",\"tldr\":\"We propose a differentiable architecture search algorithm for both convolutional and recurrent networks, achieving competitive performance with the state of the art using orders of magnitude less computation resources.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eYHoC5FX\",\"topic_qgrid_sort_column\":\"deep learning\"},{\"Index\":361,\"qgrid_unfiltered_index\":361,\"title\":\"ADVERSARIAL DOMAIN ADAPTATION FOR STABLE BRAIN-MACHINE INTERFACES\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"brain-machine interfaces\",\"tldr\":\"We implement an adversarial domain adaptation network to stabilize a fixed Brain-Machine Interface against gradual changes in the recorded neural signals.\",\"ratings\":\"[9, 5, 7]\",\"confidence\":\"[4, 3, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hyx6Bi0qYm\",\"topic_qgrid_sort_column\":\"brain-machine interfaces\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial example\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\",\"topic_qgrid_sort_column\":\"adversarial example\"},{\"Index\":846,\"qgrid_unfiltered_index\":846,\"title\":\"The effects of neural resource constraints on early visual representations \",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"visual system\",\"tldr\":\"We reproduced neural representations found in biological visual systems by simulating their neural resource constraints in a deep convolutional model.\",\"ratings\":\"[5, 8, 8]\",\"confidence\":\"[5, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xq3oR5tQ\",\"topic_qgrid_sort_column\":\"visual system\"},{\"Index\":814,\"qgrid_unfiltered_index\":814,\"title\":\"Wizard of Wikipedia: Knowledge-Powered Conversational Agents\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"dialogue\",\"tldr\":\"We build knowledgeable conversational agents by conditioning on Wikipedia + a new supervised task.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1l73iRqKm\",\"topic_qgrid_sort_column\":\"dialogue\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\",\"topic_qgrid_sort_column\":\"deep learning\"},{\"Index\":383,\"qgrid_unfiltered_index\":383,\"title\":\"An analytic theory of generalization dynamics and transfer learning in deep linear networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"generalization\",\"tldr\":\"We provide many insights into neural network generalization from the theoretically tractable linear case.\",\"ratings\":\"[8, 7, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryfMLoCqtQ\",\"topic_qgrid_sort_column\":\"generalization\"},{\"Index\":768,\"qgrid_unfiltered_index\":768,\"title\":\"How Important is a Neuron\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"attribution\",\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylKoo0cKm\",\"topic_qgrid_sort_column\":\"attribution\"},{\"Index\":110,\"qgrid_unfiltered_index\":110,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.7,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syx72jC9tm\",\"topic_qgrid_sort_column\":\"graph learning\"},{\"Index\":748,\"qgrid_unfiltered_index\":748,\"title\":\"Deep Learning 3D Shapes Using Alt-az Anisotropic 2-Sphere Convolution\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"spherical convolution\",\"tldr\":\"A method for applying deep learning to 3D surfaces using their spherical descriptors and alt-az anisotropic convolution on 2-sphere.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[3, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkeSiiA5Fm\",\"topic_qgrid_sort_column\":\"spherical convolution\"},{\"Index\":527,\"qgrid_unfiltered_index\":527,\"title\":\"Near-Optimal Representation Learning for Hierarchical Reinforcement Learning\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"representation hierarchy reinforcement learning\",\"tldr\":\"We translate a bound on sub-optimality of representations to a practical training objective in the context of hierarchical reinforcement learning.\",\"ratings\":\"[6, 6, 9]\",\"confidence\":\"[3, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1emus0qF7\",\"topic_qgrid_sort_column\":\"representation hierarchy reinforcement learning\"},{\"Index\":100,\"qgrid_unfiltered_index\":100,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylCrnCcFX\",\"topic_qgrid_sort_column\":\"None\"},{\"Index\":102,\"qgrid_unfiltered_index\":102,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkxjYoCqKX\",\"topic_qgrid_sort_column\":\"quantization\"},{\"Index\":706,\"qgrid_unfiltered_index\":706,\"title\":\"Riemannian Adaptive Optimization Methods\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"riemannian optimization\",\"tldr\":\"Adapting Adam, Amsgrad, Adagrad to Riemannian manifolds. \",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eiqi09K7\",\"topic_qgrid_sort_column\":\"riemannian optimization\"},{\"Index\":666,\"qgrid_unfiltered_index\":666,\"title\":\"Deep Graph Infomax\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"unsupervised learning\",\"tldr\":\"A new method for unsupervised representation learning on graphs, relying on maximizing mutual information between local and global representations in a graph. State-of-the-art results, competitive with supervised learning.\",\"ratings\":\"[7, 9, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rklz9iAcKQ\",\"topic_qgrid_sort_column\":\"unsupervised learning\"},{\"Index\":665,\"qgrid_unfiltered_index\":665,\"title\":\"SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"neural network pruning\",\"tldr\":\"We present a new approach, SNIP, that is simple, versatile and interpretable; it prunes irrelevant connections for a given task at single-shot prior to training and is applicable to a variety of neural network models without modifications.\",\"ratings\":\"[6, 6, 9]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1VZqjAcYX\",\"topic_qgrid_sort_column\":\"neural network pruning\"},{\"Index\":642,\"qgrid_unfiltered_index\":642,\"title\":\"Greedy Attack and Gumbel Attack: Generating Adversarial Examples for Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"adversarial example\",\"tldr\":\"We develop two methods for generating adversarial examples on discrete data under a probabilistic framework.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[4, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByghKiC5YX\",\"topic_qgrid_sort_column\":\"adversarial example\"},{\"Index\":113,\"qgrid_unfiltered_index\":113,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkxStoC5F7\",\"topic_qgrid_sort_column\":\"probabilistic models\"},{\"Index\":1559,\"qgrid_unfiltered_index\":1559,\"title\":\"Learning sparse relational transition models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"deictic reference\",\"tldr\":\"A new approach that learns a representation for describing transition models in complex uncertaindomains using relational rules. \",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJxsV2R5FQ\",\"topic_qgrid_sort_column\":\"deictic reference\"},{\"Index\":921,\"qgrid_unfiltered_index\":921,\"title\":\"How Powerful are Graph Neural Networks?\",\"avg_rating\":7.0,\"avg_confidence\":5.0,\"topic\":\"graph neural network\",\"tldr\":\"We develop theoretical foundations for expressive power of GNNs and design a provably most powerful GNN.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryGs6iA5Km\",\"topic_qgrid_sort_column\":\"graph neural network\"},{\"Index\":1280,\"qgrid_unfiltered_index\":1280,\"title\":\"Lagging Inference Networks and Posterior Collapse in Variational Autoencoders\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"variational autoencoders\",\"tldr\":\"To address posterior collapse in VAEs, we propose a simple yet effective training algorithm that aggressively optimizes inference network with more updates\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylDfnCqF7\",\"topic_qgrid_sort_column\":\"variational autoencoders\"},{\"Index\":1025,\"qgrid_unfiltered_index\":1025,\"title\":\"Feature Intertwiners\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"feature learning\",\"tldr\":\"A feature intertwiner module to leverage features from one accurate set to help the learning of another less reliable set.\",\"ratings\":\"[7, 5, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxZJn05YX\",\"topic_qgrid_sort_column\":\"feature learning\"},{\"Index\":1108,\"qgrid_unfiltered_index\":1108,\"title\":\"Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word Vectors\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"word vectors\",\"tldr\":\"Max-pooled word vectors with fuzzy Jaccard set similarity are an extremely competitive baseline for semantic similarity; we propose a simple dynamic variant that performs even better.\",\"ratings\":\"[8, 8, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxXg2C5FX\",\"topic_qgrid_sort_column\":\"word vectors\"},{\"Index\":1103,\"qgrid_unfiltered_index\":1103,\"title\":\"The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"neuro-symbolic representations\",\"tldr\":\"We present a Neuro-Symbolic Concept Learner to learn visual concepts, words, and semantic parsing of sentences without explicit annotations for any of them. \",\"ratings\":\"[7, 5, 9]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgMlhRctm\",\"topic_qgrid_sort_column\":\"neuro-symbolic representations\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"generative models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\",\"topic_qgrid_sort_column\":\"generative models\"},{\"Index\":1180,\"qgrid_unfiltered_index\":1180,\"title\":\"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"neural networks\",\"tldr\":\"Feedforward neural networks that can have weights pruned after training could have had the same weights pruned before training\",\"ratings\":\"[5, 8, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl-b3RcF7\",\"topic_qgrid_sort_column\":\"neural networks\"},{\"Index\":1077,\"qgrid_unfiltered_index\":1077,\"title\":\"Local SGD Converges Fast and Communicates Little\",\"avg_rating\":7.0,\"avg_confidence\":4.7,\"topic\":\"optimisation\",\"tldr\":\"We prove that parallel local SGD achieves linear speedup with much lesser communication than parallel mini-batch SGD.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1g2JnRcFX\",\"topic_qgrid_sort_column\":\"optimisation\"},{\"Index\":1484,\"qgrid_unfiltered_index\":1484,\"title\":\"Learning to Screen for Fast Softmax  Inference on Large Vocabulary Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"fast inference\",\"tldr\":\"\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByeMB3Act7\",\"topic_qgrid_sort_column\":\"fast inference\"},{\"Index\":1063,\"qgrid_unfiltered_index\":1063,\"title\":\"ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"text-to-speech\",\"tldr\":\"\",\"ratings\":\"[9, 5, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklY120cYm\",\"topic_qgrid_sort_column\":\"text-to-speech\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\",\"topic_qgrid_sort_column\":\"None\"},{\"Index\":1232,\"qgrid_unfiltered_index\":1232,\"title\":\"Learning Neural PDE Solvers with Convergence Guarantees\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"partial differential equation\",\"tldr\":\"We learn a fast neural solver for PDEs that has convergence guarantees.\",\"ratings\":\"[7, 8, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rklaWn0qK7\",\"topic_qgrid_sort_column\":\"partial differential equation\"},{\"Index\":1138,\"qgrid_unfiltered_index\":1138,\"title\":\"Learning Implicitly Recurrent CNNs Through Parameter Sharing\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We propose a method that enables CNN folding to create recurrent connections\",\"ratings\":\"[8, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgYxn09Fm\",\"topic_qgrid_sort_column\":\"deep learning\"},{\"Index\":1268,\"qgrid_unfiltered_index\":1268,\"title\":\"Improving the Differentiable Neural Computer Through Memory Masking, De-allocation, and Link Distribution Sharpness Control\",\"avg_rating\":7.0,\"avg_confidence\":5.0,\"topic\":\"rna\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyGEM3C9KQ\",\"topic_qgrid_sort_column\":\"rna\"},{\"Index\":1119,\"qgrid_unfiltered_index\":1119,\"title\":\"What do you learn from context? Probing for sentence structure in contextualized word representations\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"natural language processing\",\"tldr\":\"We probe for sentence structure in ELMo and related contextual embedding models. We find existing models efficiently encode syntax and show evidence of long-range dependencies, but only offer small improvements on semantic tasks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJzSgnRcKX\",\"topic_qgrid_sort_column\":\"natural language processing\"},{\"Index\":1020,\"qgrid_unfiltered_index\":1020,\"title\":\"Scalable Reversible Generative Models with Free-form Continuous Dynamics\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"generative models\",\"tldr\":\"We use continuous time dynamics to define a generative model with exact likelihoods and efficient sampling that is parameterized by unrestricted neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxgknCcK7\",\"topic_qgrid_sort_column\":\"generative models\"},{\"Index\":1530,\"qgrid_unfiltered_index\":1530,\"title\":\"Global-to-local Memory Pointer Networks for Task-Oriented Dialogue\",\"avg_rating\":7.0,\"avg_confidence\":2.3,\"topic\":\"pointer networks\",\"tldr\":\"We propose a global memory encoder and a global memory decoder that share an external knowledge to strengthen task-oriented dialogue generation via sketch responses and pointer networks. \",\"ratings\":\"[8, 8, 5]\",\"confidence\":\"[2, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryxnHhRqFm\",\"topic_qgrid_sort_column\":\"pointer networks\"},{\"Index\":949,\"qgrid_unfiltered_index\":949,\"title\":\"Learning Self-Imitating Diverse Policies\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"Policy optimization by using past good rollouts from the agent; learning shaped rewards via divergence minimization; SVPG with JS-kernel for population-based exploration.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxzRsR9Y7\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":1414,\"qgrid_unfiltered_index\":1414,\"title\":\"GANSynth: Adversarial Neural Audio Synthesis\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"gnn\",\"tldr\":\"High-quality audio synthesis with GANs\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xQVn09FX\",\"topic_qgrid_sort_column\":\"gnn\"},{\"Index\":1337,\"qgrid_unfiltered_index\":1337,\"title\":\"Learning to Navigate the Web\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"navigating web pages\",\"tldr\":\"We train reinforcement learning policies using reward augmentation, curriculum learning, and meta-learning  to successfully navigate web pages.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJemQ209FQ\",\"topic_qgrid_sort_column\":\"navigating web pages\"},{\"Index\":999,\"qgrid_unfiltered_index\":999,\"title\":\"Unsupervised Domain Adaptation for Distance Metric Learning\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"domain adaptation\",\"tldr\":\"A new theory of unsupervised domain adaptation for distance metric learning and its application to face recognition across diverse ethnicity variations.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BklhAj09K7\",\"topic_qgrid_sort_column\":\"domain adaptation\"},{\"Index\":1313,\"qgrid_unfiltered_index\":1313,\"title\":\"Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based RL\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"meta learning\",\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxAfnA5tm\",\"topic_qgrid_sort_column\":\"meta learning\"},{\"Index\":493,\"qgrid_unfiltered_index\":493,\"title\":\"Visual Explanation by Interpretation: Improving Visual Feedback Capabilities of Deep Neural Networks\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"model explanation\",\"tldr\":\"Interpretation by Identifying model-learned features that serve as indicators for the task of interest. Explain model decisions by highlighting the response of these features in test data. Evaluate explanations objectively with a controlled dataset.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1ziPjC5Fm\",\"topic_qgrid_sort_column\":\"model explanation\"},{\"Index\":502,\"qgrid_unfiltered_index\":502,\"title\":\"Woulda, Coulda, Shoulda: Counterfactually-Guided Policy Search\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[6, 7, 7]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJG0voC9YQ\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":422,\"qgrid_unfiltered_index\":422,\"title\":\"Sample Efficient Adaptive Text-to-Speech\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"few shot\",\"tldr\":\"Sample efficient algorithms to adapt a text-to-speech model to a new voice style with the state-of-the-art performance.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkzjUoAcFX\",\"topic_qgrid_sort_column\":\"few shot\"},{\"Index\":410,\"qgrid_unfiltered_index\":410,\"title\":\"Analysis of Quantized Deep Networks\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"weight quantization\",\"tldr\":\"\",\"ratings\":\"[6, 7, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryM_IoAqYX\",\"topic_qgrid_sort_column\":\"weight quantization\"},{\"Index\":1431,\"qgrid_unfiltered_index\":1431,\"title\":\"K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJxvEh0cFQ\",\"topic_qgrid_sort_column\":\"deep learning\"},{\"Index\":509,\"qgrid_unfiltered_index\":509,\"title\":\"EMI: Exploration with Mutual Information Maximizing State and Action Embeddings\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[6, 7, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hylyui09tm\",\"topic_qgrid_sort_column\":\"reinforcement learning\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": false,
       "_sort_field": "avg_rating",
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        16
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 100,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": false,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "6bccde3e-6873-4cb0-a873-3f9d4adeb8f4",
       "layout": "IPY_MODEL_241993d79f634fdc9f27a54145c11277",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "47635fbcb4b64ec5b5c1b6a9e260e22c": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 150
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.66667,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.66667,\"avg_confidence\":3.33333,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Complement Objective Training\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.66667,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.33333,\"avg_confidence\":4.66667,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.33333,\"avg_confidence\":4.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.25,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.5,\"avg_confidence\":4.5,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 8]\",\"confidence\":\"[5, 4]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":6.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[8, 5]\",\"confidence\":\"[4, 4]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Learning Entropic Wasserstein Embeddings\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Embedding\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\",\"ratings\":\"[7, 7, 3]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"sgd\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\",\"ratings\":\"[6, 6, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Invariance and Inverse Stability under ReLU\",\"avg_rating\":6.5,\"avg_confidence\":3.5,\"topic\":\"deep neural networks\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\",\"ratings\":\"[6, 7]\",\"confidence\":\"[4, 3]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"avg_rating\":6.0,\"avg_confidence\":4.5,\"topic\":\"VAE\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\",\"ratings\":\"[4, 8]\",\"confidence\":\"[4, 5]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep learning\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"avg_rating\":4.66667,\"avg_confidence\":4.0,\"topic\":\"GAN\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"avg_rating\":6.33333,\"avg_confidence\":3.33333,\"topic\":\"dialogue\",\"tldr\":\"\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Reward Constrained Policy Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\",\"ratings\":\"[6, 7, 5]\",\"confidence\":\"[4, 2, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.66667,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"avg_rating\":6.0,\"avg_confidence\":3.66667,\"topic\":\"rotation equivariance\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\",\"ratings\":\"[7, 3, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Graph\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Adaptive Neural Trees\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"neural networks\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"Phrase-Based Attentions\",\"avg_rating\":5.0,\"avg_confidence\":4.66667,\"topic\":\"neural machine translation\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Deep Layers as Stochastic Solvers\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep networks\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[4, 5, 1]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Sparse rewards\",\"tldr\":\"\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"avg_rating\":6.33333,\"avg_confidence\":4.66667,\"topic\":\"domain adaptation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"crowdsourcing\",\"tldr\":\"\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"unsupervised learning\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\",\"ratings\":\"[5, 3, 9]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"imitation learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[8, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"relation representations\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"avg_rating\":5.33333,\"avg_confidence\":4.33333,\"topic\":\"Empirical Bayes\",\"tldr\":\"\",\"ratings\":\"[6, 3, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Feature-Wise Bias Amplification\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"bias\",\"tldr\":\"\",\"ratings\":\"[6, 7, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"avg_rating\":3.66667,\"avg_confidence\":4.0,\"topic\":\"Neural Response Generation\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\",\"ratings\":\"[3, 7, 1]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Sorting out Lipschitz function approximation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"agent evaluation\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Interpretable Continual Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.0,\"topic\":\"Interpretability\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \",\"ratings\":\"[5, 6]\",\"confidence\":\"[3, 3]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"Implicit Autoencoders\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Unsupervised Learning\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\",\"ratings\":\"[2, 7, 6]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"avg_rating\":4.33333,\"avg_confidence\":4.0,\"topic\":\"Hierarchical reinforcement learning\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_rating\":3.66667,\"avg_confidence\":3.33333,\"topic\":\"visualization\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"ratings\":\"[4, 3, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"avg_rating\":5.66667,\"avg_confidence\":4.33333,\"topic\":\"cross-lingual transfer learning\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"word embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"VAE\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"preconditioner\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\",\"ratings\":\"[8, 4, 7]\",\"confidence\":\"[5, 5, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Model quantization\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\",\"ratings\":\"[8, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"avg_rating\":5.5,\"avg_confidence\":4.5,\"topic\":\"neural program repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\",\"ratings\":\"[6, 5]\",\"confidence\":\"[4, 5]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"unsupervised learning\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \",\"ratings\":\"[7, 5, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"positive-unlabeled learning\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 3, 3]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"DEEP GRAPH TRANSLATION\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[2, 4, 4]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "f0c5ac88-1a11-4128-bd50-36220871e011",
       "layout": "IPY_MODEL_92466b87f1544b18a0257ac0a88cb9ba",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "480dcb8d871845d09d8496d4c734e64a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4b491a9d2c5a41148a45556b30e0dc5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4b51be3e3cdf4b1181ba6d971d61813b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4babd21974c04b8580038f09dd84f120": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "55cdc02631cb45eeae4b2e28b058968a": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":1002,\"qgrid_unfiltered_index\":1002,\"avg_confidence\":4.33333,\"avg_rating\":8.66667,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[9, 10, 7]\",\"title\":\"Exploration by random distillation\",\"tldr\":\"A simple exploration bonus is introduced and achieves state of the art performance in 3 hard exploration Atari games.\"},{\"index\":679,\"qgrid_unfiltered_index\":679,\"avg_confidence\":3.66667,\"avg_rating\":8.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 8, 10]\",\"title\":\"Large Scale GAN Training for High Fidelity Natural Image Synthesis\",\"tldr\":\"GANs benefit from scaling up.\"},{\"index\":618,\"qgrid_unfiltered_index\":618,\"avg_confidence\":4.0,\"avg_rating\":8.33333,\"confidence\":\"[3, 5, 4]\",\"ratings\":\"[7, 9, 9]\",\"title\":\"Benchmarking Neural Network Robustness to Common Corruptions and Perturbations\",\"tldr\":\"We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness\"},{\"index\":1298,\"qgrid_unfiltered_index\":1298,\"avg_confidence\":4.33333,\"avg_rating\":8.0,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[10, 6, 8]\",\"title\":\"ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA\",\"tldr\":\"\"},{\"index\":200,\"qgrid_unfiltered_index\":200,\"avg_confidence\":3.66667,\"avg_rating\":8.0,\"confidence\":\"[5, 2, 4]\",\"ratings\":\"[8, 8, 8]\",\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\"},{\"index\":689,\"qgrid_unfiltered_index\":689,\"avg_confidence\":3.66667,\"avg_rating\":8.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[9, 7, 8]\",\"title\":\"Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks\",\"tldr\":\"We introduce a new inductive bias that integrates tree structures in recurrent neural networks.\"},{\"index\":931,\"qgrid_unfiltered_index\":931,\"avg_confidence\":4.33333,\"avg_rating\":8.0,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[8, 9, 7]\",\"title\":\"Slimmable Neural Networks\",\"tldr\":\"We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.\"},{\"index\":1440,\"qgrid_unfiltered_index\":1440,\"avg_confidence\":4.33333,\"avg_rating\":8.0,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[8, 9, 7]\",\"title\":\"Posterior Attention Models for Sequence to Sequence Learning\",\"tldr\":\"Computing attention based on posterior distribution leads to more meaningful attention and better performance\"},{\"index\":1104,\"qgrid_unfiltered_index\":1104,\"avg_confidence\":4.33333,\"avg_rating\":8.0,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[8, 9, 7]\",\"title\":\"Temporal Difference Variational Auto-Encoder\",\"tldr\":\"Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.\"},{\"index\":1116,\"qgrid_unfiltered_index\":1116,\"avg_confidence\":3.33333,\"avg_rating\":8.0,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[6, 10, 8]\",\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\"},{\"index\":857,\"qgrid_unfiltered_index\":857,\"avg_confidence\":3.66667,\"avg_rating\":8.0,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[10, 7, 7]\",\"title\":\"GENERATING HIGH FIDELITY IMAGES WITH SUBSCALE PIXEL NETWORKS AND MULTIDIMENSIONAL UPSCALING\",\"tldr\":\"We show that autoregressive models can generate high fidelity images. \"},{\"index\":605,\"qgrid_unfiltered_index\":605,\"avg_confidence\":4.0,\"avg_rating\":7.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 9, 8]\",\"title\":\"Sparse Dictionary Learning by Dynamical Neural Networks\",\"tldr\":\"\"},{\"index\":1493,\"qgrid_unfiltered_index\":1493,\"avg_confidence\":4.0,\"avg_rating\":7.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 9, 7]\",\"title\":\"Composing Complex Skills by Learning Transition Policies with Proximity Reward Induction\",\"tldr\":\"Transition policies enable agents to execute learned skills smoothly to perform complex tasks.\"},{\"index\":1145,\"qgrid_unfiltered_index\":1145,\"avg_confidence\":4.0,\"avg_rating\":7.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 7, 8]\",\"title\":\"Pay Less Attention with Lightweight and Dynamic Convolutions\",\"tldr\":\"Dynamic lightweight convolutions are competitive to self-attention on language tasks.\"},{\"index\":216,\"qgrid_unfiltered_index\":216,\"avg_confidence\":3.33333,\"avg_rating\":7.66667,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[8, 8, 7]\",\"title\":\"Smoothing the Geometry of Probabilistic Box Embeddings\",\"tldr\":\"Improve hierarchical embedding models using kernel smoothing\"},{\"index\":631,\"qgrid_unfiltered_index\":631,\"avg_confidence\":4.0,\"avg_rating\":7.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 10, 7]\",\"title\":\"KnockoffGAN: Generating Knockoffs for Feature Selection using Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":237,\"qgrid_unfiltered_index\":237,\"avg_confidence\":4.0,\"avg_rating\":7.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[9, 6, 8]\",\"title\":\"ON RANDOM DEEP AUTOENCODERS: EXACT ASYMPTOTIC ANALYSIS, PHASE TRANSITIONS, AND IMPLICATIONS TO TRAINING\",\"tldr\":\"We study the behavior of weight-tied multilayer vanilla autoencoders under the assumption of random weights. Via an exact characterization in the limit of large dimensions, our analysis reveals interesting phase transition phenomena.\"},{\"index\":1452,\"qgrid_unfiltered_index\":1452,\"avg_confidence\":3.33333,\"avg_rating\":7.66667,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 8, 7]\",\"title\":\"A Variational Inequality Perspective on Generative Adversarial Networks\",\"tldr\":\"We cast GANs in the variational inequality framework and import techniques from this literature to optimize GANs better; we give algorithmic extensions and empirically test their performance for training GANs.\"},{\"index\":315,\"qgrid_unfiltered_index\":315,\"avg_confidence\":3.0,\"avg_rating\":7.66667,\"confidence\":\"[3, 2, 4]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware\",\"tldr\":\"We accelerate secure DNN inference in trusted execution environments (by a factor 4x-20x) by selectively outsourcing the computation of linear layers to a faster yet untrusted co-processor.\"},{\"index\":1325,\"qgrid_unfiltered_index\":1325,\"avg_confidence\":4.0,\"avg_rating\":7.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 8, 8]\",\"title\":\"Adaptive Input Representations for Neural Language Modeling\",\"tldr\":\"Variable capacity input word embeddings and SOTA on WikiText-103, Billion Word benchmarks.\"},{\"index\":736,\"qgrid_unfiltered_index\":736,\"avg_confidence\":3.33333,\"avg_rating\":7.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 8]\",\"title\":\"Learning Unsupervised Learning Rules\",\"tldr\":\"We learn an unsupervised learning algorithm that produces useful representations from a set of supervised tasks. At test-time, we apply this algorithm to new tasks without any supervision and show performance comparable to a VAE.\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"avg_confidence\":4.66667,\"avg_rating\":7.66667,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":752,\"qgrid_unfiltered_index\":752,\"avg_confidence\":3.66667,\"avg_rating\":7.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"Learning Robust Representations by Projecting Superficial Statistics Out\",\"tldr\":\"Building on previous work on domain generalization, we hope to produce a classifier that will generalize to previously unseen domains, even when domain identifiers are not available during training.\"},{\"index\":581,\"qgrid_unfiltered_index\":581,\"avg_confidence\":4.33333,\"avg_rating\":7.66667,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[9, 8, 6]\",\"title\":\"Critical Learning Periods in Deep Networks\",\"tldr\":\"Sensory deficits in early training phases can lead to irreversible performance loss in both artificial and neuronal networks, suggesting information phenomena as the common cause, and point to the importance of the initial transient and forgetting.\"},{\"index\":1231,\"qgrid_unfiltered_index\":1231,\"avg_confidence\":4.0,\"avg_rating\":7.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 9, 8]\",\"title\":\"Supervised Community Detection with Line Graph Neural Networks\",\"tldr\":\"We propose a novel graph neural network architecture based on the non-backtracking operator defined over edge adjacencies and demonstrate its effectiveness on community detection tasks on graphs.\"},{\"index\":413,\"qgrid_unfiltered_index\":413,\"avg_confidence\":3.33333,\"avg_rating\":7.66667,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[7, 10, 6]\",\"title\":\"Identifying and Controlling Important Neurons in Neural Machine Translation\",\"tldr\":\"Unsupervised methods for finding, analyzing, and controlling important neurons in NMT\"},{\"index\":309,\"qgrid_unfiltered_index\":309,\"avg_confidence\":4.0,\"avg_rating\":7.5,\"confidence\":\"[5, 3]\",\"ratings\":\"[9, 6]\",\"title\":\"Diffusion Scattering Transforms on Graphs\",\"tldr\":\"Stability of scattering transform representations of graph data to deformations of the underlying graph support.\"},{\"index\":1196,\"qgrid_unfiltered_index\":1196,\"avg_confidence\":4.33333,\"avg_rating\":7.33333,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[9, 9, 4]\",\"title\":\"Biologically-Plausible Learning Algorithms Can Scale to Large Datasets\",\"tldr\":\"Biologically plausible learning algorithms, particularly sign-symmetry, works well on ImageNet\"},{\"index\":633,\"qgrid_unfiltered_index\":633,\"avg_confidence\":2.66667,\"avg_rating\":7.33333,\"confidence\":\"[2, 3, 3]\",\"ratings\":\"[8, 7, 7]\",\"title\":\"Approximability of Discriminators Implies Diversity in GANs\",\"tldr\":\"GANs can in principle learn distributions sample-efficiently, if the discriminator class is compact and has strong distinguishing power against the particular generator class.\"},{\"index\":938,\"qgrid_unfiltered_index\":938,\"avg_confidence\":3.0,\"avg_rating\":7.33333,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 7, 9]\",\"title\":\"ProMP: Proximal Meta-Policy Search\",\"tldr\":\"A novel and theoretically grounded meta-reinforcement learning algorithm\"},{\"index\":1245,\"qgrid_unfiltered_index\":1245,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Kernel Change-point Detection with Auxiliary Deep Generative Models\",\"tldr\":\"In this paper, we propose KL-CPD, a novel kernel learning framework for time series CPD that optimizes a lower bound of test power via an auxiliary generative model as a surrogate to the abnormal distribution. \"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":982,\"qgrid_unfiltered_index\":982,\"avg_confidence\":2.66667,\"avg_rating\":7.33333,\"confidence\":\"[4, 2, 2]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Efficient Training on Very Large Corpora via Gramian Estimation\",\"tldr\":\"We develop efficient methods to train neural embedding models with a dot-product structure, by reformulating the objective function in terms of generalized Gram matrices, and maintaining estimates of those matrices.\"},{\"index\":1541,\"qgrid_unfiltered_index\":1541,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 8]\",\"title\":\"Visualizing and Understanding Generative Adversarial Networks\",\"tldr\":\"GAN representations are examined in detail, and sets of representation units are found that control the generation of semantic concepts in the output.\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"avg_confidence\":4.0,\"avg_rating\":7.33333,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":1082,\"qgrid_unfiltered_index\":1082,\"avg_confidence\":4.33333,\"avg_rating\":7.33333,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[7, 9, 6]\",\"title\":\"Gradient descent aligns the layers of deep linear networks\",\"tldr\":\"\"},{\"index\":441,\"qgrid_unfiltered_index\":441,\"avg_confidence\":4.0,\"avg_rating\":7.33333,\"confidence\":\"[4, 5, 3]\",\"ratings\":\"[6, 9, 7]\",\"title\":\"Large-Scale Study of Curiosity-Driven Learning\",\"tldr\":\"An agent trained only with curiosity, and no extrinsic reward, does surprisingly well on 54 popular environments, including the suite of Atari games, Mario etc.\"},{\"index\":1244,\"qgrid_unfiltered_index\":1244,\"avg_confidence\":4.33333,\"avg_rating\":7.33333,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Towards Metamerism via Foveated Style Transfer\",\"tldr\":\"We introduce a novel feed-forward framework to generate visual metamers\"},{\"index\":334,\"qgrid_unfiltered_index\":334,\"avg_confidence\":4.0,\"avg_rating\":7.33333,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 7, 8]\",\"title\":\"Differentiable Learning-to-Normalize via Switchable Normalization\",\"tldr\":\"\"},{\"index\":1507,\"qgrid_unfiltered_index\":1507,\"avg_confidence\":4.0,\"avg_rating\":7.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 9]\",\"title\":\"Label super-resolution networks\",\"tldr\":\"Super-resolving coarse labels into pixel-level labels, applied to aerial imagery and medical scans.\"},{\"index\":839,\"qgrid_unfiltered_index\":839,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 7, 7]\",\"title\":\"Diversity is All You Need: Learning Skills without a Reward Function\",\"tldr\":\"We propose an algorithm for learning useful skills without a reward function, and show how these skills can be used to solve downstream tasks.\"},{\"index\":513,\"qgrid_unfiltered_index\":513,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[5, 5, 1]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Evaluating Robustness of Neural Networks with Mixed Integer Programming\",\"tldr\":\"We efficiently verify the robustness of deep neural models with over 100,000 ReLUs, certifying more samples than the state-of-the-art and finding more adversarial examples than a strong first-order attack.\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":593,\"qgrid_unfiltered_index\":593,\"avg_confidence\":3.33333,\"avg_rating\":7.33333,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[7, 7, 8]\",\"title\":\"Small nonlinearities in activation functions create bad local minima in neural networks\",\"tldr\":\"We constructively prove that even the slightest nonlinear activation functions introduce spurious local minima, for general datasets and activation functions.\"},{\"index\":1279,\"qgrid_unfiltered_index\":1279,\"avg_confidence\":4.0,\"avg_rating\":7.33333,\"confidence\":\"[3, 5, 4]\",\"ratings\":\"[7, 7, 8]\",\"title\":\"LanczosNet: Multi-Scale Deep Graph Convolutional Networks\",\"tldr\":\"\"},{\"index\":1307,\"qgrid_unfiltered_index\":1307,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based RL\",\"tldr\":\"\"},{\"index\":1332,\"qgrid_unfiltered_index\":1332,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Learning to Navigate the Web\",\"tldr\":\"We train reinforcement learning policies using reward augmentation, curriculum learning, and meta-learning  to successfully navigate web pages.\"},{\"index\":722,\"qgrid_unfiltered_index\":722,\"avg_confidence\":4.33333,\"avg_rating\":7.0,\"confidence\":\"[3, 5, 5]\",\"ratings\":\"[6, 8, 7]\",\"title\":\"Deep Learning 3D Shapes Using Alt-az Anisotropic 2-Sphere Convolution\",\"tldr\":\"A method for applying deep learning to 3D surfaces using their spherical descriptors and alt-az anisotropic convolution on 2-sphere.\"},{\"index\":742,\"qgrid_unfiltered_index\":742,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 2, 5]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"How Important is a Neuron\",\"tldr\":\"\"},{\"index\":154,\"qgrid_unfiltered_index\":154,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Learning a SAT Solver from Single-Bit Supervision\",\"tldr\":\"We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.\"},{\"index\":1273,\"qgrid_unfiltered_index\":1273,\"avg_confidence\":4.0,\"avg_rating\":7.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Lagging Inference Networks and Posterior Collapse in Variational Autoencoders\",\"tldr\":\"To address posterior collapse in VAEs, we propose a simple yet effective training algorithm that aggressively optimizes inference network with more updates\"},{\"index\":789,\"qgrid_unfiltered_index\":789,\"avg_confidence\":4.33333,\"avg_rating\":7.0,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Wizard of Wikipedia: Knowledge-Powered Conversational Agents\",\"tldr\":\"We build knowledgeable conversational agents by conditioning on Wikipedia + a new supervised task.\"},{\"index\":818,\"qgrid_unfiltered_index\":818,\"avg_confidence\":4.0,\"avg_rating\":7.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Gradient Descent Provably Optimizes Over-parameterized Neural Networks\",\"tldr\":\"We prove gradient descent achieves zero training loss with a linear rate on over-parameterized neural networks.\"},{\"index\":822,\"qgrid_unfiltered_index\":822,\"avg_confidence\":4.33333,\"avg_rating\":7.0,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[5, 8, 8]\",\"title\":\"The effects of neural resource constraints on early visual representations \",\"tldr\":\"We reproduced neural representations found in biological visual systems by simulating their neural resource constraints in a deep convolutional model.\"},{\"index\":769,\"qgrid_unfiltered_index\":769,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Neural network gradient-based learning of black-box function interfaces\",\"tldr\":\"Training DNNs to interface w\\\\ black box functions w\\\\o intermediate labels by using an estimator sub-network that can be replaced with the black box after training\"},{\"index\":902,\"qgrid_unfiltered_index\":902,\"avg_confidence\":5.0,\"avg_rating\":7.0,\"confidence\":\"[5, 5, 5]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"How Powerful are Graph Neural Networks?\",\"tldr\":\"We develop theoretical foundations for expressive power of GNNs and design a provably most powerful GNN.\"},{\"index\":678,\"qgrid_unfiltered_index\":678,\"avg_confidence\":4.0,\"avg_rating\":7.0,\"confidence\":\"[3, 5, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Riemannian Adaptive Optimization Methods\",\"tldr\":\"Adapting Adam, Amsgrad, Adagrad to Riemannian manifolds. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":1172,\"qgrid_unfiltered_index\":1172,\"avg_confidence\":4.0,\"avg_rating\":7.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 8, 8]\",\"title\":\"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks\",\"tldr\":\"Feedforward neural networks that can have weights pruned after training could have had the same weights pruned before training\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":1260,\"qgrid_unfiltered_index\":1260,\"avg_confidence\":5.0,\"avg_rating\":7.0,\"confidence\":\"[5, 5, 5]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Improving the Differentiable Neural Computer Through Memory Masking, De-allocation, and Link Distribution Sharpness Control\",\"tldr\":\"\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"avg_confidence\":4.66667,\"avg_rating\":7.0,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":1482,\"qgrid_unfiltered_index\":1482,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Learning to Screen for Fast Softmax  Inference on Large Vocabulary Neural Networks\",\"tldr\":\"\"},{\"index\":1530,\"qgrid_unfiltered_index\":1530,\"avg_confidence\":2.33333,\"avg_rating\":7.0,\"confidence\":\"[2, 2, 3]\",\"ratings\":\"[8, 8, 5]\",\"title\":\"Global-to-local Memory Pointer Networks for Task-Oriented Dialogue\",\"tldr\":\"We propose a global memory encoder and a global memory decoder that share an external knowledge to strengthen task-oriented dialogue generation via sketch responses and pointer networks. \"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"avg_confidence\":2.66667,\"avg_rating\":7.0,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":636,\"qgrid_unfiltered_index\":636,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 9, 5]\",\"title\":\"Deep Graph Infomax\",\"tldr\":\"A new method for unsupervised representation learning on graphs, relying on maximizing mutual information between local and global representations in a graph. State-of-the-art results, competitive with supervised learning.\"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":930,\"qgrid_unfiltered_index\":930,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 2, 4]\",\"ratings\":\"[8, 5, 8]\",\"title\":\"Learning Self-Imitating Diverse Policies\",\"tldr\":\"Policy optimization by using past good rollouts from the agent; learning shaped rewards via divergence minimization; SVPG with JS-kernel for population-based exploration.\"},{\"index\":1560,\"qgrid_unfiltered_index\":1560,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Learning sparse relational transition models\",\"tldr\":\"A new approach that learns a representation for describing transition models in complex uncertaindomains using relational rules. \"},{\"index\":984,\"qgrid_unfiltered_index\":984,\"avg_confidence\":4.33333,\"avg_rating\":7.0,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[8, 5, 8]\",\"title\":\"Unsupervised Domain Adaptation for Distance Metric Learning\",\"tldr\":\"A new theory of unsupervised domain adaptation for distance metric learning and its application to face recognition across diverse ethnicity variations.\"},{\"index\":345,\"qgrid_unfiltered_index\":345,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 7, 6]\",\"title\":\"An analytic theory of generalization dynamics and transfer learning in deep linear networks\",\"tldr\":\"We provide many insights into neural network generalization from the theoretically tractable linear case.\"},{\"index\":491,\"qgrid_unfiltered_index\":491,\"avg_confidence\":4.33333,\"avg_rating\":7.0,\"confidence\":\"[3, 5, 5]\",\"ratings\":\"[6, 6, 9]\",\"title\":\"Near-Optimal Representation Learning for Hierarchical Reinforcement Learning\",\"tldr\":\"We translate a bound on sub-optimality of representations to a practical training objective in the context of hierarchical reinforcement learning.\"},{\"index\":323,\"qgrid_unfiltered_index\":323,\"avg_confidence\":4.0,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[9, 5, 7]\",\"title\":\"ADVERSARIAL DOMAIN ADAPTATION FOR STABLE BRAIN-MACHINE INTERFACES\",\"tldr\":\"We implement an adversarial domain adaptation network to stabilize a fixed Brain-Machine Interface against gradual changes in the recorded neural signals.\"},{\"index\":306,\"qgrid_unfiltered_index\":306,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[2, 5, 3]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"DARTS: Differentiable Architecture Search\",\"tldr\":\"We propose a differentiable architecture search algorithm for both convolutional and recurrent networks, achieving competitive performance with the state of the art using orders of magnitude less computation resources.\"},{\"index\":473,\"qgrid_unfiltered_index\":473,\"avg_confidence\":3.5,\"avg_rating\":7.0,\"confidence\":\"[4, 3]\",\"ratings\":\"[7, 7]\",\"title\":\"EMI: Exploration with Mutual Information Maximizing State and Action Embeddings\",\"tldr\":\"\"},{\"index\":265,\"qgrid_unfiltered_index\":265,\"avg_confidence\":4.0,\"avg_rating\":7.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 8, 7]\",\"title\":\"Deep, Skinny Neural Networks are not Universal Approximators\",\"tldr\":\"This paper proves that skinny neural networks cannot approximate certain functions, no matter how deep they are.\"},{\"index\":1411,\"qgrid_unfiltered_index\":1411,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"GANSynth: Adversarial Neural Audio Synthesis\",\"tldr\":\"High-quality audio synthesis with GANs\"},{\"index\":203,\"qgrid_unfiltered_index\":203,\"avg_confidence\":4.33333,\"avg_rating\":7.0,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Auxiliary Variational MCMC\",\"tldr\":\"\"},{\"index\":632,\"qgrid_unfiltered_index\":632,\"avg_confidence\":4.0,\"avg_rating\":7.0,\"confidence\":\"[4]\",\"ratings\":\"[7]\",\"title\":\"On the Minimal Supervision for Training Any Binary Classifier from Only Unlabeled Data\",\"tldr\":\"Three class priors are all you need to train deep models from only U data, while any two should not be enough.\"},{\"index\":611,\"qgrid_unfiltered_index\":611,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[6, 8, 7]\",\"title\":\"Greedy Attack and Gumbel Attack: Generating Adversarial Examples for Discrete Data\",\"tldr\":\"We develop two methods for generating adversarial examples on discrete data under a probabilistic framework.\"},{\"index\":635,\"qgrid_unfiltered_index\":635,\"avg_confidence\":4.33333,\"avg_rating\":7.0,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[6, 6, 9]\",\"title\":\"SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY\",\"tldr\":\"We present a new approach, SNIP, that is simple, versatile and interpretable; it prunes irrelevant connections for a given task at single-shot prior to training and is applicable to a variety of neural network models without modifications.\"},{\"index\":1064,\"qgrid_unfiltered_index\":1064,\"avg_confidence\":4.66667,\"avg_rating\":7.0,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 5, 8]\",\"title\":\"Local SGD Converges Fast and Communicates Little\",\"tldr\":\"We prove that parallel local SGD achieves linear speedup with much lesser communication than parallel mini-batch SGD.\"},{\"index\":910,\"qgrid_unfiltered_index\":910,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"The Comparative Power of ReLU Networks and Polynomial Kernels in the Presence of Sparse Latent Structure\",\"tldr\":\"Beyond-worst-case analysis of the representational power of  ReLU nets & polynomial kernels  -- in particular in the presence of sparse latent structure.\"},{\"index\":1224,\"qgrid_unfiltered_index\":1224,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 8, 6]\",\"title\":\"Learning Neural PDE Solvers with Convergence Guarantees\",\"tldr\":\"We learn a fast neural solver for PDEs that has convergence guarantees.\"},{\"index\":1011,\"qgrid_unfiltered_index\":1011,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 9]\",\"title\":\"Feature Intertwiners\",\"tldr\":\"A feature intertwiner module to leverage features from one accurate set to help the learning of another less reliable set.\"},{\"index\":1005,\"qgrid_unfiltered_index\":1005,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Scalable Reversible Generative Models with Free-form Continuous Dynamics\",\"tldr\":\"We use continuous time dynamics to define a generative model with exact likelihoods and efficient sampling that is parameterized by unrestricted neural networks.\"},{\"index\":1050,\"qgrid_unfiltered_index\":1050,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[9, 5, 7]\",\"title\":\"ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech\",\"tldr\":\"\"},{\"index\":1092,\"qgrid_unfiltered_index\":1092,\"avg_confidence\":4.33333,\"avg_rating\":7.0,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[7, 5, 9]\",\"title\":\"The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision\",\"tldr\":\"We present a Neuro-Symbolic Concept Learner to learn visual concepts, words, and semantic parsing of sentences without explicit annotations for any of them. \"},{\"index\":1097,\"qgrid_unfiltered_index\":1097,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[8, 8, 5]\",\"title\":\"Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word Vectors\",\"tldr\":\"Max-pooled word vectors with fuzzy Jaccard set similarity are an extremely competitive baseline for semantic similarity; we propose a simple dynamic variant that performs even better.\"},{\"index\":1108,\"qgrid_unfiltered_index\":1108,\"avg_confidence\":4.0,\"avg_rating\":7.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"What do you learn from context? Probing for sentence structure in contextualized word representations\",\"tldr\":\"We probe for sentence structure in ELMo and related contextual embedding models. We find existing models efficiently encode syntax and show evidence of long-range dependencies, but only offer small improvements on semantic tasks.\"},{\"index\":1129,\"qgrid_unfiltered_index\":1129,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 7, 6]\",\"title\":\"Learning Implicitly Recurrent CNNs Through Parameter Sharing\",\"tldr\":\"We propose a method that enables CNN folding to create recurrent connections\"},{\"index\":1490,\"qgrid_unfiltered_index\":1490,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 4, 8]\",\"title\":\"A Generative Model For Electron Paths\",\"tldr\":\"A generative model for reaction prediction that learns the mechanistic electron steps of a reaction directly from raw reaction data.\"},{\"index\":1069,\"qgrid_unfiltered_index\":1069,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 9]\",\"title\":\"AdaShift: Decorrelation and Convergence of Adaptive Learning Rate Methods\",\"tldr\":\"We analysis and solve the non-convergence issue of Adam.\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"avg_confidence\":2.0,\"avg_rating\":6.66667,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":311,\"qgrid_unfiltered_index\":311,\"avg_confidence\":3.0,\"avg_rating\":6.66667,\"confidence\":\"[3, 2, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Dynamic Sparse Graph for Efficient Deep Learning\",\"tldr\":\"We construct dynamic sparse graph via dimension-reduction search to reduce compute and memory cost in both DNN training and inference.\"},{\"index\":134,\"qgrid_unfiltered_index\":134,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Practical lossless compression with latent variables using bits back coding\",\"tldr\":\"We do lossless compression of large image datasets using a VAE, beat existing compression algorithms.\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": false,
       "_sort_field": "avg_rating",
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "940148d0-bbda-4606-b0bd-30e8f499baf1",
       "layout": "IPY_MODEL_9bbf4216f097406b8492478922efcd7c",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "56f5958741b94c3ebf9be3b9e07baa5b": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 20
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"avg_confidence\":4.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"avg_confidence\":3.33333,\"avg_rating\":5.66667,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"avg_confidence\":3.66667,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"avg_confidence\":2.66667,\"avg_rating\":7.0,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"avg_confidence\":4.0,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"avg_confidence\":2.0,\"avg_rating\":6.66667,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"avg_confidence\":4.66667,\"avg_rating\":5.33333,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"avg_confidence\":3.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"avg_confidence\":4.33333,\"avg_rating\":4.33333,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"avg_confidence\":3.25,\"avg_rating\":4.0,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"avg_confidence\":4.5,\"avg_rating\":6.5,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"avg_confidence\":4.0,\"avg_rating\":7.33333,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"avg_confidence\":4.33333,\"avg_rating\":5.0,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"avg_confidence\":3.66667,\"avg_rating\":4.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"avg_confidence\":4.0,\"avg_rating\":6.5,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"avg_confidence\":3.0,\"avg_rating\":5.0,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"avg_confidence\":3.5,\"avg_rating\":5.5,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"avg_confidence\":4.66667,\"avg_rating\":7.66667,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"avg_confidence\":3.0,\"avg_rating\":3.5,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"avg_confidence\":3.5,\"avg_rating\":6.5,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"avg_confidence\":4.5,\"avg_rating\":6.0,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"avg_confidence\":4.0,\"avg_rating\":4.66667,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"avg_confidence\":3.33333,\"avg_rating\":6.33333,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"avg_confidence\":3.0,\"avg_rating\":6.0,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"avg_confidence\":4.66667,\"avg_rating\":7.0,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"avg_confidence\":3.66667,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"avg_confidence\":4.66667,\"avg_rating\":5.0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"avg_confidence\":4.66667,\"avg_rating\":6.33333,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"avg_confidence\":4.33333,\"avg_rating\":5.33333,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"avg_confidence\":4.0,\"avg_rating\":3.66667,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"avg_confidence\":3.0,\"avg_rating\":6.0,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"avg_confidence\":3.0,\"avg_rating\":5.5,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"avg_confidence\":4.0,\"avg_rating\":4.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"avg_confidence\":3.33333,\"avg_rating\":3.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"avg_confidence\":4.33333,\"avg_rating\":5.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"avg_confidence\":4.0,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"avg_confidence\":4.0,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"avg_confidence\":4.5,\"avg_rating\":5.5,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "d7dc4156-a486-49b7-8b7f-af7e976a340b",
       "layout": "IPY_MODEL_cda88ae2bd604adbb10d0f49f1b6db58",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "5a333e9fcbd7440da06f38ad0cd2bcb4": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 100
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 1000
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 300
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxfEn09Y7\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"adversarial example\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4dFjR5K7\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"generative models\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke4KsA5FX\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"generative adversarial network\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgYl205tQ\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.3,\"avg_confidence\":3.0,\"topic\":\"model interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1E3Ko09F7\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJg8yhAqKm\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJGtFoC5Fm\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.8,\"topic\":\"adversarial example\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgVRiC9Km\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.7,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTciR9tm\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"artificial intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl42iA5t7\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.3,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylKB3A9Fm\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlxm30cKm\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"neural machine translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eEdj0cK7\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygqqsA9KX\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.2,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygn2o0qKX\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1GLm2R9Km\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke-JhA9Y7\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"inverse reinforcement learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJlmHoR5tQ\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygfghAcYX\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"network compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xLN3C9YX\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"pu learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJzLciCqKm\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1MAJhR5YX\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xsSjC9Ym\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"maximum mean discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkG5SjR5YQ\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"neural networks\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eJssCqY7\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"embedding\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJxeWnCcF7\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.7,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1grRoR9tQ\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgnmhA5KQ\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxnvsAqFm\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.3,\"avg_confidence\":4.3,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxcHnRqYQ\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"adversarial example\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJl2niR9KQ\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxt8oC9FQ\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"life-long learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hkf2_sC5FX\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.7,\"topic\":\"model free rl\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HygsfnR9Ym\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl0r3R9KX\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlk6iRqKX\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklSf3CqKm\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"cnn\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMHpjC9Ym\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJf_YjCqYX\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlEojAqFm\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bye9LiR9YX\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgToo0qFm\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygxb2CqKm\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl2E3AcF7\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4fpoA5Km\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.3,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxBFsRqYm\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyVU6s05K7\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"nlp\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xtAjR5tX\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.7,\"avg_confidence\":4.7,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJf7ts0cFm\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.7,\"avg_confidence\":3.3,\"topic\":\"non convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SklcFsAcKX\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByGuynAct7\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"generative models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representation\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJfRpoA9YX\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syxt2jC5FX\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"neural processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkE6PjC9KX\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyM7AiA5YX\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.7,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1ebTsActm\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"gan\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJeXSo09FQ\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.3,\"avg_confidence\":4.7,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx38iC5KX\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.7,\"avg_confidence\":3.3,\"topic\":\"cnn\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklnzhR9YQ\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"multi agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx7l309Fm\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzjBiR9t7\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"generative adversarial network\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1MB-3RcF7\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.3,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkgnpiR9Y7\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.2,\"topic\":\"deep rl\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1e7hs05Km\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.3,\"topic\":\"dynamic graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyePrhR5KX\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylPMnR9Ym\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyehMhC9Y7\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygm8jC9FQ\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"relgan\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJedV3R5tm\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"model based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke96sC5tm\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryf6Fs09YX\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.3,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke4HiAcY7\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl6As0cF7\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkNksoRctQ\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkemqsC9Fm\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rk4Qso0cKm\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJeQbnA5tm\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xEtoRqtQ\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial example\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"meta learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgK6iA5KX\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bayesian nonparametric\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygHGnRqK7\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.3,\"topic\":\"gans\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryMQ5sRqYX\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedwoC5t7\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1My6sR9tX\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"ai\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1erHoR5t7\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyNvti09KQ\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"direct feedback alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkGiPoC5FX\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"generative deep neural networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syfz6sC9tQ\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByMVTsR5KQ\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional network\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlaYi05tm\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlgNh0qKQ\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        16
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 100,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": false,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "b0ac44a8-8380-41c2-baa8-0dee9a1f9e8b",
       "layout": "IPY_MODEL_67f14428fe3a44ed906d8c886596ee97",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "5e46902833b74339bc4c95f5bf7fe935": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "autoHeight": true,
        "boldIndex": true,
        "defaultColumnWidth": -1,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 100,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "030246fb-237e-45f6-85fb-1492b88599d3",
       "layout": "IPY_MODEL_90e109e3e5c74d69a3f30fb87bd7f98c",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "5ff48bc1943f4d61bff3cc07ab0b7033": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.66667,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.66667,\"avg_confidence\":3.33333,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Complement Objective Training\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.66667,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.33333,\"avg_confidence\":4.66667,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.33333,\"avg_confidence\":4.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.25,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.5,\"avg_confidence\":4.5,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 8]\",\"confidence\":\"[5, 4]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":6.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[8, 5]\",\"confidence\":\"[4, 4]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Learning Entropic Wasserstein Embeddings\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Embedding\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\",\"ratings\":\"[7, 7, 3]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"sgd\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\",\"ratings\":\"[6, 6, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Invariance and Inverse Stability under ReLU\",\"avg_rating\":6.5,\"avg_confidence\":3.5,\"topic\":\"deep neural networks\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\",\"ratings\":\"[6, 7]\",\"confidence\":\"[4, 3]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"avg_rating\":6.0,\"avg_confidence\":4.5,\"topic\":\"VAE\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\",\"ratings\":\"[4, 8]\",\"confidence\":\"[4, 5]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep learning\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"avg_rating\":4.66667,\"avg_confidence\":4.0,\"topic\":\"GAN\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"avg_rating\":6.33333,\"avg_confidence\":3.33333,\"topic\":\"dialogue\",\"tldr\":\"\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Reward Constrained Policy Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\",\"ratings\":\"[6, 7, 5]\",\"confidence\":\"[4, 2, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.66667,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"avg_rating\":6.0,\"avg_confidence\":3.66667,\"topic\":\"rotation equivariance\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\",\"ratings\":\"[7, 3, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Graph\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Adaptive Neural Trees\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"neural networks\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"Phrase-Based Attentions\",\"avg_rating\":5.0,\"avg_confidence\":4.66667,\"topic\":\"neural machine translation\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Deep Layers as Stochastic Solvers\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep networks\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[4, 5, 1]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Sparse rewards\",\"tldr\":\"\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"avg_rating\":6.33333,\"avg_confidence\":4.66667,\"topic\":\"domain adaptation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"crowdsourcing\",\"tldr\":\"\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"unsupervised learning\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\",\"ratings\":\"[5, 3, 9]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"imitation learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[8, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"relation representations\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"avg_rating\":5.33333,\"avg_confidence\":4.33333,\"topic\":\"Empirical Bayes\",\"tldr\":\"\",\"ratings\":\"[6, 3, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Feature-Wise Bias Amplification\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"bias\",\"tldr\":\"\",\"ratings\":\"[6, 7, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"avg_rating\":3.66667,\"avg_confidence\":4.0,\"topic\":\"Neural Response Generation\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\",\"ratings\":\"[3, 7, 1]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Sorting out Lipschitz function approximation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"agent evaluation\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Interpretable Continual Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.0,\"topic\":\"Interpretability\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \",\"ratings\":\"[5, 6]\",\"confidence\":\"[3, 3]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"Implicit Autoencoders\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Unsupervised Learning\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\",\"ratings\":\"[2, 7, 6]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"avg_rating\":4.33333,\"avg_confidence\":4.0,\"topic\":\"Hierarchical reinforcement learning\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_rating\":3.66667,\"avg_confidence\":3.33333,\"topic\":\"visualization\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"ratings\":\"[4, 3, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"avg_rating\":5.66667,\"avg_confidence\":4.33333,\"topic\":\"cross-lingual transfer learning\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"word embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"VAE\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"preconditioner\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\",\"ratings\":\"[8, 4, 7]\",\"confidence\":\"[5, 5, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Model quantization\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\",\"ratings\":\"[8, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"avg_rating\":5.5,\"avg_confidence\":4.5,\"topic\":\"neural program repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\",\"ratings\":\"[6, 5]\",\"confidence\":\"[4, 5]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"unsupervised learning\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \",\"ratings\":\"[7, 5, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"positive-unlabeled learning\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 3, 3]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"DEEP GRAPH TRANSLATION\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[2, 4, 4]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "defaultColumnWidth": 150,
        "forceFitColumns": true
       },
       "id": "3b26fce7-97ca-4896-b4d7-6ea20ed8776d",
       "layout": "IPY_MODEL_271b2d7491c94a82adaa4124757c70ab",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "6089f0ad1dc640e9a72b79bef9472014": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "61bfeabd40304a659ac87351ec9b8e02": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.66667,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.66667,\"avg_confidence\":3.33333,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Complement Objective Training\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.66667,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.33333,\"avg_confidence\":4.66667,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.33333,\"avg_confidence\":4.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.25,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.5,\"avg_confidence\":4.5,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 8]\",\"confidence\":\"[5, 4]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":6.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[8, 5]\",\"confidence\":\"[4, 4]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Learning Entropic Wasserstein Embeddings\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Embedding\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\",\"ratings\":\"[7, 7, 3]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"sgd\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\",\"ratings\":\"[6, 6, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Invariance and Inverse Stability under ReLU\",\"avg_rating\":6.5,\"avg_confidence\":3.5,\"topic\":\"deep neural networks\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\",\"ratings\":\"[6, 7]\",\"confidence\":\"[4, 3]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"avg_rating\":6.0,\"avg_confidence\":4.5,\"topic\":\"VAE\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\",\"ratings\":\"[4, 8]\",\"confidence\":\"[4, 5]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep learning\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"avg_rating\":4.66667,\"avg_confidence\":4.0,\"topic\":\"GAN\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"avg_rating\":6.33333,\"avg_confidence\":3.33333,\"topic\":\"dialogue\",\"tldr\":\"\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Reward Constrained Policy Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\",\"ratings\":\"[6, 7, 5]\",\"confidence\":\"[4, 2, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.66667,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"avg_rating\":6.0,\"avg_confidence\":3.66667,\"topic\":\"rotation equivariance\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\",\"ratings\":\"[7, 3, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Graph\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Adaptive Neural Trees\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"neural networks\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"Phrase-Based Attentions\",\"avg_rating\":5.0,\"avg_confidence\":4.66667,\"topic\":\"neural machine translation\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Deep Layers as Stochastic Solvers\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep networks\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[4, 5, 1]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Sparse rewards\",\"tldr\":\"\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"avg_rating\":6.33333,\"avg_confidence\":4.66667,\"topic\":\"domain adaptation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"crowdsourcing\",\"tldr\":\"\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"unsupervised learning\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\",\"ratings\":\"[5, 3, 9]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"imitation learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[8, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"relation representations\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"avg_rating\":5.33333,\"avg_confidence\":4.33333,\"topic\":\"Empirical Bayes\",\"tldr\":\"\",\"ratings\":\"[6, 3, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Feature-Wise Bias Amplification\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"bias\",\"tldr\":\"\",\"ratings\":\"[6, 7, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"avg_rating\":3.66667,\"avg_confidence\":4.0,\"topic\":\"Neural Response Generation\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\",\"ratings\":\"[3, 7, 1]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Sorting out Lipschitz function approximation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"agent evaluation\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Interpretable Continual Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.0,\"topic\":\"Interpretability\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \",\"ratings\":\"[5, 6]\",\"confidence\":\"[3, 3]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"Implicit Autoencoders\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Unsupervised Learning\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\",\"ratings\":\"[2, 7, 6]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"avg_rating\":4.33333,\"avg_confidence\":4.0,\"topic\":\"Hierarchical reinforcement learning\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_rating\":3.66667,\"avg_confidence\":3.33333,\"topic\":\"visualization\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"ratings\":\"[4, 3, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"avg_rating\":5.66667,\"avg_confidence\":4.33333,\"topic\":\"cross-lingual transfer learning\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"word embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"VAE\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"preconditioner\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\",\"ratings\":\"[8, 4, 7]\",\"confidence\":\"[5, 5, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Model quantization\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\",\"ratings\":\"[8, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"avg_rating\":5.5,\"avg_confidence\":4.5,\"topic\":\"neural program repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\",\"ratings\":\"[6, 5]\",\"confidence\":\"[4, 5]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"unsupervised learning\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \",\"ratings\":\"[7, 5, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"positive-unlabeled learning\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 3, 3]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"DEEP GRAPH TRANSLATION\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[2, 4, 4]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "defaultColumnWidth": 150,
        "forceFitColumns": false
       },
       "id": "fb91c4fc-b714-4be2-b4e2-99c1794d8f6e",
       "layout": "IPY_MODEL_7eb2a2de881a43f084ca84f80762148e",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "62cdd114b448469b8998809241aa8070": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 10
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.66667,\"avg_confidence\":3.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Adversarial examples\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Generative Model\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.33333,\"avg_confidence\":3.0,\"topic\":\"Model Interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"Information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.75,\"topic\":\"adversarial examples\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.66667,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Artificial Intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.33333,\"avg_confidence\":3.33333,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.66667,\"avg_confidence\":4.33333,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Neural Machine Translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.33333,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.66667,\"avg_confidence\":2.66667,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.25,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.66667,\"avg_confidence\":2.66667,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Network Compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"PU learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Maximum Mean Discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"neural network\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"embeddings\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.33333,\"avg_confidence\":4.33333,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"adversarial examples\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"Lifelong Learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.66667,\"topic\":\"Model free RL\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"Deep Learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"Adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"Dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.66667,\"avg_confidence\":4.33333,\"topic\":\"CNN\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.66667,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.33333,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"NLP\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.66667,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.66667,\"avg_confidence\":3.33333,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.66667,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.33333,\"avg_confidence\":4.66667,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.33333,\"avg_confidence\":4.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.25,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.33333,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "f583c1bc-65de-4685-a9e8-41c48c0d66a5",
       "layout": "IPY_MODEL_7de2cae1ba6a49308d53ecc09478fdd5",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "6387ca824aae42cab22e1d8dd24a1a15": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 150
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.66667,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.66667,\"avg_confidence\":3.33333,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Complement Objective Training\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.66667,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.33333,\"avg_confidence\":4.66667,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.33333,\"avg_confidence\":4.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.25,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.5,\"avg_confidence\":4.5,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 8]\",\"confidence\":\"[5, 4]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":6.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[8, 5]\",\"confidence\":\"[4, 4]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Learning Entropic Wasserstein Embeddings\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Embedding\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\",\"ratings\":\"[7, 7, 3]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"sgd\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\",\"ratings\":\"[6, 6, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Invariance and Inverse Stability under ReLU\",\"avg_rating\":6.5,\"avg_confidence\":3.5,\"topic\":\"deep neural networks\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\",\"ratings\":\"[6, 7]\",\"confidence\":\"[4, 3]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"avg_rating\":6.0,\"avg_confidence\":4.5,\"topic\":\"VAE\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\",\"ratings\":\"[4, 8]\",\"confidence\":\"[4, 5]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep learning\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"avg_rating\":4.66667,\"avg_confidence\":4.0,\"topic\":\"GAN\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"avg_rating\":6.33333,\"avg_confidence\":3.33333,\"topic\":\"dialogue\",\"tldr\":\"\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Reward Constrained Policy Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\",\"ratings\":\"[6, 7, 5]\",\"confidence\":\"[4, 2, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.66667,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"avg_rating\":6.0,\"avg_confidence\":3.66667,\"topic\":\"rotation equivariance\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\",\"ratings\":\"[7, 3, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Graph\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Adaptive Neural Trees\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"neural networks\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"Phrase-Based Attentions\",\"avg_rating\":5.0,\"avg_confidence\":4.66667,\"topic\":\"neural machine translation\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Deep Layers as Stochastic Solvers\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep networks\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[4, 5, 1]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Sparse rewards\",\"tldr\":\"\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"avg_rating\":6.33333,\"avg_confidence\":4.66667,\"topic\":\"domain adaptation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"crowdsourcing\",\"tldr\":\"\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"unsupervised learning\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\",\"ratings\":\"[5, 3, 9]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"imitation learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[8, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"relation representations\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"avg_rating\":5.33333,\"avg_confidence\":4.33333,\"topic\":\"Empirical Bayes\",\"tldr\":\"\",\"ratings\":\"[6, 3, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Feature-Wise Bias Amplification\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"bias\",\"tldr\":\"\",\"ratings\":\"[6, 7, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"avg_rating\":3.66667,\"avg_confidence\":4.0,\"topic\":\"Neural Response Generation\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\",\"ratings\":\"[3, 7, 1]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Sorting out Lipschitz function approximation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"agent evaluation\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Interpretable Continual Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.0,\"topic\":\"Interpretability\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \",\"ratings\":\"[5, 6]\",\"confidence\":\"[3, 3]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"Implicit Autoencoders\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Unsupervised Learning\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\",\"ratings\":\"[2, 7, 6]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"avg_rating\":4.33333,\"avg_confidence\":4.0,\"topic\":\"Hierarchical reinforcement learning\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_rating\":3.66667,\"avg_confidence\":3.33333,\"topic\":\"visualization\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"ratings\":\"[4, 3, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"avg_rating\":5.66667,\"avg_confidence\":4.33333,\"topic\":\"cross-lingual transfer learning\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"word embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"VAE\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"preconditioner\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\",\"ratings\":\"[8, 4, 7]\",\"confidence\":\"[5, 5, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Model quantization\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\",\"ratings\":\"[8, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"avg_rating\":5.5,\"avg_confidence\":4.5,\"topic\":\"neural program repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\",\"ratings\":\"[6, 5]\",\"confidence\":\"[4, 5]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"unsupervised learning\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \",\"ratings\":\"[7, 5, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"positive-unlabeled learning\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 3, 3]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"DEEP GRAPH TRANSLATION\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[2, 4, 4]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "96a5f38c-018e-44fd-8469-abc7f4431b5e",
       "layout": "IPY_MODEL_dd522c0fe65b40f3911e3987e17bfbdc",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "66aac05c63d346fb85d23893e1065dc9": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "autoHeight": true,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 35,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "de2c69c7-9103-4916-aecc-b7400b637983",
       "layout": "IPY_MODEL_9414703c11f44ed5ae1348933237e5c2",
       "precision": 5,
       "show_toolbar": true
      }
     },
     "67f14428fe3a44ed906d8c886596ee97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "68b181c55f354f5fb88357ea53a4360b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6a6c620fdfd44f96ae716a2f3cdf140d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6a8c3e4b92d84a3a9ce48ba39ef256e7": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "218541cc-4b59-4825-a0ae-bfb9fd512d30",
       "layout": "IPY_MODEL_984db0de343c4cff89343905bd9bfbe4",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "6df3f32fb5d24f84933bac98c4237235": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6f9005a3e95644efa76b51dfad0e8f18": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 100
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.66667,\"avg_confidence\":3.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Adversarial examples\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Generative Model\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.33333,\"avg_confidence\":3.0,\"topic\":\"Model Interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"Information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.75,\"topic\":\"adversarial examples\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.66667,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Artificial Intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.33333,\"avg_confidence\":3.33333,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.66667,\"avg_confidence\":4.33333,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Neural Machine Translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.33333,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.66667,\"avg_confidence\":2.66667,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.25,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.66667,\"avg_confidence\":2.66667,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Network Compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"PU learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Maximum Mean Discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"neural network\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"embeddings\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.33333,\"avg_confidence\":4.33333,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"adversarial examples\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"Lifelong Learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.66667,\"topic\":\"Model free RL\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"Deep Learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"Adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"Dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.66667,\"avg_confidence\":4.33333,\"topic\":\"CNN\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.66667,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.33333,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"NLP\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.66667,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.66667,\"avg_confidence\":3.33333,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.66667,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.33333,\"avg_confidence\":4.66667,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.33333,\"avg_confidence\":4.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.25,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.33333,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "f6d1d2f8-442d-468b-8adf-f8fd41f2c2ba",
       "layout": "IPY_MODEL_1d177234936b4e7cbe46a1c024207d5c",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "715183266e2c4c998f0cb32d2c0f7b42": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 5000
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.66667,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.66667,\"avg_confidence\":3.33333,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Complement Objective Training\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.66667,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.33333,\"avg_confidence\":4.66667,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.33333,\"avg_confidence\":4.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.25,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.5,\"avg_confidence\":4.5,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 8]\",\"confidence\":\"[5, 4]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":6.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[8, 5]\",\"confidence\":\"[4, 4]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Learning Entropic Wasserstein Embeddings\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Embedding\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\",\"ratings\":\"[7, 7, 3]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"sgd\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\",\"ratings\":\"[6, 6, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Invariance and Inverse Stability under ReLU\",\"avg_rating\":6.5,\"avg_confidence\":3.5,\"topic\":\"deep neural networks\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\",\"ratings\":\"[6, 7]\",\"confidence\":\"[4, 3]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"avg_rating\":6.0,\"avg_confidence\":4.5,\"topic\":\"VAE\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\",\"ratings\":\"[4, 8]\",\"confidence\":\"[4, 5]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep learning\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"avg_rating\":4.66667,\"avg_confidence\":4.0,\"topic\":\"GAN\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"avg_rating\":6.33333,\"avg_confidence\":3.33333,\"topic\":\"dialogue\",\"tldr\":\"\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Reward Constrained Policy Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\",\"ratings\":\"[6, 7, 5]\",\"confidence\":\"[4, 2, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.66667,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"avg_rating\":6.0,\"avg_confidence\":3.66667,\"topic\":\"rotation equivariance\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\",\"ratings\":\"[7, 3, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Graph\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Adaptive Neural Trees\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"neural networks\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"Phrase-Based Attentions\",\"avg_rating\":5.0,\"avg_confidence\":4.66667,\"topic\":\"neural machine translation\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Deep Layers as Stochastic Solvers\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep networks\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[4, 5, 1]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Sparse rewards\",\"tldr\":\"\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"avg_rating\":6.33333,\"avg_confidence\":4.66667,\"topic\":\"domain adaptation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"crowdsourcing\",\"tldr\":\"\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"unsupervised learning\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\",\"ratings\":\"[5, 3, 9]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"imitation learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[8, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"relation representations\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"avg_rating\":5.33333,\"avg_confidence\":4.33333,\"topic\":\"Empirical Bayes\",\"tldr\":\"\",\"ratings\":\"[6, 3, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Feature-Wise Bias Amplification\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"bias\",\"tldr\":\"\",\"ratings\":\"[6, 7, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"avg_rating\":3.66667,\"avg_confidence\":4.0,\"topic\":\"Neural Response Generation\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\",\"ratings\":\"[3, 7, 1]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Sorting out Lipschitz function approximation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"agent evaluation\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Interpretable Continual Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.0,\"topic\":\"Interpretability\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \",\"ratings\":\"[5, 6]\",\"confidence\":\"[3, 3]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"Implicit Autoencoders\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Unsupervised Learning\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\",\"ratings\":\"[2, 7, 6]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"avg_rating\":4.33333,\"avg_confidence\":4.0,\"topic\":\"Hierarchical reinforcement learning\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_rating\":3.66667,\"avg_confidence\":3.33333,\"topic\":\"visualization\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"ratings\":\"[4, 3, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"avg_rating\":5.66667,\"avg_confidence\":4.33333,\"topic\":\"cross-lingual transfer learning\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"word embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"VAE\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"preconditioner\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\",\"ratings\":\"[8, 4, 7]\",\"confidence\":\"[5, 5, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Model quantization\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\",\"ratings\":\"[8, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"avg_rating\":5.5,\"avg_confidence\":4.5,\"topic\":\"neural program repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\",\"ratings\":\"[6, 5]\",\"confidence\":\"[4, 5]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"unsupervised learning\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \",\"ratings\":\"[7, 5, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"positive-unlabeled learning\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 3, 3]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"DEEP GRAPH TRANSLATION\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[2, 4, 4]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "defaultColumnWidth": 150,
        "forceFitColumns": true
       },
       "id": "12302d0a-cfeb-45f7-a02b-63583edd2593",
       "layout": "IPY_MODEL_40dd31db837d4c0b92c17fef3258202c",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "7224a25b9bd94c2ca61a9f360b32a8e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "724496f32c7a4f2c9354ab338313021d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "75aaa1751c4a4185860d27d053c6b86f": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 5000
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.66667,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.66667,\"avg_confidence\":3.33333,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Complement Objective Training\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.66667,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.33333,\"avg_confidence\":4.66667,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.33333,\"avg_confidence\":4.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.25,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.5,\"avg_confidence\":4.5,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 8]\",\"confidence\":\"[5, 4]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":6.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[8, 5]\",\"confidence\":\"[4, 4]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Learning Entropic Wasserstein Embeddings\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Embedding\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\",\"ratings\":\"[7, 7, 3]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"sgd\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\",\"ratings\":\"[6, 6, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Invariance and Inverse Stability under ReLU\",\"avg_rating\":6.5,\"avg_confidence\":3.5,\"topic\":\"deep neural networks\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\",\"ratings\":\"[6, 7]\",\"confidence\":\"[4, 3]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"avg_rating\":6.0,\"avg_confidence\":4.5,\"topic\":\"VAE\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\",\"ratings\":\"[4, 8]\",\"confidence\":\"[4, 5]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep learning\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"avg_rating\":4.66667,\"avg_confidence\":4.0,\"topic\":\"GAN\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"avg_rating\":6.33333,\"avg_confidence\":3.33333,\"topic\":\"dialogue\",\"tldr\":\"\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Reward Constrained Policy Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\",\"ratings\":\"[6, 7, 5]\",\"confidence\":\"[4, 2, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.66667,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"avg_rating\":6.0,\"avg_confidence\":3.66667,\"topic\":\"rotation equivariance\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\",\"ratings\":\"[7, 3, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Graph\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Adaptive Neural Trees\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"neural networks\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"Phrase-Based Attentions\",\"avg_rating\":5.0,\"avg_confidence\":4.66667,\"topic\":\"neural machine translation\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Deep Layers as Stochastic Solvers\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep networks\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[4, 5, 1]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Sparse rewards\",\"tldr\":\"\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"avg_rating\":6.33333,\"avg_confidence\":4.66667,\"topic\":\"domain adaptation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"crowdsourcing\",\"tldr\":\"\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"unsupervised learning\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\",\"ratings\":\"[5, 3, 9]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"imitation learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[8, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"relation representations\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"avg_rating\":5.33333,\"avg_confidence\":4.33333,\"topic\":\"Empirical Bayes\",\"tldr\":\"\",\"ratings\":\"[6, 3, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Feature-Wise Bias Amplification\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"bias\",\"tldr\":\"\",\"ratings\":\"[6, 7, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"avg_rating\":3.66667,\"avg_confidence\":4.0,\"topic\":\"Neural Response Generation\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\",\"ratings\":\"[3, 7, 1]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Sorting out Lipschitz function approximation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"agent evaluation\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Interpretable Continual Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.0,\"topic\":\"Interpretability\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \",\"ratings\":\"[5, 6]\",\"confidence\":\"[3, 3]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"Implicit Autoencoders\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Unsupervised Learning\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\",\"ratings\":\"[2, 7, 6]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"avg_rating\":4.33333,\"avg_confidence\":4.0,\"topic\":\"Hierarchical reinforcement learning\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_rating\":3.66667,\"avg_confidence\":3.33333,\"topic\":\"visualization\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"ratings\":\"[4, 3, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"avg_rating\":5.66667,\"avg_confidence\":4.33333,\"topic\":\"cross-lingual transfer learning\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"word embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"VAE\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"preconditioner\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\",\"ratings\":\"[8, 4, 7]\",\"confidence\":\"[5, 5, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Model quantization\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\",\"ratings\":\"[8, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"avg_rating\":5.5,\"avg_confidence\":4.5,\"topic\":\"neural program repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\",\"ratings\":\"[6, 5]\",\"confidence\":\"[4, 5]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"unsupervised learning\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \",\"ratings\":\"[7, 5, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"positive-unlabeled learning\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 3, 3]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"DEEP GRAPH TRANSLATION\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[2, 4, 4]\"},{\"Index\":100,\"qgrid_unfiltered_index\":100,\"title\":\"Neural Networks with Structural Resistance to Adversarial Attacks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"machine learning\",\"tldr\":\"We introduce a type of neural network that is structurally resistant to adversarial attacks, even when trained on unaugmented training sets.  The resistance is due to the stability of network units wrt input perturbations.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":101,\"qgrid_unfiltered_index\":101,\"title\":\"Von Mises-Fisher Loss for Training Sequence to Sequence Models with Continuous Outputs\",\"avg_rating\":6.0,\"avg_confidence\":4.33333,\"topic\":\"Language Generation\",\"tldr\":\"Language generation using seq2seq models which produce word embeddings instead of a softmax based distribution over the vocabulary at each step enabling much faster training while maintaining generation quality\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":102,\"qgrid_unfiltered_index\":102,\"title\":\"On the Spectral Bias of Neural Networks\",\"avg_rating\":5.75,\"avg_confidence\":3.25,\"topic\":\"deep learning theory\",\"tldr\":\"We investigate ReLU networks in the Fourier domain and demonstrate peculiar behaviour.\",\"ratings\":\"[5, 6, 5, 7]\",\"confidence\":\"[4, 3, 3, 3]\"},{\"Index\":103,\"qgrid_unfiltered_index\":103,\"title\":\"RoC-GAN: Robust Conditional GAN\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"conditional GAN\",\"tldr\":\"We introduce a new type of conditional GAN, which aims to leverage structure in the target space of the generator. We augment the generator with a new, unsupervised pathway to learn the target structure. \",\"ratings\":\"[6, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":104,\"qgrid_unfiltered_index\":104,\"title\":\"The Effectiveness of Pre-Trained Code Embeddings\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"machine learning\",\"tldr\":\"Researchers exploring natural language processing techniques applied to source code are not using any form of pre-trained embeddings, we show that they should be.\",\"ratings\":\"[6, 4, 5]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":105,\"qgrid_unfiltered_index\":105,\"title\":\"Learning Disentangled Representations with Reference-Based Variational Autoencoders\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Disentangled representations\",\"tldr\":\"\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":106,\"qgrid_unfiltered_index\":106,\"title\":\"Likelihood-based Permutation Invariant Loss Function for Probability Distributions\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"Set reconstruction\",\"tldr\":\"The proposed method, Set Cross Entropy, measures the information-theoretic similarity of sets in a permutation-invariant manner.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":107,\"qgrid_unfiltered_index\":107,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Maximum Mean Discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":108,\"qgrid_unfiltered_index\":108,\"title\":\"Confidence Calibration in Deep Neural Networks through Stochastic Inferences\",\"avg_rating\":4.33333,\"avg_confidence\":3.33333,\"topic\":\"Variance-Weighted Confidence-Integrated loss\",\"tldr\":\"We propose a framework to learn confidence-calibrated networks by designing a novel loss function that incorporates predictive uncertainty estimated through stochastic inferences.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":109,\"qgrid_unfiltered_index\":109,\"title\":\"Shallow Learning For Deep Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"CNN\",\"tldr\":\"We build CNNs layer by layer without end to end training and show for the first time that this kind of approach can scale to Imagenet, while having multiple favorable  properties.\",\"ratings\":\"[5, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":110,\"qgrid_unfiltered_index\":110,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":111,\"qgrid_unfiltered_index\":111,\"title\":\"Modeling Uncertainty with Hedged Instance Embeddings\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"uncertainty\",\"tldr\":\"The paper proposes using probability distributions instead of points for instance embeddings tasks such as recognition and verification.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 3, 5]\"},{\"Index\":112,\"qgrid_unfiltered_index\":112,\"title\":\"Manifold Mixup: Learning Better Representations by Interpolating Hidden States\",\"avg_rating\":6.0,\"avg_confidence\":3.66667,\"topic\":\"Regularizer\",\"tldr\":\"A method for learning better representations, that acts as a regularizer and despite its no significant additional computation cost , achieves improvements over strong baselines on Supervised and Semi-supervised Learning tasks.\",\"ratings\":\"[6, 4, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":113,\"qgrid_unfiltered_index\":113,\"title\":\"MEAN-FIELD ANALYSIS OF BATCH NORMALIZATION\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[3, 3, 3]\"}]}",
       "_df_range": [
        0,
        114
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        14,
        31
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "02f1e6bb-a6c2-4cfa-bc00-d01eb8fdfb0b",
       "layout": "IPY_MODEL_3c9857800a7c4486a22794da79812055",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "75bcf0ffbf9d483a8b3244e5d8cfdb2d": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 5000
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.66667,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.66667,\"avg_confidence\":3.33333,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Complement Objective Training\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.66667,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.33333,\"avg_confidence\":4.66667,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.33333,\"avg_confidence\":4.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.25,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.5,\"avg_confidence\":4.5,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 8]\",\"confidence\":\"[5, 4]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":6.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[8, 5]\",\"confidence\":\"[4, 4]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Learning Entropic Wasserstein Embeddings\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Embedding\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\",\"ratings\":\"[7, 7, 3]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"sgd\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\",\"ratings\":\"[6, 6, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Invariance and Inverse Stability under ReLU\",\"avg_rating\":6.5,\"avg_confidence\":3.5,\"topic\":\"deep neural networks\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\",\"ratings\":\"[6, 7]\",\"confidence\":\"[4, 3]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"avg_rating\":6.0,\"avg_confidence\":4.5,\"topic\":\"VAE\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\",\"ratings\":\"[4, 8]\",\"confidence\":\"[4, 5]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep learning\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"avg_rating\":4.66667,\"avg_confidence\":4.0,\"topic\":\"GAN\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"avg_rating\":6.33333,\"avg_confidence\":3.33333,\"topic\":\"dialogue\",\"tldr\":\"\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Reward Constrained Policy Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\",\"ratings\":\"[6, 7, 5]\",\"confidence\":\"[4, 2, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.66667,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"avg_rating\":6.0,\"avg_confidence\":3.66667,\"topic\":\"rotation equivariance\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\",\"ratings\":\"[7, 3, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Graph\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Adaptive Neural Trees\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"neural networks\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"Phrase-Based Attentions\",\"avg_rating\":5.0,\"avg_confidence\":4.66667,\"topic\":\"neural machine translation\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Deep Layers as Stochastic Solvers\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep networks\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[4, 5, 1]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Sparse rewards\",\"tldr\":\"\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"avg_rating\":6.33333,\"avg_confidence\":4.66667,\"topic\":\"domain adaptation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"crowdsourcing\",\"tldr\":\"\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"unsupervised learning\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\",\"ratings\":\"[5, 3, 9]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"imitation learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[8, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"relation representations\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"avg_rating\":5.33333,\"avg_confidence\":4.33333,\"topic\":\"Empirical Bayes\",\"tldr\":\"\",\"ratings\":\"[6, 3, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Feature-Wise Bias Amplification\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"bias\",\"tldr\":\"\",\"ratings\":\"[6, 7, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"avg_rating\":3.66667,\"avg_confidence\":4.0,\"topic\":\"Neural Response Generation\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\",\"ratings\":\"[3, 7, 1]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Sorting out Lipschitz function approximation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"agent evaluation\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Interpretable Continual Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.0,\"topic\":\"Interpretability\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \",\"ratings\":\"[5, 6]\",\"confidence\":\"[3, 3]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"Implicit Autoencoders\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Unsupervised Learning\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\",\"ratings\":\"[2, 7, 6]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"avg_rating\":4.33333,\"avg_confidence\":4.0,\"topic\":\"Hierarchical reinforcement learning\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_rating\":3.66667,\"avg_confidence\":3.33333,\"topic\":\"visualization\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"ratings\":\"[4, 3, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"avg_rating\":5.66667,\"avg_confidence\":4.33333,\"topic\":\"cross-lingual transfer learning\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"word embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"VAE\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"preconditioner\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\",\"ratings\":\"[8, 4, 7]\",\"confidence\":\"[5, 5, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Model quantization\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\",\"ratings\":\"[8, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"avg_rating\":5.5,\"avg_confidence\":4.5,\"topic\":\"neural program repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\",\"ratings\":\"[6, 5]\",\"confidence\":\"[4, 5]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"unsupervised learning\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \",\"ratings\":\"[7, 5, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"positive-unlabeled learning\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 3, 3]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"DEEP GRAPH TRANSLATION\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[2, 4, 4]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "defaultColumnWidth": 150,
        "forceFitColumns": true
       },
       "id": "1f04d12e-ff85-4802-95a8-05ce5aaccad3",
       "layout": "IPY_MODEL_6089f0ad1dc640e9a72b79bef9472014",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "787837d8cee147c2afc540116fa28faf": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 10
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.66667,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.66667,\"avg_confidence\":3.33333,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Complement Objective Training\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.66667,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.33333,\"avg_confidence\":4.66667,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.33333,\"avg_confidence\":4.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.25,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.5,\"avg_confidence\":4.5,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 8]\",\"confidence\":\"[5, 4]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":6.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[8, 5]\",\"confidence\":\"[4, 4]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Learning Entropic Wasserstein Embeddings\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Embedding\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\",\"ratings\":\"[7, 7, 3]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"sgd\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\",\"ratings\":\"[6, 6, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Invariance and Inverse Stability under ReLU\",\"avg_rating\":6.5,\"avg_confidence\":3.5,\"topic\":\"deep neural networks\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\",\"ratings\":\"[6, 7]\",\"confidence\":\"[4, 3]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"avg_rating\":6.0,\"avg_confidence\":4.5,\"topic\":\"VAE\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\",\"ratings\":\"[4, 8]\",\"confidence\":\"[4, 5]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep learning\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"avg_rating\":4.66667,\"avg_confidence\":4.0,\"topic\":\"GAN\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"avg_rating\":6.33333,\"avg_confidence\":3.33333,\"topic\":\"dialogue\",\"tldr\":\"\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Reward Constrained Policy Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\",\"ratings\":\"[6, 7, 5]\",\"confidence\":\"[4, 2, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.66667,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"avg_rating\":6.0,\"avg_confidence\":3.66667,\"topic\":\"rotation equivariance\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\",\"ratings\":\"[7, 3, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Graph\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Adaptive Neural Trees\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"neural networks\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"Phrase-Based Attentions\",\"avg_rating\":5.0,\"avg_confidence\":4.66667,\"topic\":\"neural machine translation\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Deep Layers as Stochastic Solvers\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep networks\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[4, 5, 1]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Sparse rewards\",\"tldr\":\"\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"avg_rating\":6.33333,\"avg_confidence\":4.66667,\"topic\":\"domain adaptation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"crowdsourcing\",\"tldr\":\"\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"unsupervised learning\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\",\"ratings\":\"[5, 3, 9]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"imitation learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[8, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"relation representations\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"avg_rating\":5.33333,\"avg_confidence\":4.33333,\"topic\":\"Empirical Bayes\",\"tldr\":\"\",\"ratings\":\"[6, 3, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Feature-Wise Bias Amplification\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"bias\",\"tldr\":\"\",\"ratings\":\"[6, 7, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"avg_rating\":3.66667,\"avg_confidence\":4.0,\"topic\":\"Neural Response Generation\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\",\"ratings\":\"[3, 7, 1]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Sorting out Lipschitz function approximation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"agent evaluation\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Interpretable Continual Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.0,\"topic\":\"Interpretability\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \",\"ratings\":\"[5, 6]\",\"confidence\":\"[3, 3]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"Implicit Autoencoders\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Unsupervised Learning\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\",\"ratings\":\"[2, 7, 6]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"avg_rating\":4.33333,\"avg_confidence\":4.0,\"topic\":\"Hierarchical reinforcement learning\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_rating\":3.66667,\"avg_confidence\":3.33333,\"topic\":\"visualization\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"ratings\":\"[4, 3, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"avg_rating\":5.66667,\"avg_confidence\":4.33333,\"topic\":\"cross-lingual transfer learning\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"word embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"VAE\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"preconditioner\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\",\"ratings\":\"[8, 4, 7]\",\"confidence\":\"[5, 5, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Model quantization\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\",\"ratings\":\"[8, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"avg_rating\":5.5,\"avg_confidence\":4.5,\"topic\":\"neural program repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\",\"ratings\":\"[6, 5]\",\"confidence\":\"[4, 5]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"unsupervised learning\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \",\"ratings\":\"[7, 5, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"positive-unlabeled learning\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 3, 3]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"DEEP GRAPH TRANSLATION\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[2, 4, 4]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": "Index",
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "defaultColumnWidth": 150,
        "forceFitColumns": true
       },
       "id": "e887d544-57af-4490-b40e-a7c7e3a9bdbc",
       "layout": "IPY_MODEL_9c11d7bda4524e91a01b406ea40ab2b6",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "79c76962a9194765924f238b23d2e22e": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 5000
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.66667,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.66667,\"avg_confidence\":3.33333,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Complement Objective Training\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.66667,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.33333,\"avg_confidence\":4.66667,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.33333,\"avg_confidence\":4.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.25,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.5,\"avg_confidence\":4.5,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 8]\",\"confidence\":\"[5, 4]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":6.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[8, 5]\",\"confidence\":\"[4, 4]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Learning Entropic Wasserstein Embeddings\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Embedding\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\",\"ratings\":\"[7, 7, 3]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"sgd\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\",\"ratings\":\"[6, 6, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Invariance and Inverse Stability under ReLU\",\"avg_rating\":6.5,\"avg_confidence\":3.5,\"topic\":\"deep neural networks\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\",\"ratings\":\"[6, 7]\",\"confidence\":\"[4, 3]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"avg_rating\":6.0,\"avg_confidence\":4.5,\"topic\":\"VAE\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\",\"ratings\":\"[4, 8]\",\"confidence\":\"[4, 5]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep learning\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"avg_rating\":4.66667,\"avg_confidence\":4.0,\"topic\":\"GAN\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"avg_rating\":6.33333,\"avg_confidence\":3.33333,\"topic\":\"dialogue\",\"tldr\":\"\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Reward Constrained Policy Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\",\"ratings\":\"[6, 7, 5]\",\"confidence\":\"[4, 2, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.66667,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"avg_rating\":6.0,\"avg_confidence\":3.66667,\"topic\":\"rotation equivariance\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\",\"ratings\":\"[7, 3, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Graph\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Adaptive Neural Trees\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"neural networks\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"Phrase-Based Attentions\",\"avg_rating\":5.0,\"avg_confidence\":4.66667,\"topic\":\"neural machine translation\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Deep Layers as Stochastic Solvers\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep networks\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[4, 5, 1]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Sparse rewards\",\"tldr\":\"\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"avg_rating\":6.33333,\"avg_confidence\":4.66667,\"topic\":\"domain adaptation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"crowdsourcing\",\"tldr\":\"\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"unsupervised learning\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\",\"ratings\":\"[5, 3, 9]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"imitation learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[8, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"relation representations\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"avg_rating\":5.33333,\"avg_confidence\":4.33333,\"topic\":\"Empirical Bayes\",\"tldr\":\"\",\"ratings\":\"[6, 3, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Feature-Wise Bias Amplification\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"bias\",\"tldr\":\"\",\"ratings\":\"[6, 7, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"avg_rating\":3.66667,\"avg_confidence\":4.0,\"topic\":\"Neural Response Generation\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\",\"ratings\":\"[3, 7, 1]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Sorting out Lipschitz function approximation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"agent evaluation\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Interpretable Continual Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.0,\"topic\":\"Interpretability\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \",\"ratings\":\"[5, 6]\",\"confidence\":\"[3, 3]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"Implicit Autoencoders\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Unsupervised Learning\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\",\"ratings\":\"[2, 7, 6]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"avg_rating\":4.33333,\"avg_confidence\":4.0,\"topic\":\"Hierarchical reinforcement learning\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_rating\":3.66667,\"avg_confidence\":3.33333,\"topic\":\"visualization\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"ratings\":\"[4, 3, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"avg_rating\":5.66667,\"avg_confidence\":4.33333,\"topic\":\"cross-lingual transfer learning\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"word embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"VAE\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"preconditioner\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\",\"ratings\":\"[8, 4, 7]\",\"confidence\":\"[5, 5, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Model quantization\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\",\"ratings\":\"[8, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"avg_rating\":5.5,\"avg_confidence\":4.5,\"topic\":\"neural program repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\",\"ratings\":\"[6, 5]\",\"confidence\":\"[4, 5]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"unsupervised learning\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \",\"ratings\":\"[7, 5, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"positive-unlabeled learning\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 3, 3]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"DEEP GRAPH TRANSLATION\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[2, 4, 4]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "defaultColumnWidth": 150,
        "forceFitColumns": false
       },
       "id": "8d0a5872-023c-4147-b179-eb8ba99f26a1",
       "layout": "IPY_MODEL_edd30b293f40402aa8e5283a4158d893",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "7a1eacf5fb6445bf9e7a58d747ff04cc": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "autoHeight": true,
        "boldIndex": true,
        "defaultColumnWidth": -1,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": -1,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 100,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "636c3133-7071-48ac-b900-f4da0075628f",
       "layout": "IPY_MODEL_8408dfde88b44da491c003b4bfbb2ce8",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "7cfb155efe314570a63a8274b98ddbcc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7de2cae1ba6a49308d53ecc09478fdd5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7eb2a2de881a43f084ca84f80762148e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "823c1172b6544556acf95085d98feaef": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 200
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxfEn09Y7\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"Adversarial examples\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4dFjR5K7\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"Generative Model\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke4KsA5FX\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgYl205tQ\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.3,\"avg_confidence\":3.0,\"topic\":\"Model Interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1E3Ko09F7\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"Information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJg8yhAqKm\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJGtFoC5Fm\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.8,\"topic\":\"adversarial examples\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgVRiC9Km\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.7,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTciR9tm\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Artificial Intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl42iA5t7\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.3,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylKB3A9Fm\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlxm30cKm\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Neural Machine Translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eEdj0cK7\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygqqsA9KX\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.2,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygn2o0qKX\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1GLm2R9Km\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke-JhA9Y7\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJlmHoR5tQ\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygfghAcYX\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"Network Compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xLN3C9YX\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"PU learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJzLciCqKm\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1MAJhR5YX\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xsSjC9Ym\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"Maximum Mean Discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkG5SjR5YQ\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"neural network\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eJssCqY7\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"embeddings\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJxeWnCcF7\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.7,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1grRoR9tQ\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgnmhA5KQ\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxnvsAqFm\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.3,\"avg_confidence\":4.3,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxcHnRqYQ\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"adversarial examples\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJl2niR9KQ\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxt8oC9FQ\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"Lifelong Learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hkf2_sC5FX\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.7,\"topic\":\"Model free RL\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HygsfnR9Ym\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"Deep Learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl0r3R9KX\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"Adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlk6iRqKX\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"Dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklSf3CqKm\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"CNN\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMHpjC9Ym\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJf_YjCqYX\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlEojAqFm\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bye9LiR9YX\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgToo0qFm\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygxb2CqKm\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl2E3AcF7\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4fpoA5Km\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.3,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxBFsRqYm\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyVU6s05K7\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"NLP\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xtAjR5tX\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.7,\"avg_confidence\":4.7,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJf7ts0cFm\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.7,\"avg_confidence\":3.3,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SklcFsAcKX\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByGuynAct7\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJfRpoA9YX\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syxt2jC5FX\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkE6PjC9KX\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyM7AiA5YX\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.7,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1ebTsActm\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJeXSo09FQ\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.3,\"avg_confidence\":4.7,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx38iC5KX\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.7,\"avg_confidence\":3.3,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklnzhR9YQ\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx7l309Fm\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzjBiR9t7\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1MB-3RcF7\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.3,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkgnpiR9Y7\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.2,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1e7hs05Km\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.3,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyePrhR5KX\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylPMnR9Ym\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyehMhC9Y7\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygm8jC9FQ\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJedV3R5tm\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke96sC5tm\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryf6Fs09YX\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.3,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke4HiAcY7\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl6As0cF7\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkNksoRctQ\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkemqsC9Fm\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rk4Qso0cKm\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJeQbnA5tm\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xEtoRqtQ\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgK6iA5KX\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygHGnRqK7\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.3,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryMQ5sRqYX\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedwoC5t7\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1My6sR9tX\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1erHoR5t7\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyNvti09KQ\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkGiPoC5FX\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syfz6sC9tQ\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByMVTsR5KQ\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlaYi05tm\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlgNh0qKQ\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "4bbe1559-5706-40f3-922e-f30f40ecfd6a",
       "layout": "IPY_MODEL_6a6c620fdfd44f96ae716a2f3cdf140d",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "8408dfde88b44da491c003b4bfbb2ce8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8797c79941114de68f55abd967bc6648": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "fc6fda92-ef84-4c14-b355-e9bf82d9b050",
       "layout": "IPY_MODEL_ae7ebb328f534dbaa5af21a07f5f8997",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "89fd6f31f6a147ecb49595ea0a51ca8d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "906fa1aea348455dab201f463bcc8ae8": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"State-Regularized Recurrent Networks\",\"avg_confidence\":4.66667,\"avg_rating\":5.66667,\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_confidence\":3.33333,\"avg_rating\":5.66667,\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"The Deep Weight Prior\",\"avg_confidence\":3.66667,\"avg_rating\":6.33333,\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_confidence\":2.66667,\"avg_rating\":7.0,\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"Adversarial Information Factorization\",\"avg_confidence\":4.0,\"avg_rating\":6.0,\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"Attentive Neural Processes\",\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Complement Objective Training\",\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"tldr\":\"\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"tldr\":\"\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_confidence\":2.0,\"avg_rating\":6.66667,\"tldr\":\"\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_confidence\":4.66667,\"avg_rating\":5.33333,\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_confidence\":3.33333,\"avg_rating\":4.66667,\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"tldr\":\"\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"confidence\":\"[3, 3, 4]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_confidence\":4.33333,\"avg_rating\":4.33333,\"tldr\":\"\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_confidence\":3.25,\"avg_rating\":4.0,\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_confidence\":4.5,\"avg_rating\":6.5,\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"confidence\":\"[5, 4]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learning what you can do before doing anything\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_confidence\":4.0,\"avg_rating\":7.33333,\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_confidence\":4.33333,\"avg_rating\":5.0,\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"tldr\":\"\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_confidence\":3.0,\"avg_rating\":7.0,\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_confidence\":3.66667,\"avg_rating\":4.66667,\"tldr\":\"\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_confidence\":4.0,\"avg_rating\":6.5,\"tldr\":\"\",\"confidence\":\"[4, 4]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_confidence\":3.0,\"avg_rating\":5.0,\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_confidence\":3.5,\"avg_rating\":5.5,\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"The Problem of Model Completion\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_confidence\":3.0,\"avg_rating\":7.0,\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"tldr\":\"\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"confidence\":\"[4, 4, 5]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"tldr\":\"\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_confidence\":4.66667,\"avg_rating\":7.66667,\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Generative Feature Matching Networks\",\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Adversarial Audio Synthesis\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_confidence\":3.0,\"avg_rating\":3.5,\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"confidence\":\"[4, 2]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"confidence\":\"[4, 5, 2]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"tldr\":\"\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Learning Entropic Wasserstein Embeddings\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Invariance and Inverse Stability under ReLU\",\"avg_confidence\":3.5,\"avg_rating\":6.5,\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\",\"confidence\":\"[4, 3]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"avg_confidence\":4.5,\"avg_rating\":6.0,\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\",\"confidence\":\"[4, 5]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"avg_confidence\":4.0,\"avg_rating\":4.66667,\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"avg_confidence\":3.33333,\"avg_rating\":6.33333,\"tldr\":\"\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Reward Constrained Policy Optimization\",\"avg_confidence\":3.0,\"avg_rating\":6.0,\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\",\"confidence\":\"[4, 2, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_confidence\":4.66667,\"avg_rating\":7.0,\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"avg_confidence\":3.66667,\"avg_rating\":6.0,\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"confidence\":\"[4, 2, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Adaptive Neural Trees\",\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"Phrase-Based Attentions\",\"avg_confidence\":4.66667,\"avg_rating\":5.0,\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Deep Layers as Stochastic Solvers\",\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\",\"confidence\":\"[4, 5, 1]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"tldr\":\"\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"avg_confidence\":4.66667,\"avg_rating\":6.33333,\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"tldr\":\"\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"tldr\":\"\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \",\"confidence\":\"[4, 5, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"avg_confidence\":4.33333,\"avg_rating\":5.33333,\"tldr\":\"\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Feature-Wise Bias Amplification\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"avg_confidence\":4.0,\"avg_rating\":3.66667,\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Sorting out Lipschitz function approximation\",\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"avg_confidence\":3.0,\"avg_rating\":6.0,\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Interpretable Continual Learning\",\"avg_confidence\":3.0,\"avg_rating\":5.5,\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \",\"confidence\":\"[3, 3]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"Implicit Autoencoders\",\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"avg_confidence\":4.0,\"avg_rating\":4.33333,\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \",\"confidence\":\"[4, 4, 4]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_confidence\":3.33333,\"avg_rating\":3.66667,\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"avg_confidence\":4.33333,\"avg_rating\":5.66667,\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"avg_confidence\":4.0,\"avg_rating\":6.0,\"tldr\":\"\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\",\"confidence\":\"[5, 5, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"avg_confidence\":4.0,\"avg_rating\":6.0,\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"avg_confidence\":4.5,\"avg_rating\":5.5,\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\",\"confidence\":\"[4, 5]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \",\"confidence\":\"[4, 5, 4]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_confidence\":3.0,\"avg_rating\":7.0,\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\",\"confidence\":\"[5, 3, 3]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"DEEP GRAPH TRANSLATION\",\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"tldr\":\"\",\"confidence\":\"[2, 4, 4]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "84118ae6-49e8-46b3-af13-f82e413d57c9",
       "layout": "IPY_MODEL_1ec3e4489bd046a6a0aa587ed10338d5",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "90e109e3e5c74d69a3f30fb87bd7f98c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "92466b87f1544b18a0257ac0a88cb9ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9414703c11f44ed5ae1348933237e5c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9522078d234846289dbcae44bc2182a4": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 100
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxfEn09Y7\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"Adversarial examples\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4dFjR5K7\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"Generative Model\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke4KsA5FX\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgYl205tQ\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.3,\"avg_confidence\":3.0,\"topic\":\"Model Interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1E3Ko09F7\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"Information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJg8yhAqKm\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJGtFoC5Fm\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.8,\"topic\":\"adversarial examples\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgVRiC9Km\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.7,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTciR9tm\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Artificial Intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl42iA5t7\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.3,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylKB3A9Fm\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlxm30cKm\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Neural Machine Translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eEdj0cK7\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygqqsA9KX\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.2,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygn2o0qKX\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1GLm2R9Km\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke-JhA9Y7\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJlmHoR5tQ\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygfghAcYX\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"Network Compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xLN3C9YX\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"PU learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJzLciCqKm\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1MAJhR5YX\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xsSjC9Ym\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"Maximum Mean Discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkG5SjR5YQ\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"neural network\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eJssCqY7\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"embeddings\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJxeWnCcF7\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.7,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1grRoR9tQ\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgnmhA5KQ\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxnvsAqFm\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.3,\"avg_confidence\":4.3,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxcHnRqYQ\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"adversarial examples\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJl2niR9KQ\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxt8oC9FQ\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"Lifelong Learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hkf2_sC5FX\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.7,\"topic\":\"Model free RL\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HygsfnR9Ym\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"Deep Learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl0r3R9KX\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"Adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlk6iRqKX\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"Dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklSf3CqKm\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"CNN\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMHpjC9Ym\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJf_YjCqYX\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlEojAqFm\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bye9LiR9YX\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgToo0qFm\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygxb2CqKm\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl2E3AcF7\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4fpoA5Km\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.3,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxBFsRqYm\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyVU6s05K7\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"NLP\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xtAjR5tX\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.7,\"avg_confidence\":4.7,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJf7ts0cFm\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.7,\"avg_confidence\":3.3,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SklcFsAcKX\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByGuynAct7\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJfRpoA9YX\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syxt2jC5FX\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkE6PjC9KX\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyM7AiA5YX\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.7,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1ebTsActm\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJeXSo09FQ\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.3,\"avg_confidence\":4.7,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx38iC5KX\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.7,\"avg_confidence\":3.3,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklnzhR9YQ\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx7l309Fm\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzjBiR9t7\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1MB-3RcF7\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.3,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkgnpiR9Y7\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.2,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1e7hs05Km\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.3,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyePrhR5KX\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylPMnR9Ym\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyehMhC9Y7\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygm8jC9FQ\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJedV3R5tm\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke96sC5tm\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryf6Fs09YX\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.3,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke4HiAcY7\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl6As0cF7\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkNksoRctQ\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkemqsC9Fm\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rk4Qso0cKm\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJeQbnA5tm\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xEtoRqtQ\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgK6iA5KX\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygHGnRqK7\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.3,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryMQ5sRqYX\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedwoC5t7\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1My6sR9tX\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1erHoR5t7\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyNvti09KQ\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkGiPoC5FX\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syfz6sC9tQ\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByMVTsR5KQ\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlaYi05tm\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlgNh0qKQ\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "028069a9-57d2-4714-8934-450a76eee962",
       "layout": "IPY_MODEL_a56e921bf4884058a4c661b34681e38c",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "96a91434da2b4e1a8ec8237ed45d8a4e": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 100
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 1000
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 100
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 300
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxfEn09Y7\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"adversarial example\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4dFjR5K7\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"generative models\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke4KsA5FX\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"generative adversarial network\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgYl205tQ\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.3,\"avg_confidence\":3.0,\"topic\":\"model interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1E3Ko09F7\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJg8yhAqKm\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJGtFoC5Fm\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.8,\"topic\":\"adversarial example\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgVRiC9Km\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.7,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTciR9tm\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"artificial intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl42iA5t7\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.3,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylKB3A9Fm\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlxm30cKm\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"neural machine translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eEdj0cK7\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygqqsA9KX\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.2,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygn2o0qKX\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1GLm2R9Km\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke-JhA9Y7\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"inverse reinforcement learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJlmHoR5tQ\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygfghAcYX\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"network compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xLN3C9YX\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"pu learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJzLciCqKm\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1MAJhR5YX\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xsSjC9Ym\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"maximum mean discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkG5SjR5YQ\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"neural networks\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eJssCqY7\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"embedding\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJxeWnCcF7\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.7,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1grRoR9tQ\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgnmhA5KQ\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxnvsAqFm\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.3,\"avg_confidence\":4.3,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxcHnRqYQ\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"adversarial example\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJl2niR9KQ\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxt8oC9FQ\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"life-long learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hkf2_sC5FX\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.7,\"topic\":\"model free rl\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HygsfnR9Ym\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl0r3R9KX\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlk6iRqKX\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklSf3CqKm\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"cnn\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMHpjC9Ym\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJf_YjCqYX\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlEojAqFm\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bye9LiR9YX\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgToo0qFm\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygxb2CqKm\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl2E3AcF7\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4fpoA5Km\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.3,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxBFsRqYm\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyVU6s05K7\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"nlp\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xtAjR5tX\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.7,\"avg_confidence\":4.7,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJf7ts0cFm\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.7,\"avg_confidence\":3.3,\"topic\":\"non convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SklcFsAcKX\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByGuynAct7\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"generative models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representation\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJfRpoA9YX\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syxt2jC5FX\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"neural processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkE6PjC9KX\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyM7AiA5YX\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.7,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1ebTsActm\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"gan\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJeXSo09FQ\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.3,\"avg_confidence\":4.7,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx38iC5KX\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.7,\"avg_confidence\":3.3,\"topic\":\"cnn\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklnzhR9YQ\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"multi agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx7l309Fm\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzjBiR9t7\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"generative adversarial network\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1MB-3RcF7\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.3,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkgnpiR9Y7\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.2,\"topic\":\"deep rl\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1e7hs05Km\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.3,\"topic\":\"dynamic graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyePrhR5KX\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylPMnR9Ym\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyehMhC9Y7\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygm8jC9FQ\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"relgan\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJedV3R5tm\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"model based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke96sC5tm\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryf6Fs09YX\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.3,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke4HiAcY7\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl6As0cF7\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkNksoRctQ\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkemqsC9Fm\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rk4Qso0cKm\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJeQbnA5tm\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xEtoRqtQ\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial example\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"meta learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgK6iA5KX\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bayesian nonparametric\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygHGnRqK7\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.3,\"topic\":\"gans\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryMQ5sRqYX\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedwoC5t7\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1My6sR9tX\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"ai\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1erHoR5t7\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyNvti09KQ\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"direct feedback alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkGiPoC5FX\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"generative deep neural networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syfz6sC9tQ\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByMVTsR5KQ\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional network\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlaYi05tm\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlgNh0qKQ\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 100,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": false,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "8d18355d-6e20-49e9-a77f-36099f4fc09c",
       "layout": "IPY_MODEL_0eea5c828290485e9e035ea8d371b82c",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "96ac06f46af14caba212d3bab16e2639": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "984db0de343c4cff89343905bd9bfbe4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9873cf51b050430a9de3cee114a51ac7": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 100
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxfEn09Y7\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"adversarial example\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4dFjR5K7\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"generative models\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke4KsA5FX\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"generative adversarial network\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgYl205tQ\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.3,\"avg_confidence\":3.0,\"topic\":\"model interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1E3Ko09F7\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJg8yhAqKm\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJGtFoC5Fm\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.8,\"topic\":\"adversarial example\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgVRiC9Km\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.7,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTciR9tm\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"artificial intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl42iA5t7\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.3,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylKB3A9Fm\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlxm30cKm\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"neural machine translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eEdj0cK7\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygqqsA9KX\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.2,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygn2o0qKX\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1GLm2R9Km\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke-JhA9Y7\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"inverse reinforcement learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJlmHoR5tQ\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygfghAcYX\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"network compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xLN3C9YX\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"pu learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJzLciCqKm\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1MAJhR5YX\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xsSjC9Ym\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"maximum mean discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkG5SjR5YQ\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"neural networks\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eJssCqY7\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"embedding\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJxeWnCcF7\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.7,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1grRoR9tQ\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgnmhA5KQ\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxnvsAqFm\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.3,\"avg_confidence\":4.3,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxcHnRqYQ\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"adversarial example\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJl2niR9KQ\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxt8oC9FQ\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"life-long learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hkf2_sC5FX\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.7,\"topic\":\"model free rl\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HygsfnR9Ym\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl0r3R9KX\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlk6iRqKX\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklSf3CqKm\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"cnn\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMHpjC9Ym\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJf_YjCqYX\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlEojAqFm\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bye9LiR9YX\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgToo0qFm\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygxb2CqKm\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl2E3AcF7\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4fpoA5Km\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.3,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxBFsRqYm\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyVU6s05K7\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"nlp\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xtAjR5tX\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.7,\"avg_confidence\":4.7,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJf7ts0cFm\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.7,\"avg_confidence\":3.3,\"topic\":\"non convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SklcFsAcKX\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByGuynAct7\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"generative models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representation\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJfRpoA9YX\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syxt2jC5FX\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"neural processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkE6PjC9KX\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyM7AiA5YX\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.7,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1ebTsActm\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"gan\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJeXSo09FQ\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.3,\"avg_confidence\":4.7,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx38iC5KX\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.7,\"avg_confidence\":3.3,\"topic\":\"cnn\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklnzhR9YQ\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"multi agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx7l309Fm\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzjBiR9t7\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"generative adversarial network\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1MB-3RcF7\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.3,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkgnpiR9Y7\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.2,\"topic\":\"deep rl\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1e7hs05Km\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.3,\"topic\":\"dynamic graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyePrhR5KX\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylPMnR9Ym\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyehMhC9Y7\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygm8jC9FQ\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"relgan\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJedV3R5tm\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"model based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke96sC5tm\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryf6Fs09YX\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.3,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke4HiAcY7\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl6As0cF7\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkNksoRctQ\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkemqsC9Fm\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rk4Qso0cKm\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJeQbnA5tm\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xEtoRqtQ\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial example\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"meta learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgK6iA5KX\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bayesian nonparametric\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygHGnRqK7\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.3,\"topic\":\"gans\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryMQ5sRqYX\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedwoC5t7\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1My6sR9tX\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"ai\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1erHoR5t7\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyNvti09KQ\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"direct feedback alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkGiPoC5FX\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"generative deep neural networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syfz6sC9tQ\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByMVTsR5KQ\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional network\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlaYi05tm\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlgNh0qKQ\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "9ad41894-698e-45c2-b754-989b9a46b0dc",
       "layout": "IPY_MODEL_89fd6f31f6a147ecb49595ea0a51ca8d",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "98e9fd455eb249aa84334731682822ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "98ff22ab22c04d1c9be22486b926064b": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "maxWidth": null,
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": null
        },
        "index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "maxWidth": null,
         "minWidth": 30,
         "name": "index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "maxWidth": null,
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": null
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "maxWidth": null,
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": null
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "maxWidth": null,
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": null
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "5543d529-64c7-4cea-905b-19e3c82db6f8",
       "layout": "IPY_MODEL_d85f788fc55e478c8361b5a72b3f8b54",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "99cb1d78c27341b79bbf0f2b17dc5ef6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9bbf4216f097406b8492478922efcd7c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9c11d7bda4524e91a01b406ea40ab2b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9cedb93d128d4b5d89ccd05edbbd875c": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":1002,\"qgrid_unfiltered_index\":1002,\"title\":\"Exploration by random distillation\",\"avg_rating\":8.66667,\"avg_confidence\":4.33333,\"tldr\":\"A simple exploration bonus is introduced and achieves state of the art performance in 3 hard exploration Atari games.\",\"ratings\":\"[9, 10, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":679,\"qgrid_unfiltered_index\":679,\"title\":\"Large Scale GAN Training for High Fidelity Natural Image Synthesis\",\"avg_rating\":8.33333,\"avg_confidence\":3.66667,\"tldr\":\"GANs benefit from scaling up.\",\"ratings\":\"[7, 8, 10]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":618,\"qgrid_unfiltered_index\":618,\"title\":\"Benchmarking Neural Network Robustness to Common Corruptions and Perturbations\",\"avg_rating\":8.33333,\"avg_confidence\":4.0,\"tldr\":\"We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness\",\"ratings\":\"[7, 9, 9]\",\"confidence\":\"[3, 5, 4]\"},{\"Index\":857,\"qgrid_unfiltered_index\":857,\"title\":\"GENERATING HIGH FIDELITY IMAGES WITH SUBSCALE PIXEL NETWORKS AND MULTIDIMENSIONAL UPSCALING\",\"avg_rating\":8.0,\"avg_confidence\":3.66667,\"tldr\":\"We show that autoregressive models can generate high fidelity images. \",\"ratings\":\"[10, 7, 7]\",\"confidence\":\"[5, 3, 3]\"},{\"Index\":1298,\"qgrid_unfiltered_index\":1298,\"title\":\"ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA\",\"avg_rating\":8.0,\"avg_confidence\":4.33333,\"tldr\":\"\",\"ratings\":\"[10, 6, 8]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":1104,\"qgrid_unfiltered_index\":1104,\"title\":\"Temporal Difference Variational Auto-Encoder\",\"avg_rating\":8.0,\"avg_confidence\":4.33333,\"tldr\":\"Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":689,\"qgrid_unfiltered_index\":689,\"title\":\"Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks\",\"avg_rating\":8.0,\"avg_confidence\":3.66667,\"tldr\":\"We introduce a new inductive bias that integrates tree structures in recurrent neural networks.\",\"ratings\":\"[9, 7, 8]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":1440,\"qgrid_unfiltered_index\":1440,\"title\":\"Posterior Attention Models for Sequence to Sequence Learning\",\"avg_rating\":8.0,\"avg_confidence\":4.33333,\"tldr\":\"Computing attention based on posterior distribution leads to more meaningful attention and better performance\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":200,\"qgrid_unfiltered_index\":200,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.66667,\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\"},{\"Index\":931,\"qgrid_unfiltered_index\":931,\"title\":\"Slimmable Neural Networks\",\"avg_rating\":8.0,\"avg_confidence\":4.33333,\"tldr\":\"We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":1116,\"qgrid_unfiltered_index\":1116,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.33333,\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":1493,\"qgrid_unfiltered_index\":1493,\"title\":\"Composing Complex Skills by Learning Transition Policies with Proximity Reward Induction\",\"avg_rating\":7.66667,\"avg_confidence\":4.0,\"tldr\":\"Transition policies enable agents to execute learned skills smoothly to perform complex tasks.\",\"ratings\":\"[7, 9, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":1231,\"qgrid_unfiltered_index\":1231,\"title\":\"Supervised Community Detection with Line Graph Neural Networks\",\"avg_rating\":7.66667,\"avg_confidence\":4.0,\"tldr\":\"We propose a novel graph neural network architecture based on the non-backtracking operator defined over edge adjacencies and demonstrate its effectiveness on community detection tasks on graphs.\",\"ratings\":\"[6, 9, 8]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":581,\"qgrid_unfiltered_index\":581,\"title\":\"Critical Learning Periods in Deep Networks\",\"avg_rating\":7.66667,\"avg_confidence\":4.33333,\"tldr\":\"Sensory deficits in early training phases can lead to irreversible performance loss in both artificial and neuronal networks, suggesting information phenomena as the common cause, and point to the importance of the initial transient and forgetting.\",\"ratings\":\"[9, 8, 6]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":605,\"qgrid_unfiltered_index\":605,\"title\":\"Sparse Dictionary Learning by Dynamical Neural Networks\",\"avg_rating\":7.66667,\"avg_confidence\":4.0,\"tldr\":\"\",\"ratings\":\"[6, 9, 8]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":216,\"qgrid_unfiltered_index\":216,\"title\":\"Smoothing the Geometry of Probabilistic Box Embeddings\",\"avg_rating\":7.66667,\"avg_confidence\":3.33333,\"tldr\":\"Improve hierarchical embedding models using kernel smoothing\",\"ratings\":\"[8, 8, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":237,\"qgrid_unfiltered_index\":237,\"title\":\"ON RANDOM DEEP AUTOENCODERS: EXACT ASYMPTOTIC ANALYSIS, PHASE TRANSITIONS, AND IMPLICATIONS TO TRAINING\",\"avg_rating\":7.66667,\"avg_confidence\":4.0,\"tldr\":\"We study the behavior of weight-tied multilayer vanilla autoencoders under the assumption of random weights. Via an exact characterization in the limit of large dimensions, our analysis reveals interesting phase transition phenomena.\",\"ratings\":\"[9, 6, 8]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":315,\"qgrid_unfiltered_index\":315,\"title\":\"Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware\",\"avg_rating\":7.66667,\"avg_confidence\":3.0,\"tldr\":\"We accelerate secure DNN inference in trusted execution environments (by a factor 4x-20x) by selectively outsourcing the computation of linear layers to a faster yet untrusted co-processor.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[3, 2, 4]\"},{\"Index\":752,\"qgrid_unfiltered_index\":752,\"title\":\"Learning Robust Representations by Projecting Superficial Statistics Out\",\"avg_rating\":7.66667,\"avg_confidence\":3.66667,\"tldr\":\"Building on previous work on domain generalization, we hope to produce a classifier that will generalize to previously unseen domains, even when domain identifiers are not available during training.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":1325,\"qgrid_unfiltered_index\":1325,\"title\":\"Adaptive Input Representations for Neural Language Modeling\",\"avg_rating\":7.66667,\"avg_confidence\":4.0,\"tldr\":\"Variable capacity input word embeddings and SOTA on WikiText-103, Billion Word benchmarks.\",\"ratings\":\"[7, 8, 8]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":1452,\"qgrid_unfiltered_index\":1452,\"title\":\"A Variational Inequality Perspective on Generative Adversarial Networks\",\"avg_rating\":7.66667,\"avg_confidence\":3.33333,\"tldr\":\"We cast GANs in the variational inequality framework and import techniques from this literature to optimize GANs better; we give algorithmic extensions and empirically test their performance for training GANs.\",\"ratings\":\"[8, 8, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":736,\"qgrid_unfiltered_index\":736,\"title\":\"Learning Unsupervised Learning Rules\",\"avg_rating\":7.66667,\"avg_confidence\":3.33333,\"tldr\":\"We learn an unsupervised learning algorithm that produces useful representations from a set of supervised tasks. At test-time, we apply this algorithm to new tasks without any supervision and show performance comparable to a VAE.\",\"ratings\":\"[8, 7, 8]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":1145,\"qgrid_unfiltered_index\":1145,\"title\":\"Pay Less Attention with Lightweight and Dynamic Convolutions\",\"avg_rating\":7.66667,\"avg_confidence\":4.0,\"tldr\":\"Dynamic lightweight convolutions are competitive to self-attention on language tasks.\",\"ratings\":\"[8, 7, 8]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":413,\"qgrid_unfiltered_index\":413,\"title\":\"Identifying and Controlling Important Neurons in Neural Machine Translation\",\"avg_rating\":7.66667,\"avg_confidence\":3.33333,\"tldr\":\"Unsupervised methods for finding, analyzing, and controlling important neurons in NMT\",\"ratings\":\"[7, 10, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":631,\"qgrid_unfiltered_index\":631,\"title\":\"KnockoffGAN: Generating Knockoffs for Feature Selection using Generative Adversarial Networks\",\"avg_rating\":7.66667,\"avg_confidence\":4.0,\"tldr\":\"\",\"ratings\":\"[6, 10, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":309,\"qgrid_unfiltered_index\":309,\"title\":\"Diffusion Scattering Transforms on Graphs\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"tldr\":\"Stability of scattering transform representations of graph data to deformations of the underlying graph support.\",\"ratings\":\"[9, 6]\",\"confidence\":\"[5, 3]\"},{\"Index\":1245,\"qgrid_unfiltered_index\":1245,\"title\":\"Kernel Change-point Detection with Auxiliary Deep Generative Models\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"tldr\":\"In this paper, we propose KL-CPD, a novel kernel learning framework for time series CPD that optimizes a lower bound of test power via an auxiliary generative model as a surrogate to the abnormal distribution. \",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":1541,\"qgrid_unfiltered_index\":1541,\"title\":\"Visualizing and Understanding Generative Adversarial Networks\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"tldr\":\"GAN representations are examined in detail, and sets of representation units are found that control the generation of semantic concepts in the output.\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":1196,\"qgrid_unfiltered_index\":1196,\"title\":\"Biologically-Plausible Learning Algorithms Can Scale to Large Datasets\",\"avg_rating\":7.33333,\"avg_confidence\":4.33333,\"tldr\":\"Biologically plausible learning algorithms, particularly sign-symmetry, works well on ImageNet\",\"ratings\":\"[9, 9, 4]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":513,\"qgrid_unfiltered_index\":513,\"title\":\"Evaluating Robustness of Neural Networks with Mixed Integer Programming\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"tldr\":\"We efficiently verify the robustness of deep neural models with over 100,000 ReLUs, certifying more samples than the state-of-the-art and finding more adversarial examples than a strong first-order attack.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[5, 5, 1]\"},{\"Index\":982,\"qgrid_unfiltered_index\":982,\"title\":\"Efficient Training on Very Large Corpora via Gramian Estimation\",\"avg_rating\":7.33333,\"avg_confidence\":2.66667,\"tldr\":\"We develop efficient methods to train neural embedding models with a dot-product structure, by reformulating the objective function in terms of generalized Gram matrices, and maintaining estimates of those matrices.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[4, 2, 2]\"},{\"Index\":839,\"qgrid_unfiltered_index\":839,\"title\":\"Diversity is All You Need: Learning Skills without a Reward Function\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"tldr\":\"We propose an algorithm for learning useful skills without a reward function, and show how these skills can be used to solve downstream tasks.\",\"ratings\":\"[8, 7, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":633,\"qgrid_unfiltered_index\":633,\"title\":\"Approximability of Discriminators Implies Diversity in GANs\",\"avg_rating\":7.33333,\"avg_confidence\":2.66667,\"tldr\":\"GANs can in principle learn distributions sample-efficiently, if the discriminator class is compact and has strong distinguishing power against the particular generator class.\",\"ratings\":\"[8, 7, 7]\",\"confidence\":\"[2, 3, 3]\"},{\"Index\":1082,\"qgrid_unfiltered_index\":1082,\"title\":\"Gradient descent aligns the layers of deep linear networks\",\"avg_rating\":7.33333,\"avg_confidence\":4.33333,\"tldr\":\"\",\"ratings\":\"[7, 9, 6]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":1507,\"qgrid_unfiltered_index\":1507,\"title\":\"Label super-resolution networks\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"tldr\":\"Super-resolving coarse labels into pixel-level labels, applied to aerial imagery and medical scans.\",\"ratings\":\"[7, 6, 9]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":593,\"qgrid_unfiltered_index\":593,\"title\":\"Small nonlinearities in activation functions create bad local minima in neural networks\",\"avg_rating\":7.33333,\"avg_confidence\":3.33333,\"tldr\":\"We constructively prove that even the slightest nonlinear activation functions introduce spurious local minima, for general datasets and activation functions.\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":1279,\"qgrid_unfiltered_index\":1279,\"title\":\"LanczosNet: Multi-Scale Deep Graph Convolutional Networks\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"tldr\":\"\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 5, 4]\"},{\"Index\":441,\"qgrid_unfiltered_index\":441,\"title\":\"Large-Scale Study of Curiosity-Driven Learning\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"tldr\":\"An agent trained only with curiosity, and no extrinsic reward, does surprisingly well on 54 popular environments, including the suite of Atari games, Mario etc.\",\"ratings\":\"[6, 9, 7]\",\"confidence\":\"[4, 5, 3]\"},{\"Index\":1244,\"qgrid_unfiltered_index\":1244,\"title\":\"Towards Metamerism via Foveated Style Transfer\",\"avg_rating\":7.33333,\"avg_confidence\":4.33333,\"tldr\":\"We introduce a novel feed-forward framework to generate visual metamers\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":938,\"qgrid_unfiltered_index\":938,\"title\":\"ProMP: Proximal Meta-Policy Search\",\"avg_rating\":7.33333,\"avg_confidence\":3.0,\"tldr\":\"A novel and theoretically grounded meta-reinforcement learning algorithm\",\"ratings\":\"[6, 7, 9]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":334,\"qgrid_unfiltered_index\":334,\"title\":\"Differentiable Learning-to-Normalize via Switchable Normalization\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"tldr\":\"\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":822,\"qgrid_unfiltered_index\":822,\"title\":\"The effects of neural resource constraints on early visual representations \",\"avg_rating\":7.0,\"avg_confidence\":4.33333,\"tldr\":\"We reproduced neural representations found in biological visual systems by simulating their neural resource constraints in a deep convolutional model.\",\"ratings\":\"[5, 8, 8]\",\"confidence\":\"[5, 5, 3]\"},{\"Index\":1172,\"qgrid_unfiltered_index\":1172,\"title\":\"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"tldr\":\"Feedforward neural networks that can have weights pruned after training could have had the same weights pruned before training\",\"ratings\":\"[5, 8, 8]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":323,\"qgrid_unfiltered_index\":323,\"title\":\"ADVERSARIAL DOMAIN ADAPTATION FOR STABLE BRAIN-MACHINE INTERFACES\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"tldr\":\"We implement an adversarial domain adaptation network to stabilize a fixed Brain-Machine Interface against gradual changes in the recorded neural signals.\",\"ratings\":\"[9, 5, 7]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":930,\"qgrid_unfiltered_index\":930,\"title\":\"Learning Self-Imitating Diverse Policies\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"tldr\":\"Policy optimization by using past good rollouts from the agent; learning shaped rewards via divergence minimization; SVPG with JS-kernel for population-based exploration.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[3, 2, 4]\"},{\"Index\":1092,\"qgrid_unfiltered_index\":1092,\"title\":\"The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision\",\"avg_rating\":7.0,\"avg_confidence\":4.33333,\"tldr\":\"We present a Neuro-Symbolic Concept Learner to learn visual concepts, words, and semantic parsing of sentences without explicit annotations for any of them. \",\"ratings\":\"[7, 5, 9]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":910,\"qgrid_unfiltered_index\":910,\"title\":\"The Comparative Power of ReLU Networks and Polynomial Kernels in the Presence of Sparse Latent Structure\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"tldr\":\"Beyond-worst-case analysis of the representational power of  ReLU nets & polynomial kernels  -- in particular in the presence of sparse latent structure.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":1224,\"qgrid_unfiltered_index\":1224,\"title\":\"Learning Neural PDE Solvers with Convergence Guarantees\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"tldr\":\"We learn a fast neural solver for PDEs that has convergence guarantees.\",\"ratings\":\"[7, 8, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":678,\"qgrid_unfiltered_index\":678,\"title\":\"Riemannian Adaptive Optimization Methods\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"tldr\":\"Adapting Adam, Amsgrad, Adagrad to Riemannian manifolds. \",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 5, 4]\"},{\"Index\":345,\"qgrid_unfiltered_index\":345,\"title\":\"An analytic theory of generalization dynamics and transfer learning in deep linear networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"tldr\":\"We provide many insights into neural network generalization from the theoretically tractable linear case.\",\"ratings\":\"[8, 7, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":742,\"qgrid_unfiltered_index\":742,\"title\":\"How Important is a Neuron\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 2, 5]\"},{\"Index\":473,\"qgrid_unfiltered_index\":473,\"title\":\"EMI: Exploration with Mutual Information Maximizing State and Action Embeddings\",\"avg_rating\":7.0,\"avg_confidence\":3.5,\"tldr\":\"\",\"ratings\":\"[7, 7]\",\"confidence\":\"[4, 3]\"},{\"Index\":1273,\"qgrid_unfiltered_index\":1273,\"title\":\"Lagging Inference Networks and Posterior Collapse in Variational Autoencoders\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"tldr\":\"To address posterior collapse in VAEs, we propose a simple yet effective training algorithm that aggressively optimizes inference network with more updates\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":636,\"qgrid_unfiltered_index\":636,\"title\":\"Deep Graph Infomax\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"tldr\":\"A new method for unsupervised representation learning on graphs, relying on maximizing mutual information between local and global representations in a graph. State-of-the-art results, competitive with supervised learning.\",\"ratings\":\"[7, 9, 5]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":769,\"qgrid_unfiltered_index\":769,\"title\":\"Neural network gradient-based learning of black-box function interfaces\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"tldr\":\"Training DNNs to interface w\\\\ black box functions w\\\\o intermediate labels by using an estimator sub-network that can be replaced with the black box after training\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":491,\"qgrid_unfiltered_index\":491,\"title\":\"Near-Optimal Representation Learning for Hierarchical Reinforcement Learning\",\"avg_rating\":7.0,\"avg_confidence\":4.33333,\"tldr\":\"We translate a bound on sub-optimality of representations to a practical training objective in the context of hierarchical reinforcement learning.\",\"ratings\":\"[6, 6, 9]\",\"confidence\":\"[3, 5, 5]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":1260,\"qgrid_unfiltered_index\":1260,\"title\":\"Improving the Differentiable Neural Computer Through Memory Masking, De-allocation, and Link Distribution Sharpness Control\",\"avg_rating\":7.0,\"avg_confidence\":5.0,\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[5, 5, 5]\"},{\"Index\":154,\"qgrid_unfiltered_index\":154,\"title\":\"Learning a SAT Solver from Single-Bit Supervision\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"tldr\":\"We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":722,\"qgrid_unfiltered_index\":722,\"title\":\"Deep Learning 3D Shapes Using Alt-az Anisotropic 2-Sphere Convolution\",\"avg_rating\":7.0,\"avg_confidence\":4.33333,\"tldr\":\"A method for applying deep learning to 3D surfaces using their spherical descriptors and alt-az anisotropic convolution on 2-sphere.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[3, 5, 5]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":902,\"qgrid_unfiltered_index\":902,\"title\":\"How Powerful are Graph Neural Networks?\",\"avg_rating\":7.0,\"avg_confidence\":5.0,\"tldr\":\"We develop theoretical foundations for expressive power of GNNs and design a provably most powerful GNN.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[5, 5, 5]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":306,\"qgrid_unfiltered_index\":306,\"title\":\"DARTS: Differentiable Architecture Search\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"tldr\":\"We propose a differentiable architecture search algorithm for both convolutional and recurrent networks, achieving competitive performance with the state of the art using orders of magnitude less computation resources.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[2, 5, 3]\"},{\"Index\":789,\"qgrid_unfiltered_index\":789,\"title\":\"Wizard of Wikipedia: Knowledge-Powered Conversational Agents\",\"avg_rating\":7.0,\"avg_confidence\":4.33333,\"tldr\":\"We build knowledgeable conversational agents by conditioning on Wikipedia + a new supervised task.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.66667,\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":1064,\"qgrid_unfiltered_index\":1064,\"title\":\"Local SGD Converges Fast and Communicates Little\",\"avg_rating\":7.0,\"avg_confidence\":4.66667,\"tldr\":\"We prove that parallel local SGD achieves linear speedup with much lesser communication than parallel mini-batch SGD.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":635,\"qgrid_unfiltered_index\":635,\"title\":\"SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY\",\"avg_rating\":7.0,\"avg_confidence\":4.33333,\"tldr\":\"We present a new approach, SNIP, that is simple, versatile and interpretable; it prunes irrelevant connections for a given task at single-shot prior to training and is applicable to a variety of neural network models without modifications.\",\"ratings\":\"[6, 6, 9]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":1482,\"qgrid_unfiltered_index\":1482,\"title\":\"Learning to Screen for Fast Softmax  Inference on Large Vocabulary Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"tldr\":\"\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":1411,\"qgrid_unfiltered_index\":1411,\"title\":\"GANSynth: Adversarial Neural Audio Synthesis\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"tldr\":\"High-quality audio synthesis with GANs\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":1097,\"qgrid_unfiltered_index\":1097,\"title\":\"Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word Vectors\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"tldr\":\"Max-pooled word vectors with fuzzy Jaccard set similarity are an extremely competitive baseline for semantic similarity; we propose a simple dynamic variant that performs even better.\",\"ratings\":\"[8, 8, 5]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":984,\"qgrid_unfiltered_index\":984,\"title\":\"Unsupervised Domain Adaptation for Distance Metric Learning\",\"avg_rating\":7.0,\"avg_confidence\":4.33333,\"tldr\":\"A new theory of unsupervised domain adaptation for distance metric learning and its application to face recognition across diverse ethnicity variations.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":818,\"qgrid_unfiltered_index\":818,\"title\":\"Gradient Descent Provably Optimizes Over-parameterized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"tldr\":\"We prove gradient descent achieves zero training loss with a linear rate on over-parameterized neural networks.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":1530,\"qgrid_unfiltered_index\":1530,\"title\":\"Global-to-local Memory Pointer Networks for Task-Oriented Dialogue\",\"avg_rating\":7.0,\"avg_confidence\":2.33333,\"tldr\":\"We propose a global memory encoder and a global memory decoder that share an external knowledge to strengthen task-oriented dialogue generation via sketch responses and pointer networks. \",\"ratings\":\"[8, 8, 5]\",\"confidence\":\"[2, 2, 3]\"},{\"Index\":265,\"qgrid_unfiltered_index\":265,\"title\":\"Deep, Skinny Neural Networks are not Universal Approximators\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"tldr\":\"This paper proves that skinny neural networks cannot approximate certain functions, no matter how deep they are.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":1050,\"qgrid_unfiltered_index\":1050,\"title\":\"ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"tldr\":\"\",\"ratings\":\"[9, 5, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":1307,\"qgrid_unfiltered_index\":1307,\"title\":\"Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based RL\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":1011,\"qgrid_unfiltered_index\":1011,\"title\":\"Feature Intertwiners\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"tldr\":\"A feature intertwiner module to leverage features from one accurate set to help the learning of another less reliable set.\",\"ratings\":\"[7, 5, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":1560,\"qgrid_unfiltered_index\":1560,\"title\":\"Learning sparse relational transition models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"tldr\":\"A new approach that learns a representation for describing transition models in complex uncertaindomains using relational rules. \",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 2, 3]\"},{\"Index\":1108,\"qgrid_unfiltered_index\":1108,\"title\":\"What do you learn from context? Probing for sentence structure in contextualized word representations\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"tldr\":\"We probe for sentence structure in ELMo and related contextual embedding models. We find existing models efficiently encode syntax and show evidence of long-range dependencies, but only offer small improvements on semantic tasks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":203,\"qgrid_unfiltered_index\":203,\"title\":\"Auxiliary Variational MCMC\",\"avg_rating\":7.0,\"avg_confidence\":4.33333,\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":1332,\"qgrid_unfiltered_index\":1332,\"title\":\"Learning to Navigate the Web\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"tldr\":\"We train reinforcement learning policies using reward augmentation, curriculum learning, and meta-learning  to successfully navigate web pages.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":1129,\"qgrid_unfiltered_index\":1129,\"title\":\"Learning Implicitly Recurrent CNNs Through Parameter Sharing\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"tldr\":\"We propose a method that enables CNN folding to create recurrent connections\",\"ratings\":\"[8, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":611,\"qgrid_unfiltered_index\":611,\"title\":\"Greedy Attack and Gumbel Attack: Generating Adversarial Examples for Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"tldr\":\"We develop two methods for generating adversarial examples on discrete data under a probabilistic framework.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":632,\"qgrid_unfiltered_index\":632,\"title\":\"On the Minimal Supervision for Training Any Binary Classifier from Only Unlabeled Data\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"tldr\":\"Three class priors are all you need to train deep models from only U data, while any two should not be enough.\",\"ratings\":\"[7]\",\"confidence\":\"[4]\"},{\"Index\":1005,\"qgrid_unfiltered_index\":1005,\"title\":\"Scalable Reversible Generative Models with Free-form Continuous Dynamics\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"tldr\":\"We use continuous time dynamics to define a generative model with exact likelihoods and efficient sampling that is parameterized by unrestricted neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":1489,\"qgrid_unfiltered_index\":1489,\"title\":\"Learning to Infer and Execute 3D Shape Programs\",\"avg_rating\":6.66667,\"avg_confidence\":4.33333,\"tldr\":\"We propose 3D shape programs, a structured, compositional shape representation. Our model learns to infer and execute shape programs to explain 3D shapes.\",\"ratings\":\"[6, 7, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":145,\"qgrid_unfiltered_index\":145,\"title\":\"Non-vacuous Generalization Bounds at the ImageNet Scale: a PAC-Bayesian Compression Approach\",\"avg_rating\":6.66667,\"avg_confidence\":4.33333,\"tldr\":\"We obtain non-vacuous generalization bounds on ImageNet-scale deep neural networks by combining an original PAC-Bayes bound and an off-the-shelf neural network compression method.\",\"ratings\":\"[6, 6, 8]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":994,\"qgrid_unfiltered_index\":994,\"title\":\"Generative Question Answering: Learning to Answer the Whole Question\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"tldr\":\"Question answering models that model the joint distribution of questions and answers can learn more than discriminative models\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":1428,\"qgrid_unfiltered_index\":1428,\"title\":\"Learning from Incomplete Data with Generative Adversarial Networks\",\"avg_rating\":6.66667,\"avg_confidence\":4.33333,\"tldr\":\"This paper presents a model for learning the distribution from high-dimensional incomplete data using GANs.\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":793,\"qgrid_unfiltered_index\":793,\"title\":\"Generalized Tensor Models for Recurrent Neural Networks\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"tldr\":\"Analysis of expressivity and generality of recurrent neural networks with ReLu nonlinearities using Tensor-Train decomposition.\",\"ratings\":\"[6, 7, 7]\",\"confidence\":\"[4, 3, 4]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": false,
       "_sort_field": "avg_rating",
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        16
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "af7e04dc-4360-4f45-bc52-dd936ca75942",
       "layout": "IPY_MODEL_7cfb155efe314570a63a8274b98ddbcc",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "a158b50cdd0a44ce9a87c3ae7155851e": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"Adversarial examples\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"Generative Model\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.3,\"avg_confidence\":3.0,\"topic\":\"Model Interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"Information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.8,\"topic\":\"adversarial examples\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.7,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Artificial Intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.3,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Neural Machine Translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.2,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"Network Compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"PU learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"Maximum Mean Discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"neural network\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"embeddings\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.7,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.3,\"avg_confidence\":4.3,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"adversarial examples\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"Lifelong Learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.7,\"topic\":\"Model free RL\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"Deep Learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"Adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"Dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"CNN\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.3,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"NLP\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.7,\"avg_confidence\":4.7,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.7,\"avg_confidence\":3.3,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.7,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.3,\"avg_confidence\":4.7,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.7,\"avg_confidence\":3.3,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.3,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.2,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.3,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.3,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.3,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "019bf55a-46d2-49ab-af05-b072f3e0d36c",
       "layout": "IPY_MODEL_99cb1d78c27341b79bbf0f2b17dc5ef6",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "a53538e89a5f45db99d4de1ec9776260": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 200
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxfEn09Y7\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"Adversarial examples\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4dFjR5K7\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"Generative Model\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke4KsA5FX\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgYl205tQ\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.3,\"avg_confidence\":3.0,\"topic\":\"Model Interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1E3Ko09F7\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"Information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJg8yhAqKm\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJGtFoC5Fm\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.8,\"topic\":\"adversarial examples\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgVRiC9Km\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.7,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTciR9tm\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Artificial Intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl42iA5t7\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.3,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylKB3A9Fm\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlxm30cKm\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Neural Machine Translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eEdj0cK7\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygqqsA9KX\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.2,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygn2o0qKX\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1GLm2R9Km\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke-JhA9Y7\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJlmHoR5tQ\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygfghAcYX\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"Network Compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xLN3C9YX\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"PU learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJzLciCqKm\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1MAJhR5YX\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xsSjC9Ym\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"Maximum Mean Discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkG5SjR5YQ\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"neural network\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eJssCqY7\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"embeddings\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJxeWnCcF7\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.7,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1grRoR9tQ\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgnmhA5KQ\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxnvsAqFm\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.3,\"avg_confidence\":4.3,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxcHnRqYQ\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"adversarial examples\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJl2niR9KQ\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxt8oC9FQ\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"Lifelong Learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hkf2_sC5FX\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.7,\"topic\":\"Model free RL\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HygsfnR9Ym\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"Deep Learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl0r3R9KX\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"Adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlk6iRqKX\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"Dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklSf3CqKm\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"CNN\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMHpjC9Ym\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJf_YjCqYX\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlEojAqFm\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bye9LiR9YX\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgToo0qFm\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygxb2CqKm\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl2E3AcF7\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4fpoA5Km\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.3,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxBFsRqYm\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyVU6s05K7\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"NLP\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xtAjR5tX\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.7,\"avg_confidence\":4.7,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJf7ts0cFm\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.7,\"avg_confidence\":3.3,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SklcFsAcKX\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByGuynAct7\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJfRpoA9YX\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syxt2jC5FX\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkE6PjC9KX\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyM7AiA5YX\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.7,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1ebTsActm\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJeXSo09FQ\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.3,\"avg_confidence\":4.7,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx38iC5KX\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.7,\"avg_confidence\":3.3,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklnzhR9YQ\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx7l309Fm\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzjBiR9t7\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1MB-3RcF7\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.3,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkgnpiR9Y7\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.2,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1e7hs05Km\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.3,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyePrhR5KX\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylPMnR9Ym\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyehMhC9Y7\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygm8jC9FQ\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJedV3R5tm\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke96sC5tm\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryf6Fs09YX\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.3,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke4HiAcY7\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl6As0cF7\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkNksoRctQ\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkemqsC9Fm\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rk4Qso0cKm\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJeQbnA5tm\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xEtoRqtQ\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgK6iA5KX\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygHGnRqK7\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.3,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryMQ5sRqYX\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedwoC5t7\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1My6sR9tX\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1erHoR5t7\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyNvti09KQ\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkGiPoC5FX\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syfz6sC9tQ\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByMVTsR5KQ\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlaYi05tm\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlgNh0qKQ\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "95f51836-f9f0-4d8f-ad6f-ed5371d4cbb1",
       "layout": "IPY_MODEL_cf682439116a4aa79a61c0180bade574",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "a56e921bf4884058a4c661b34681e38c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ad06941647e94bd2a3b8e458d86caa4d": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 100
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxfEn09Y7\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"adversarial example\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4dFjR5K7\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"generative models\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke4KsA5FX\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"generative adversarial network\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgYl205tQ\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.3,\"avg_confidence\":3.0,\"topic\":\"model interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1E3Ko09F7\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJg8yhAqKm\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJGtFoC5Fm\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.8,\"topic\":\"adversarial example\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgVRiC9Km\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.7,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTciR9tm\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"artificial intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl42iA5t7\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.3,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylKB3A9Fm\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlxm30cKm\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"neural machine translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eEdj0cK7\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygqqsA9KX\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.2,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygn2o0qKX\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1GLm2R9Km\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke-JhA9Y7\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"inverse reinforcement learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJlmHoR5tQ\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygfghAcYX\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"network compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xLN3C9YX\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"pu learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJzLciCqKm\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1MAJhR5YX\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xsSjC9Ym\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"maximum mean discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkG5SjR5YQ\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"neural networks\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eJssCqY7\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"embedding\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJxeWnCcF7\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.7,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1grRoR9tQ\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgnmhA5KQ\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxnvsAqFm\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.3,\"avg_confidence\":4.3,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxcHnRqYQ\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"adversarial example\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJl2niR9KQ\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxt8oC9FQ\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"life-long learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hkf2_sC5FX\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.7,\"topic\":\"model free rl\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HygsfnR9Ym\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl0r3R9KX\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlk6iRqKX\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklSf3CqKm\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"cnn\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMHpjC9Ym\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJf_YjCqYX\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlEojAqFm\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bye9LiR9YX\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgToo0qFm\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygxb2CqKm\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl2E3AcF7\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4fpoA5Km\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.3,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxBFsRqYm\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyVU6s05K7\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"nlp\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xtAjR5tX\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.7,\"avg_confidence\":4.7,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJf7ts0cFm\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.7,\"avg_confidence\":3.3,\"topic\":\"non convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SklcFsAcKX\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByGuynAct7\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"generative models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representation\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJfRpoA9YX\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syxt2jC5FX\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"neural processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkE6PjC9KX\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyM7AiA5YX\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.7,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1ebTsActm\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"gan\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJeXSo09FQ\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.3,\"avg_confidence\":4.7,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx38iC5KX\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.7,\"avg_confidence\":3.3,\"topic\":\"cnn\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklnzhR9YQ\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"multi agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx7l309Fm\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzjBiR9t7\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"generative adversarial network\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1MB-3RcF7\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.3,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkgnpiR9Y7\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.2,\"topic\":\"deep rl\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1e7hs05Km\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.3,\"topic\":\"dynamic graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyePrhR5KX\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylPMnR9Ym\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyehMhC9Y7\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygm8jC9FQ\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"relgan\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJedV3R5tm\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"model based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke96sC5tm\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryf6Fs09YX\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.3,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke4HiAcY7\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl6As0cF7\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkNksoRctQ\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkemqsC9Fm\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rk4Qso0cKm\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJeQbnA5tm\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xEtoRqtQ\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial example\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"meta learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgK6iA5KX\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bayesian nonparametric\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygHGnRqK7\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.3,\"topic\":\"gans\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryMQ5sRqYX\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedwoC5t7\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1My6sR9tX\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"ai\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1erHoR5t7\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyNvti09KQ\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"direct feedback alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkGiPoC5FX\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"generative deep neural networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syfz6sC9tQ\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByMVTsR5KQ\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional network\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlaYi05tm\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlgNh0qKQ\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        16
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 100,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": false,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "e2812797-f9d5-4ec1-add7-b205b6d53c73",
       "layout": "IPY_MODEL_bcdb19cc0a2641b08141705bba767ea2",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "ad1dc4c7b35647c980764bcc15e71e9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ae7ebb328f534dbaa5af21a07f5f8997": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b25655ffb70841b5ac0050f21467f8c8": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "autoHeight": true,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 100,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "9e8a828c-3b3a-4c19-9454-036843125b8f",
       "layout": "IPY_MODEL_4b51be3e3cdf4b1181ba6d971d61813b",
       "precision": 5,
       "show_toolbar": true
      }
     },
     "b39870dc9c9848488d95a8b39d66ee04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b42900306e4748b793838a11ee750983": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 100
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxfEn09Y7\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"adversarial example\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4dFjR5K7\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"generative models\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke4KsA5FX\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"generative adversarial network\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgYl205tQ\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.3,\"avg_confidence\":3.0,\"topic\":\"model interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1E3Ko09F7\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJg8yhAqKm\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJGtFoC5Fm\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.8,\"topic\":\"adversarial example\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgVRiC9Km\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.7,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTciR9tm\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"artificial intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl42iA5t7\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.3,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylKB3A9Fm\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlxm30cKm\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"neural machine translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eEdj0cK7\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygqqsA9KX\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.2,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygn2o0qKX\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1GLm2R9Km\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke-JhA9Y7\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"inverse reinforcement learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJlmHoR5tQ\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygfghAcYX\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"network compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xLN3C9YX\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"pu learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJzLciCqKm\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1MAJhR5YX\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xsSjC9Ym\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"maximum mean discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkG5SjR5YQ\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"neural networks\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eJssCqY7\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"embedding\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJxeWnCcF7\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.7,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1grRoR9tQ\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgnmhA5KQ\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxnvsAqFm\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.3,\"avg_confidence\":4.3,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxcHnRqYQ\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"adversarial example\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJl2niR9KQ\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxt8oC9FQ\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"life-long learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hkf2_sC5FX\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.7,\"topic\":\"model free rl\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HygsfnR9Ym\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl0r3R9KX\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlk6iRqKX\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklSf3CqKm\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"cnn\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMHpjC9Ym\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJf_YjCqYX\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlEojAqFm\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bye9LiR9YX\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgToo0qFm\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygxb2CqKm\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl2E3AcF7\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4fpoA5Km\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.3,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxBFsRqYm\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyVU6s05K7\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"nlp\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xtAjR5tX\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.7,\"avg_confidence\":4.7,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJf7ts0cFm\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.7,\"avg_confidence\":3.3,\"topic\":\"non convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SklcFsAcKX\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByGuynAct7\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"generative models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representation\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJfRpoA9YX\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syxt2jC5FX\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"neural processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkE6PjC9KX\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyM7AiA5YX\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.7,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1ebTsActm\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"gan\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJeXSo09FQ\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.3,\"avg_confidence\":4.7,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx38iC5KX\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.7,\"avg_confidence\":3.3,\"topic\":\"cnn\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklnzhR9YQ\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"multi agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx7l309Fm\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzjBiR9t7\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"generative adversarial network\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1MB-3RcF7\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.3,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkgnpiR9Y7\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.2,\"topic\":\"deep rl\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1e7hs05Km\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.3,\"topic\":\"dynamic graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyePrhR5KX\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylPMnR9Ym\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyehMhC9Y7\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygm8jC9FQ\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"relgan\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJedV3R5tm\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"model based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke96sC5tm\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryf6Fs09YX\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.3,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke4HiAcY7\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl6As0cF7\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkNksoRctQ\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkemqsC9Fm\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rk4Qso0cKm\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJeQbnA5tm\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xEtoRqtQ\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial example\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"meta learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgK6iA5KX\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bayesian nonparametric\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygHGnRqK7\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.3,\"topic\":\"gans\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryMQ5sRqYX\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedwoC5t7\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1My6sR9tX\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"ai\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1erHoR5t7\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyNvti09KQ\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"direct feedback alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkGiPoC5FX\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"generative deep neural networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syfz6sC9tQ\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByMVTsR5KQ\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional network\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlaYi05tm\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlgNh0qKQ\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        16
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 100,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": false,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "e7906266-9dff-44a3-8f2b-b2fee60abbe2",
       "layout": "IPY_MODEL_40287962a59a496989be4cf28518825d",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "b4523f21ed9d410da11dbc0511fd04df": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 100
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"},{\"name\":\"topic_qgrid_sort_column\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":1017,\"qgrid_unfiltered_index\":1017,\"title\":\"Exploration by random distillation\",\"avg_rating\":8.7,\"avg_confidence\":4.3,\"topic\":\"reinforcement learning\",\"tldr\":\"A simple exploration bonus is introduced and achieves state of the art performance in 3 hard exploration Atari games.\",\"ratings\":\"[9, 10, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lJJnR5Ym\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":648,\"qgrid_unfiltered_index\":648,\"title\":\"Benchmarking Neural Network Robustness to Common Corruptions and Perturbations\",\"avg_rating\":8.3,\"avg_confidence\":4.0,\"topic\":\"robustness\",\"tldr\":\"We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness\",\"ratings\":\"[7, 9, 9]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJz6tiCqYm\",\"topic_qgrid_sort_column\":\"robustness\"},{\"Index\":707,\"qgrid_unfiltered_index\":707,\"title\":\"Large Scale GAN Training for High Fidelity Natural Image Synthesis\",\"avg_rating\":8.3,\"avg_confidence\":3.7,\"topic\":\"GANs\",\"tldr\":\"GANs benefit from scaling up.\",\"ratings\":\"[7, 8, 10]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1xsqj09Fm\",\"topic_qgrid_sort_column\":\"GANs\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":950,\"qgrid_unfiltered_index\":950,\"title\":\"Slimmable Neural Networks\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"Slimmable neural networks\",\"tldr\":\"We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1gMCsAqY7\",\"topic_qgrid_sort_column\":\"Slimmable neural networks\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\",\"topic_qgrid_sort_column\":\"music\"},{\"Index\":1304,\"qgrid_unfiltered_index\":1304,\"title\":\"ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"sparse recovery\",\"tldr\":\"\",\"ratings\":\"[10, 6, 8]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1lnzn0ctQ\",\"topic_qgrid_sort_column\":\"sparse recovery\"},{\"Index\":1442,\"qgrid_unfiltered_index\":1442,\"title\":\"Posterior Attention Models for Sequence to Sequence Learning\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"posterior inference\",\"tldr\":\"Computing attention based on posterior distribution leads to more meaningful attention and better performance\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkltNhC9FX\",\"topic_qgrid_sort_column\":\"posterior inference\"},{\"Index\":878,\"qgrid_unfiltered_index\":878,\"title\":\"GENERATING HIGH FIDELITY IMAGES WITH SUBSCALE PIXEL NETWORKS AND MULTIDIMENSIONAL UPSCALING\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"We show that autoregressive models can generate high fidelity images. \",\"ratings\":\"[10, 7, 7]\",\"confidence\":\"[5, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HylzTiC5Km\",\"topic_qgrid_sort_column\":\"None\"},{\"Index\":717,\"qgrid_unfiltered_index\":717,\"title\":\"Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"Deep Learning\",\"tldr\":\"We introduce a new inductive bias that integrates tree structures in recurrent neural networks.\",\"ratings\":\"[9, 7, 8]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1l6qiR5F7\",\"topic_qgrid_sort_column\":\"Deep Learning\"},{\"Index\":1115,\"qgrid_unfiltered_index\":1115,\"title\":\"Temporal Difference Variational Auto-Encoder\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"generative models\",\"tldr\":\"Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1x4ghC9tQ\",\"topic_qgrid_sort_column\":\"generative models\"},{\"Index\":1239,\"qgrid_unfiltered_index\":1239,\"title\":\"Supervised Community Detection with Line Graph Neural Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"community detection\",\"tldr\":\"We propose a novel graph neural network architecture based on the non-backtracking operator defined over edge adjacencies and demonstrate its effectiveness on community detection tasks on graphs.\",\"ratings\":\"[6, 9, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1g0Z3A9Fm\",\"topic_qgrid_sort_column\":\"community detection\"},{\"Index\":762,\"qgrid_unfiltered_index\":762,\"title\":\"Learning Unsupervised Learning Rules\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"Meta-learning\",\"tldr\":\"We learn an unsupervised learning algorithm that produces useful representations from a set of supervised tasks. At test-time, we apply this algorithm to new tasks without any supervision and show performance comparable to a VAE.\",\"ratings\":\"[8, 7, 8]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkNDsiC9KQ\",\"topic_qgrid_sort_column\":\"Meta-learning\"},{\"Index\":1330,\"qgrid_unfiltered_index\":1330,\"title\":\"Adaptive Input Representations for Neural Language Modeling\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Neural language modeling\",\"tldr\":\"Variable capacity input word embeddings and SOTA on WikiText-103, Billion Word benchmarks.\",\"ratings\":\"[7, 8, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxZX20qFQ\",\"topic_qgrid_sort_column\":\"Neural language modeling\"},{\"Index\":614,\"qgrid_unfiltered_index\":614,\"title\":\"Critical Learning Periods in Deep Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.3,\"topic\":\"Critical Period\",\"tldr\":\"Sensory deficits in early training phases can lead to irreversible performance loss in both artificial and neuronal networks, suggesting information phenomena as the common cause, and point to the importance of the initial transient and forgetting.\",\"ratings\":\"[9, 8, 6]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkeStsCcKQ\",\"topic_qgrid_sort_column\":\"Critical Period\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\",\"topic_qgrid_sort_column\":\"asynchronous\"},{\"Index\":636,\"qgrid_unfiltered_index\":636,\"title\":\"Sparse Dictionary Learning by Dynamical Neural Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[6, 9, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1gstsCqt7\",\"topic_qgrid_sort_column\":\"None\"},{\"Index\":1154,\"qgrid_unfiltered_index\":1154,\"title\":\"Pay Less Attention with Lightweight and Dynamic Convolutions\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Deep learning\",\"tldr\":\"Dynamic lightweight convolutions are competitive to self-attention on language tasks.\",\"ratings\":\"[8, 7, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkVhlh09tX\",\"topic_qgrid_sort_column\":\"Deep learning\"},{\"Index\":450,\"qgrid_unfiltered_index\":450,\"title\":\"Identifying and Controlling Important Neurons in Neural Machine Translation\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"neural machine translation\",\"tldr\":\"Unsupervised methods for finding, analyzing, and controlling important neurons in NMT\",\"ratings\":\"[7, 10, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1z-PsR5KX\",\"topic_qgrid_sort_column\":\"neural machine translation\"},{\"Index\":778,\"qgrid_unfiltered_index\":778,\"title\":\"Learning Robust Representations by Projecting Superficial Statistics Out\",\"avg_rating\":7.7,\"avg_confidence\":3.7,\"topic\":\"domain generalization\",\"tldr\":\"Building on previous work on domain generalization, we hope to produce a classifier that will generalize to previously unseen domains, even when domain identifiers are not available during training.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJEjjoR9K7\",\"topic_qgrid_sort_column\":\"domain generalization\"},{\"Index\":661,\"qgrid_unfiltered_index\":661,\"title\":\"KnockoffGAN: Generating Knockoffs for Feature Selection using Generative Adversarial Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Knockoff model\",\"tldr\":\"\",\"ratings\":\"[6, 10, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByeZ5jC5YQ\",\"topic_qgrid_sort_column\":\"Knockoff model\"},{\"Index\":1454,\"qgrid_unfiltered_index\":1454,\"title\":\"A Variational Inequality Perspective on Generative Adversarial Networks\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"optimization\",\"tldr\":\"We cast GANs in the variational inequality framework and import techniques from this literature to optimize GANs better; we give algorithmic extensions and empirically test their performance for training GANs.\",\"ratings\":\"[8, 8, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1laEnA5Ym\",\"topic_qgrid_sort_column\":\"optimization\"},{\"Index\":353,\"qgrid_unfiltered_index\":353,\"title\":\"Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware\",\"avg_rating\":7.7,\"avg_confidence\":3.0,\"topic\":\"Trusted hardware\",\"tldr\":\"We accelerate secure DNN inference in trusted execution environments (by a factor 4x-20x) by selectively outsourcing the computation of linear layers to a faster yet untrusted co-processor.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJVorjCcKQ\",\"topic_qgrid_sort_column\":\"Trusted hardware\"},{\"Index\":1495,\"qgrid_unfiltered_index\":1495,\"title\":\"Composing Complex Skills by Learning Transition Policies with Proximity Reward Induction\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"reinforcement learning\",\"tldr\":\"Transition policies enable agents to execute learned skills smoothly to perform complex tasks.\",\"ratings\":\"[7, 9, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygrBhC5tQ\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":276,\"qgrid_unfiltered_index\":276,\"title\":\"ON RANDOM DEEP AUTOENCODERS: EXACT ASYMPTOTIC ANALYSIS, PHASE TRANSITIONS, AND IMPLICATIONS TO TRAINING\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Random Deep Autoencoders\",\"tldr\":\"We study the behavior of weight-tied multilayer vanilla autoencoders under the assumption of random weights. Via an exact characterization in the limit of large dimensions, our analysis reveals interesting phase transition phenomena.\",\"ratings\":\"[9, 6, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx54i05tX\",\"topic_qgrid_sort_column\":\"Random Deep Autoencoders\"},{\"Index\":255,\"qgrid_unfiltered_index\":255,\"title\":\"Smoothing the Geometry of Probabilistic Box Embeddings\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"embeddings\",\"tldr\":\"Improve hierarchical embedding models using kernel smoothing\",\"ratings\":\"[8, 8, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xSNiRcF7\",\"topic_qgrid_sort_column\":\"embeddings\"},{\"Index\":348,\"qgrid_unfiltered_index\":348,\"title\":\"Diffusion Scattering Transforms on Graphs\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"graph neural networks\",\"tldr\":\"Stability of scattering transform representations of graph data to deformations of the underlying graph support.\",\"ratings\":\"[9, 6]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygqBiRcFQ\",\"topic_qgrid_sort_column\":\"graph neural networks\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\",\"topic_qgrid_sort_column\":\"memory-augmented neural networks\"},{\"Index\":662,\"qgrid_unfiltered_index\":662,\"title\":\"On the Minimal Supervision for Training Any Binary Classifier from Only Unlabeled Data\",\"avg_rating\":7.5,\"avg_confidence\":3.5,\"topic\":\"learning from only unlabeled data\",\"tldr\":\"Three class priors are all you need to train deep models from only U data, while any two should not be enough.\",\"ratings\":\"[8, 7]\",\"confidence\":\"[3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1xWcj0qYm\",\"topic_qgrid_sort_column\":\"learning from only unlabeled data\"},{\"Index\":861,\"qgrid_unfiltered_index\":861,\"title\":\"Diversity is All You Need: Learning Skills without a Reward Function\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"reinforcement learning\",\"tldr\":\"We propose an algorithm for learning useful skills without a reward function, and show how these skills can be used to solve downstream tasks.\",\"ratings\":\"[8, 7, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJx63jRqFm\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":1094,\"qgrid_unfiltered_index\":1094,\"title\":\"Gradient descent aligns the layers of deep linear networks\",\"avg_rating\":7.3,\"avg_confidence\":4.3,\"topic\":\"implicit regularization\",\"tldr\":\"\",\"ratings\":\"[7, 9, 6]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJflg30qKX\",\"topic_qgrid_sort_column\":\"implicit regularization\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\",\"topic_qgrid_sort_column\":\"autoencoders\"},{\"Index\":997,\"qgrid_unfiltered_index\":997,\"title\":\"Efficient Training on Very Large Corpora via Gramian Estimation\",\"avg_rating\":7.3,\"avg_confidence\":2.7,\"topic\":\"similarity learning\",\"tldr\":\"We develop efficient methods to train neural embedding models with a dot-product structure, by reformulating the objective function in terms of generalized Gram matrices, and maintaining estimates of those matrices.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[4, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke20iA9Y7\",\"topic_qgrid_sort_column\":\"similarity learning\"},{\"Index\":957,\"qgrid_unfiltered_index\":957,\"title\":\"ProMP: Proximal Meta-Policy Search\",\"avg_rating\":7.3,\"avg_confidence\":3.0,\"topic\":\"Meta-Reinforcement Learning\",\"tldr\":\"A novel and theoretically grounded meta-reinforcement learning algorithm\",\"ratings\":\"[6, 7, 9]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxXCi0qFX\",\"topic_qgrid_sort_column\":\"Meta-Reinforcement Learning\"},{\"Index\":663,\"qgrid_unfiltered_index\":663,\"title\":\"Approximability of Discriminators Implies Diversity in GANs\",\"avg_rating\":7.3,\"avg_confidence\":2.7,\"topic\":\"Theory\",\"tldr\":\"GANs can in principle learn distributions sample-efficiently, if the discriminator class is compact and has strong distinguishing power against the particular generator class.\",\"ratings\":\"[8, 7, 7]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJfW5oA5KQ\",\"topic_qgrid_sort_column\":\"Theory\"},{\"Index\":1204,\"qgrid_unfiltered_index\":1204,\"title\":\"Biologically-Plausible Learning Algorithms Can Scale to Large Datasets\",\"avg_rating\":7.3,\"avg_confidence\":4.3,\"topic\":\"biologically plausible learning algorithm\",\"tldr\":\"Biologically plausible learning algorithms, particularly sign-symmetry, works well on ImageNet\",\"ratings\":\"[9, 9, 4]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygvZ209F7\",\"topic_qgrid_sort_column\":\"biologically plausible learning algorithm\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\",\"topic_qgrid_sort_column\":\"visual prediction\"},{\"Index\":478,\"qgrid_unfiltered_index\":478,\"title\":\"Large-Scale Study of Curiosity-Driven Learning\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"exploration\",\"tldr\":\"An agent trained only with curiosity, and no extrinsic reward, does surprisingly well on 54 popular environments, including the suite of Atari games, Mario etc.\",\"ratings\":\"[6, 9, 7]\",\"confidence\":\"[4, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJNwDjAqYX\",\"topic_qgrid_sort_column\":\"exploration\"},{\"Index\":1540,\"qgrid_unfiltered_index\":1540,\"title\":\"Visualizing and Understanding Generative Adversarial Networks\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"GANs\",\"tldr\":\"GAN representations are examined in detail, and sets of representation units are found that control the generation of semantic concepts in the output.\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hyg_X2C5FX\",\"topic_qgrid_sort_column\":\"GANs\"},{\"Index\":124,\"qgrid_unfiltered_index\":124,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylV-2C9KQ\",\"topic_qgrid_sort_column\":\"natural image model\"},{\"Index\":548,\"qgrid_unfiltered_index\":548,\"title\":\"Evaluating Robustness of Neural Networks with Mixed Integer Programming\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"verification\",\"tldr\":\"We efficiently verify the robustness of deep neural models with over 100,000 ReLUs, certifying more samples than the state-of-the-art and finding more adversarial examples than a strong first-order attack.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[5, 5, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyGIdiRqtm\",\"topic_qgrid_sort_column\":\"verification\"},{\"Index\":1509,\"qgrid_unfiltered_index\":1509,\"title\":\"Label super-resolution networks\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"weakly supervised segmentation\",\"tldr\":\"Super-resolving coarse labels into pixel-level labels, applied to aerial imagery and medical scans.\",\"ratings\":\"[7, 6, 9]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxwShA9Ym\",\"topic_qgrid_sort_column\":\"weakly supervised segmentation\"},{\"Index\":625,\"qgrid_unfiltered_index\":625,\"title\":\"Small nonlinearities in activation functions create bad local minima in neural networks\",\"avg_rating\":7.3,\"avg_confidence\":3.3,\"topic\":\"spurious local minima\",\"tldr\":\"We constructively prove that even the slightest nonlinear activation functions introduce spurious local minima, for general datasets and activation functions.\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke_YiRct7\",\"topic_qgrid_sort_column\":\"spurious local minima\"},{\"Index\":1286,\"qgrid_unfiltered_index\":1286,\"title\":\"LanczosNet: Multi-Scale Deep Graph Convolutional Networks\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedznAqKQ\",\"topic_qgrid_sort_column\":\"None\"},{\"Index\":1253,\"qgrid_unfiltered_index\":1253,\"title\":\"Kernel Change-point Detection with Auxiliary Deep Generative Models\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"deep kernel learning\",\"tldr\":\"In this paper, we propose KL-CPD, a novel kernel learning framework for time series CPD that optimizes a lower bound of test power via an auxiliary generative model as a surrogate to the abnormal distribution. \",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1GbfhRqF7\",\"topic_qgrid_sort_column\":\"deep kernel learning\"},{\"Index\":1252,\"qgrid_unfiltered_index\":1252,\"title\":\"Towards Metamerism via Foveated Style Transfer\",\"avg_rating\":7.3,\"avg_confidence\":4.3,\"topic\":\"Metamerism\",\"tldr\":\"We introduce a novel feed-forward framework to generate visual metamers\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJzbG20cFQ\",\"topic_qgrid_sort_column\":\"Metamerism\"},{\"Index\":372,\"qgrid_unfiltered_index\":372,\"title\":\"Differentiable Learning-to-Normalize via Switchable Normalization\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"normalization\",\"tldr\":\"\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryggIs0cYQ\",\"topic_qgrid_sort_column\":\"normalization\"},{\"Index\":197,\"qgrid_unfiltered_index\":197,\"title\":\"Learning a SAT Solver from Single-Bit Supervision\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"sat\",\"tldr\":\"We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMC_iA5tm\",\"topic_qgrid_sort_column\":\"sat\"},{\"Index\":242,\"qgrid_unfiltered_index\":242,\"title\":\"Auxiliary Variational MCMC\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"MCMC\",\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1NJqsRctX\",\"topic_qgrid_sort_column\":\"MCMC\"},{\"Index\":929,\"qgrid_unfiltered_index\":929,\"title\":\"The Comparative Power of ReLU Networks and Polynomial Kernels in the Presence of Sparse Latent Structure\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"theory\",\"tldr\":\"Beyond-worst-case analysis of the representational power of  ReLU nets & polynomial kernels  -- in particular in the presence of sparse latent structure.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTTjA9tX\",\"topic_qgrid_sort_column\":\"theory\"},{\"Index\":794,\"qgrid_unfiltered_index\":794,\"title\":\"Neural network gradient-based learning of black-box function interfaces\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"neural networks\",\"tldr\":\"Training DNNs to interface w\\\\ black box functions w\\\\o intermediate labels by using an estimator sub-network that can be replaced with the black box after training\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1e13s05YX\",\"topic_qgrid_sort_column\":\"neural networks\"},{\"Index\":143,\"qgrid_unfiltered_index\":143,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJe9rh0cFX\",\"topic_qgrid_sort_column\":\"Quantized Neural Networks\"},{\"Index\":304,\"qgrid_unfiltered_index\":304,\"title\":\"Deep, Skinny Neural Networks are not Universal Approximators\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"neural network\",\"tldr\":\"This paper proves that skinny neural networks cannot approximate certain functions, no matter how deep they are.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryGgSsAcFQ\",\"topic_qgrid_sort_column\":\"neural network\"},{\"Index\":345,\"qgrid_unfiltered_index\":345,\"title\":\"DARTS: Differentiable Architecture Search\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"deep learning\",\"tldr\":\"We propose a differentiable architecture search algorithm for both convolutional and recurrent networks, achieving competitive performance with the state of the art using orders of magnitude less computation resources.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eYHoC5FX\",\"topic_qgrid_sort_column\":\"deep learning\"},{\"Index\":361,\"qgrid_unfiltered_index\":361,\"title\":\"ADVERSARIAL DOMAIN ADAPTATION FOR STABLE BRAIN-MACHINE INTERFACES\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"Brain-Machine Interfaces\",\"tldr\":\"We implement an adversarial domain adaptation network to stabilize a fixed Brain-Machine Interface against gradual changes in the recorded neural signals.\",\"ratings\":\"[9, 5, 7]\",\"confidence\":\"[4, 3, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hyx6Bi0qYm\",\"topic_qgrid_sort_column\":\"Brain-Machine Interfaces\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\",\"topic_qgrid_sort_column\":\"adversarial examples\"},{\"Index\":846,\"qgrid_unfiltered_index\":846,\"title\":\"The effects of neural resource constraints on early visual representations \",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"visual system\",\"tldr\":\"We reproduced neural representations found in biological visual systems by simulating their neural resource constraints in a deep convolutional model.\",\"ratings\":\"[5, 8, 8]\",\"confidence\":\"[5, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xq3oR5tQ\",\"topic_qgrid_sort_column\":\"visual system\"},{\"Index\":814,\"qgrid_unfiltered_index\":814,\"title\":\"Wizard of Wikipedia: Knowledge-Powered Conversational Agents\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"dialogue\",\"tldr\":\"We build knowledgeable conversational agents by conditioning on Wikipedia + a new supervised task.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1l73iRqKm\",\"topic_qgrid_sort_column\":\"dialogue\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\",\"topic_qgrid_sort_column\":\"Deep Learning\"},{\"Index\":383,\"qgrid_unfiltered_index\":383,\"title\":\"An analytic theory of generalization dynamics and transfer learning in deep linear networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Generalization\",\"tldr\":\"We provide many insights into neural network generalization from the theoretically tractable linear case.\",\"ratings\":\"[8, 7, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryfMLoCqtQ\",\"topic_qgrid_sort_column\":\"Generalization\"},{\"Index\":768,\"qgrid_unfiltered_index\":768,\"title\":\"How Important is a Neuron\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"attribution\",\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylKoo0cKm\",\"topic_qgrid_sort_column\":\"attribution\"},{\"Index\":110,\"qgrid_unfiltered_index\":110,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.7,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syx72jC9tm\",\"topic_qgrid_sort_column\":\"graph learning\"},{\"Index\":748,\"qgrid_unfiltered_index\":748,\"title\":\"Deep Learning 3D Shapes Using Alt-az Anisotropic 2-Sphere Convolution\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"Spherical Convolution\",\"tldr\":\"A method for applying deep learning to 3D surfaces using their spherical descriptors and alt-az anisotropic convolution on 2-sphere.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[3, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkeSiiA5Fm\",\"topic_qgrid_sort_column\":\"Spherical Convolution\"},{\"Index\":527,\"qgrid_unfiltered_index\":527,\"title\":\"Near-Optimal Representation Learning for Hierarchical Reinforcement Learning\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"representation hierarchy reinforcement learning\",\"tldr\":\"We translate a bound on sub-optimality of representations to a practical training objective in the context of hierarchical reinforcement learning.\",\"ratings\":\"[6, 6, 9]\",\"confidence\":\"[3, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1emus0qF7\",\"topic_qgrid_sort_column\":\"representation hierarchy reinforcement learning\"},{\"Index\":100,\"qgrid_unfiltered_index\":100,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylCrnCcFX\",\"topic_qgrid_sort_column\":\"None\"},{\"Index\":102,\"qgrid_unfiltered_index\":102,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkxjYoCqKX\",\"topic_qgrid_sort_column\":\"Quantization\"},{\"Index\":706,\"qgrid_unfiltered_index\":706,\"title\":\"Riemannian Adaptive Optimization Methods\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"Riemannian optimization\",\"tldr\":\"Adapting Adam, Amsgrad, Adagrad to Riemannian manifolds. \",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eiqi09K7\",\"topic_qgrid_sort_column\":\"Riemannian optimization\"},{\"Index\":666,\"qgrid_unfiltered_index\":666,\"title\":\"Deep Graph Infomax\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Unsupervised Learning\",\"tldr\":\"A new method for unsupervised representation learning on graphs, relying on maximizing mutual information between local and global representations in a graph. State-of-the-art results, competitive with supervised learning.\",\"ratings\":\"[7, 9, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rklz9iAcKQ\",\"topic_qgrid_sort_column\":\"Unsupervised Learning\"},{\"Index\":665,\"qgrid_unfiltered_index\":665,\"title\":\"SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"neural network pruning\",\"tldr\":\"We present a new approach, SNIP, that is simple, versatile and interpretable; it prunes irrelevant connections for a given task at single-shot prior to training and is applicable to a variety of neural network models without modifications.\",\"ratings\":\"[6, 6, 9]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1VZqjAcYX\",\"topic_qgrid_sort_column\":\"neural network pruning\"},{\"Index\":642,\"qgrid_unfiltered_index\":642,\"title\":\"Greedy Attack and Gumbel Attack: Generating Adversarial Examples for Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"Adversarial Examples\",\"tldr\":\"We develop two methods for generating adversarial examples on discrete data under a probabilistic framework.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[4, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByghKiC5YX\",\"topic_qgrid_sort_column\":\"Adversarial Examples\"},{\"Index\":113,\"qgrid_unfiltered_index\":113,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkxStoC5F7\",\"topic_qgrid_sort_column\":\"probabilistic models\"},{\"Index\":1559,\"qgrid_unfiltered_index\":1559,\"title\":\"Learning sparse relational transition models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deictic reference\",\"tldr\":\"A new approach that learns a representation for describing transition models in complex uncertaindomains using relational rules. \",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJxsV2R5FQ\",\"topic_qgrid_sort_column\":\"Deictic reference\"},{\"Index\":921,\"qgrid_unfiltered_index\":921,\"title\":\"How Powerful are Graph Neural Networks?\",\"avg_rating\":7.0,\"avg_confidence\":5.0,\"topic\":\"graph neural networks\",\"tldr\":\"We develop theoretical foundations for expressive power of GNNs and design a provably most powerful GNN.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryGs6iA5Km\",\"topic_qgrid_sort_column\":\"graph neural networks\"},{\"Index\":1280,\"qgrid_unfiltered_index\":1280,\"title\":\"Lagging Inference Networks and Posterior Collapse in Variational Autoencoders\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"variational autoencoders\",\"tldr\":\"To address posterior collapse in VAEs, we propose a simple yet effective training algorithm that aggressively optimizes inference network with more updates\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylDfnCqF7\",\"topic_qgrid_sort_column\":\"variational autoencoders\"},{\"Index\":1025,\"qgrid_unfiltered_index\":1025,\"title\":\"Feature Intertwiners\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"feature learning\",\"tldr\":\"A feature intertwiner module to leverage features from one accurate set to help the learning of another less reliable set.\",\"ratings\":\"[7, 5, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxZJn05YX\",\"topic_qgrid_sort_column\":\"feature learning\"},{\"Index\":1108,\"qgrid_unfiltered_index\":1108,\"title\":\"Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word Vectors\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"word vectors\",\"tldr\":\"Max-pooled word vectors with fuzzy Jaccard set similarity are an extremely competitive baseline for semantic similarity; we propose a simple dynamic variant that performs even better.\",\"ratings\":\"[8, 8, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxXg2C5FX\",\"topic_qgrid_sort_column\":\"word vectors\"},{\"Index\":1103,\"qgrid_unfiltered_index\":1103,\"title\":\"The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"Neuro-Symbolic Representations\",\"tldr\":\"We present a Neuro-Symbolic Concept Learner to learn visual concepts, words, and semantic parsing of sentences without explicit annotations for any of them. \",\"ratings\":\"[7, 5, 9]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgMlhRctm\",\"topic_qgrid_sort_column\":\"Neuro-Symbolic Representations\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\",\"topic_qgrid_sort_column\":\"Generative Models\"},{\"Index\":1180,\"qgrid_unfiltered_index\":1180,\"title\":\"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"Neural networks\",\"tldr\":\"Feedforward neural networks that can have weights pruned after training could have had the same weights pruned before training\",\"ratings\":\"[5, 8, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl-b3RcF7\",\"topic_qgrid_sort_column\":\"Neural networks\"},{\"Index\":1077,\"qgrid_unfiltered_index\":1077,\"title\":\"Local SGD Converges Fast and Communicates Little\",\"avg_rating\":7.0,\"avg_confidence\":4.7,\"topic\":\"optimization\",\"tldr\":\"We prove that parallel local SGD achieves linear speedup with much lesser communication than parallel mini-batch SGD.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1g2JnRcFX\",\"topic_qgrid_sort_column\":\"optimization\"},{\"Index\":1484,\"qgrid_unfiltered_index\":1484,\"title\":\"Learning to Screen for Fast Softmax  Inference on Large Vocabulary Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"fast inference\",\"tldr\":\"\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByeMB3Act7\",\"topic_qgrid_sort_column\":\"fast inference\"},{\"Index\":1063,\"qgrid_unfiltered_index\":1063,\"title\":\"ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"text-to-speech\",\"tldr\":\"\",\"ratings\":\"[9, 5, 7]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklY120cYm\",\"topic_qgrid_sort_column\":\"text-to-speech\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\",\"topic_qgrid_sort_column\":\"None\"},{\"Index\":1232,\"qgrid_unfiltered_index\":1232,\"title\":\"Learning Neural PDE Solvers with Convergence Guarantees\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Partial differential equation\",\"tldr\":\"We learn a fast neural solver for PDEs that has convergence guarantees.\",\"ratings\":\"[7, 8, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rklaWn0qK7\",\"topic_qgrid_sort_column\":\"Partial differential equation\"},{\"Index\":1138,\"qgrid_unfiltered_index\":1138,\"title\":\"Learning Implicitly Recurrent CNNs Through Parameter Sharing\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We propose a method that enables CNN folding to create recurrent connections\",\"ratings\":\"[8, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgYxn09Fm\",\"topic_qgrid_sort_column\":\"deep learning\"},{\"Index\":1268,\"qgrid_unfiltered_index\":1268,\"title\":\"Improving the Differentiable Neural Computer Through Memory Masking, De-allocation, and Link Distribution Sharpness Control\",\"avg_rating\":7.0,\"avg_confidence\":5.0,\"topic\":\"rnn\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyGEM3C9KQ\",\"topic_qgrid_sort_column\":\"rnn\"},{\"Index\":1119,\"qgrid_unfiltered_index\":1119,\"title\":\"What do you learn from context? Probing for sentence structure in contextualized word representations\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"natural language processing\",\"tldr\":\"We probe for sentence structure in ELMo and related contextual embedding models. We find existing models efficiently encode syntax and show evidence of long-range dependencies, but only offer small improvements on semantic tasks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJzSgnRcKX\",\"topic_qgrid_sort_column\":\"natural language processing\"},{\"Index\":1020,\"qgrid_unfiltered_index\":1020,\"title\":\"Scalable Reversible Generative Models with Free-form Continuous Dynamics\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"generative models\",\"tldr\":\"We use continuous time dynamics to define a generative model with exact likelihoods and efficient sampling that is parameterized by unrestricted neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxgknCcK7\",\"topic_qgrid_sort_column\":\"generative models\"},{\"Index\":1530,\"qgrid_unfiltered_index\":1530,\"title\":\"Global-to-local Memory Pointer Networks for Task-Oriented Dialogue\",\"avg_rating\":7.0,\"avg_confidence\":2.3,\"topic\":\"pointer networks\",\"tldr\":\"We propose a global memory encoder and a global memory decoder that share an external knowledge to strengthen task-oriented dialogue generation via sketch responses and pointer networks. \",\"ratings\":\"[8, 8, 5]\",\"confidence\":\"[2, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryxnHhRqFm\",\"topic_qgrid_sort_column\":\"pointer networks\"},{\"Index\":949,\"qgrid_unfiltered_index\":949,\"title\":\"Learning Self-Imitating Diverse Policies\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Reinforcement-learning\",\"tldr\":\"Policy optimization by using past good rollouts from the agent; learning shaped rewards via divergence minimization; SVPG with JS-kernel for population-based exploration.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxzRsR9Y7\",\"topic_qgrid_sort_column\":\"Reinforcement-learning\"},{\"Index\":1414,\"qgrid_unfiltered_index\":1414,\"title\":\"GANSynth: Adversarial Neural Audio Synthesis\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"GAN\",\"tldr\":\"High-quality audio synthesis with GANs\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xQVn09FX\",\"topic_qgrid_sort_column\":\"GAN\"},{\"Index\":1337,\"qgrid_unfiltered_index\":1337,\"title\":\"Learning to Navigate the Web\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"navigating web pages\",\"tldr\":\"We train reinforcement learning policies using reward augmentation, curriculum learning, and meta-learning  to successfully navigate web pages.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJemQ209FQ\",\"topic_qgrid_sort_column\":\"navigating web pages\"},{\"Index\":999,\"qgrid_unfiltered_index\":999,\"title\":\"Unsupervised Domain Adaptation for Distance Metric Learning\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"domain adaptation\",\"tldr\":\"A new theory of unsupervised domain adaptation for distance metric learning and its application to face recognition across diverse ethnicity variations.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BklhAj09K7\",\"topic_qgrid_sort_column\":\"domain adaptation\"},{\"Index\":1313,\"qgrid_unfiltered_index\":1313,\"title\":\"Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based RL\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"meta-learning\",\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxAfnA5tm\",\"topic_qgrid_sort_column\":\"meta-learning\"},{\"Index\":493,\"qgrid_unfiltered_index\":493,\"title\":\"Visual Explanation by Interpretation: Improving Visual Feedback Capabilities of Deep Neural Networks\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"model explanation\",\"tldr\":\"Interpretation by Identifying model-learned features that serve as indicators for the task of interest. Explain model decisions by highlighting the response of these features in test data. Evaluate explanations objectively with a controlled dataset.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1ziPjC5Fm\",\"topic_qgrid_sort_column\":\"model explanation\"},{\"Index\":502,\"qgrid_unfiltered_index\":502,\"title\":\"Woulda, Coulda, Shoulda: Counterfactually-Guided Policy Search\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[6, 7, 7]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJG0voC9YQ\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":422,\"qgrid_unfiltered_index\":422,\"title\":\"Sample Efficient Adaptive Text-to-Speech\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"few shot\",\"tldr\":\"Sample efficient algorithms to adapt a text-to-speech model to a new voice style with the state-of-the-art performance.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkzjUoAcFX\",\"topic_qgrid_sort_column\":\"few shot\"},{\"Index\":410,\"qgrid_unfiltered_index\":410,\"title\":\"Analysis of Quantized Deep Networks\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"weight quantization\",\"tldr\":\"\",\"ratings\":\"[6, 7, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryM_IoAqYX\",\"topic_qgrid_sort_column\":\"weight quantization\"},{\"Index\":1431,\"qgrid_unfiltered_index\":1431,\"title\":\"K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJxvEh0cFQ\",\"topic_qgrid_sort_column\":\"deep learning\"},{\"Index\":509,\"qgrid_unfiltered_index\":509,\"title\":\"EMI: Exploration with Mutual Information Maximizing State and Action Embeddings\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[6, 7, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hylyui09tm\",\"topic_qgrid_sort_column\":\"reinforcement learning\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": false,
       "_sort_field": "avg_rating",
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        16
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "87d47174-23fc-46b1-b0c7-a591d8c66047",
       "layout": "IPY_MODEL_480dcb8d871845d09d8496d4c734e64a",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "b8c32e16d621478f8b730a666307f579": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        16
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "0998303e-086a-4af8-8414-cb6ba3f61c44",
       "layout": "IPY_MODEL_d706b8f5dd0a4f15a492f3df689c0b8d",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "b9196870fd04412d941241e9c9a8cdc1": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.66667,\"avg_confidence\":3.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Adversarial examples\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Generative Model\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.33333,\"avg_confidence\":3.0,\"topic\":\"Model Interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"Information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.75,\"topic\":\"adversarial examples\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.66667,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Artificial Intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.33333,\"avg_confidence\":3.33333,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.66667,\"avg_confidence\":4.33333,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"Neural Machine Translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.33333,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.66667,\"avg_confidence\":2.66667,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.25,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.66667,\"avg_confidence\":2.66667,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Network Compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"PU learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Maximum Mean Discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"neural network\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"embeddings\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.33333,\"avg_confidence\":4.33333,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"adversarial examples\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"Lifelong Learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.66667,\"topic\":\"Model free RL\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"Deep Learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"Adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"Dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.66667,\"avg_confidence\":4.33333,\"topic\":\"CNN\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.66667,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.33333,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"NLP\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.66667,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.66667,\"avg_confidence\":3.33333,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.66667,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.33333,\"avg_confidence\":4.66667,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.33333,\"avg_confidence\":4.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.25,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.33333,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "cb91639a-6c53-4c6d-9d63-f8d9c4949dc1",
       "layout": "IPY_MODEL_2a14582ab6e8497588878876bec8e92b",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "bba10f23ce664e38a5d2bde040e9ae06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bbbaf199bf7d41a0975b1215f010eb13": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 10
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"avg_confidence\":4.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"avg_confidence\":3.33333,\"avg_rating\":5.66667,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"avg_confidence\":3.66667,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"avg_confidence\":2.66667,\"avg_rating\":7.0,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"avg_confidence\":4.0,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"avg_confidence\":2.0,\"avg_rating\":6.66667,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"avg_confidence\":4.66667,\"avg_rating\":5.33333,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"avg_confidence\":3.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"avg_confidence\":4.33333,\"avg_rating\":4.33333,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"avg_confidence\":3.25,\"avg_rating\":4.0,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"avg_confidence\":4.5,\"avg_rating\":6.5,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"avg_confidence\":4.0,\"avg_rating\":7.33333,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"avg_confidence\":4.33333,\"avg_rating\":5.0,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"avg_confidence\":3.66667,\"avg_rating\":4.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"avg_confidence\":4.0,\"avg_rating\":6.5,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"avg_confidence\":3.0,\"avg_rating\":5.0,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"avg_confidence\":3.5,\"avg_rating\":5.5,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"avg_confidence\":4.66667,\"avg_rating\":7.66667,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"avg_confidence\":3.0,\"avg_rating\":3.5,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"avg_confidence\":3.5,\"avg_rating\":6.5,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"avg_confidence\":4.5,\"avg_rating\":6.0,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"avg_confidence\":4.0,\"avg_rating\":4.66667,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"avg_confidence\":3.33333,\"avg_rating\":6.33333,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"avg_confidence\":3.0,\"avg_rating\":6.0,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"avg_confidence\":4.66667,\"avg_rating\":7.0,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"avg_confidence\":3.66667,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"avg_confidence\":4.66667,\"avg_rating\":5.0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"avg_confidence\":4.66667,\"avg_rating\":6.33333,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"avg_confidence\":4.33333,\"avg_rating\":5.33333,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"avg_confidence\":4.0,\"avg_rating\":3.66667,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"avg_confidence\":3.0,\"avg_rating\":6.0,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"avg_confidence\":3.0,\"avg_rating\":5.5,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"avg_confidence\":4.0,\"avg_rating\":4.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"avg_confidence\":3.33333,\"avg_rating\":3.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"avg_confidence\":4.33333,\"avg_rating\":5.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"avg_confidence\":4.0,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"avg_confidence\":4.0,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"avg_confidence\":4.5,\"avg_rating\":5.5,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "454066da-81c6-4754-bb9c-4b7d5983c04d",
       "layout": "IPY_MODEL_0773b82c026945628f00371177cd6731",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "bcdb19cc0a2641b08141705bba767ea2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bd5afa6732014deb8e25b36ebabb24b2": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 100
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 1000
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 200
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 300
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":421,\"qgrid_unfiltered_index\":421,\"title\":\"Object detection deep learning networks for Optical Character Recognition\",\"avg_rating\":2.0,\"avg_confidence\":5.0,\"topic\":\"ocr\",\"tldr\":\"Yolo \\/ RCNN neural network for object detection adapted to the task of OCR\",\"ratings\":\"[1, 2, 1, 4]\",\"confidence\":\"[5, 5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1ej8o05tm\"},{\"Index\":962,\"qgrid_unfiltered_index\":962,\"title\":\"Hierarchical Bayesian Modeling for Clustering Sparse Sequences in the Context of Group Profiling\",\"avg_rating\":2.0,\"avg_confidence\":4.6,\"topic\":\"hierarchical bayesian modeling\",\"tldr\":\"Hierarchical Bayesian Modeling for Clustering Sparse Sequences ; user group modeling using behavioral data\",\"ratings\":\"[2, 2, 1, 3, 2]\",\"confidence\":\"[5, 5, 5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyerAiCqt7\"},{\"Index\":289,\"qgrid_unfiltered_index\":289,\"title\":\"A Synaptic Neural Network and Synapse Learning\",\"avg_rating\":2.2,\"avg_confidence\":3.2,\"topic\":\"synaptic neural network\",\"tldr\":\"A synaptic neural network with synapse graph and learning that has the feature of Bose-Einstein distribution in surprisal space.  \",\"ratings\":\"[2, 3, 2, 2]\",\"confidence\":\"[4, 3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryGpEiAcFQ\"},{\"Index\":542,\"qgrid_unfiltered_index\":542,\"title\":\"Training Variational Auto Encoders with Discrete Latent Representations using Importance Sampling\",\"avg_rating\":2.3,\"avg_confidence\":5.0,\"topic\":\"variational auto encoder\",\"tldr\":\"We propose an easy method to train Variational Auto Encoders (VAE) with discrete latent representations, using importance sampling\",\"ratings\":\"[3, 1, 3]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkNSOjR9Y7\"},{\"Index\":591,\"qgrid_unfiltered_index\":591,\"title\":\"VECTORIZATION METHODS IN RECOMMENDER SYSTEM\",\"avg_rating\":2.3,\"avg_confidence\":4.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[2, 2, 3]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HylJtiRqYQ\"},{\"Index\":1383,\"qgrid_unfiltered_index\":1383,\"title\":\"Hierarchical Deep Reinforcement Learning Agent with Counter Self-play  on Competitive Games \",\"avg_rating\":2.3,\"avg_confidence\":3.3,\"topic\":\"deep reinforcement learning\",\"tldr\":\"We develop Hierarchical Agent with Self-play (HASP), a learning approach for obtaining hierarchically structured policies that can achieve high performance than conventional self-play on competitive real-time strategic games.\",\"ratings\":\"[3, 2, 2]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJz6QhR9YQ\"},{\"Index\":908,\"qgrid_unfiltered_index\":908,\"title\":\"Deli-Fisher GAN: Stable and Efficient Image Generation With Structured Latent Generative Space\",\"avg_rating\":2.3,\"avg_confidence\":4.7,\"topic\":\"generative adversarial network\",\"tldr\":\"This paper proposes a new Generative Adversarial Network that is more stable, more efficient, and produces better images than those of status-quo \",\"ratings\":\"[2, 2, 3]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyMuaiAqY7\"},{\"Index\":557,\"qgrid_unfiltered_index\":557,\"title\":\"Psychophysical vs. learnt texture representations in novelty detection\",\"avg_rating\":2.3,\"avg_confidence\":3.3,\"topic\":\"novelty detection\",\"tldr\":\"Comparison of psychophysical and CNN-encoded  texture representations in a one-class neural network novelty detection application.\",\"ratings\":\"[3, 3, 1]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJEOOsCqKm\"},{\"Index\":559,\"qgrid_unfiltered_index\":559,\"title\":\"Pixel Chem: A Representation for Predicting Material Properties with Neural Network\",\"avg_rating\":2.3,\"avg_confidence\":4.3,\"topic\":\"material property prediction\",\"tldr\":\"Proposed a unified, physics based representation of material structures to predict various properties with neural netwoek.\",\"ratings\":\"[3, 1, 3]\",\"confidence\":\"[3, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxYOiCqKX\"},{\"Index\":1296,\"qgrid_unfiltered_index\":1296,\"title\":\"Advanced Neuroevolution: A gradient-free algorithm to train Deep Neural Networks\",\"avg_rating\":2.3,\"avg_confidence\":4.7,\"topic\":\"evolutionary algorithm\",\"tldr\":\"A new algorithm to train deep neural networks. Tested on optimization functions and MNIST.\",\"ratings\":\"[1, 1, 5]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1g5Gh05KQ\"},{\"Index\":238,\"qgrid_unfiltered_index\":238,\"title\":\"Weak contraction mapping and optimization\",\"avg_rating\":2.5,\"avg_confidence\":5.0,\"topic\":\"weak contraction mapping\",\"tldr\":\"A gradient-free method is proposed for non-convex optimization problem \",\"ratings\":\"[1, 4]\",\"confidence\":\"[5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygJSiA5YQ\"},{\"Index\":572,\"qgrid_unfiltered_index\":572,\"title\":\"A Solution to China Competitive Poker Using Deep Learning\",\"avg_rating\":2.5,\"avg_confidence\":3.5,\"topic\":\"artificial intelligence\",\"tldr\":\"This paper introduces a method to play China competitive poker using deep neural network, gets the state of the art performance.\",\"ratings\":\"[3, 2]\",\"confidence\":\"[4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJzoujRct7\"},{\"Index\":486,\"qgrid_unfiltered_index\":486,\"title\":\"VARIATIONAL SGD: DROPOUT , GENERALIZATION AND CRITICAL POINT AT THE END OF CONVEXITY\",\"avg_rating\":2.7,\"avg_confidence\":4.0,\"topic\":\"bayesian inference\",\"tldr\":\"Proposed method for finding the most generalizable solution that is stable w.r.t. perturbations of trainig data.\",\"ratings\":\"[4, 2, 2]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1ztwiCcYQ\"},{\"Index\":1069,\"qgrid_unfiltered_index\":1069,\"title\":\"HAPPIER: Hierarchical Polyphonic Music Generative RNN\",\"avg_rating\":2.7,\"avg_confidence\":4.3,\"topic\":\"hierarchical model\",\"tldr\":\"\",\"ratings\":\"[2, 3, 3]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJx5kn0cK7\"},{\"Index\":938,\"qgrid_unfiltered_index\":938,\"title\":\"A bird's eye view on coherence, and a worm's eye view on cohesion\",\"avg_rating\":2.7,\"avg_confidence\":4.0,\"topic\":\"text generation\",\"tldr\":\"We encode linguistic properties, such as, coherence and cohesion, into expert discriminators and improve text generation.\",\"ratings\":\"[2, 2, 4]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1gkAoA5FQ\"},{\"Index\":873,\"qgrid_unfiltered_index\":873,\"title\":\"End-to-End Learning of Video Compression Using Spatio-Temporal Autoencoders\",\"avg_rating\":2.7,\"avg_confidence\":4.0,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 2]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyllasActm\"},{\"Index\":1520,\"qgrid_unfiltered_index\":1520,\"title\":\"A CASE STUDY ON OPTIMAL DEEP LEARNING MODEL FOR UAVS\",\"avg_rating\":2.7,\"avg_confidence\":2.3,\"topic\":\"energy efficiency\",\"tldr\":\"case study on optimal deep learning model for UAVs\",\"ratings\":\"[3, 3, 2]\",\"confidence\":\"[3, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syx9rnRcYm\"},{\"Index\":220,\"qgrid_unfiltered_index\":220,\"title\":\"Learning Goal-Conditioned Value Functions with one-step Path rewards rather than Goal-Rewards\",\"avg_rating\":2.7,\"avg_confidence\":3.7,\"topic\":\"floyd-warshall\",\"tldr\":\"Do Goal-Conditioned Value Functions need Goal-Rewards to Learn?\",\"ratings\":\"[4, 1, 3]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkesGnCcFX\"},{\"Index\":278,\"qgrid_unfiltered_index\":278,\"title\":\"Multiple Encoder-Decoders Net for Lane Detection\",\"avg_rating\":2.7,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[2, 2, 4]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJgiNo0cKX\"},{\"Index\":295,\"qgrid_unfiltered_index\":295,\"title\":\"Explaining Adversarial Examples with Knowledge Representation\",\"avg_rating\":2.7,\"avg_confidence\":3.7,\"topic\":\"adversarial example\",\"tldr\":\"Hybird storage and representation of learned knowledge may be a reason for adversarial examples.\",\"ratings\":\"[3, 3, 2]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BylRVjC9K7\"},{\"Index\":590,\"qgrid_unfiltered_index\":590,\"title\":\"Decoupling Gating from Linearity\",\"avg_rating\":2.7,\"avg_confidence\":4.7,\"topic\":\"artificial neural network\",\"tldr\":\"We propose Gated Linear Unit networks \\u2014 a model that performs similarly to ReLU networks on real data while being much easier to analyze theoretically.\",\"ratings\":\"[3, 2, 3]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJGyFiRqK7\"},{\"Index\":379,\"qgrid_unfiltered_index\":379,\"title\":\"Exponentially Decaying Flows for Optimization in Deep Learning\",\"avg_rating\":2.7,\"avg_confidence\":4.3,\"topic\":\"optimisation\",\"tldr\":\"Introduction of a new optimization method and its application to deep learning.\",\"ratings\":\"[3, 3, 2]\",\"confidence\":\"[5, 3, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJe-LiA5YX\"},{\"Index\":586,\"qgrid_unfiltered_index\":586,\"title\":\"Faster Training by Selecting Samples Using Embeddings\",\"avg_rating\":2.7,\"avg_confidence\":4.3,\"topic\":\"machine learning\",\"tldr\":\"Training is sped up by using a dataset that has been subsampled through embedding analysis.\",\"ratings\":\"[3, 3, 2]\",\"confidence\":\"[5, 3, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SklR_iCcYm\"},{\"Index\":1183,\"qgrid_unfiltered_index\":1183,\"title\":\"Predictive Local Smoothness for Stochastic Gradient Methods\",\"avg_rating\":2.8,\"avg_confidence\":4.2,\"topic\":\"stochastic gradient method\",\"tldr\":\"\",\"ratings\":\"[2, 3, 2, 4]\",\"confidence\":\"[4, 3, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJWfW2C9Y7\"},{\"Index\":406,\"qgrid_unfiltered_index\":406,\"title\":\"Stacking for Transfer Learning\",\"avg_rating\":3.0,\"avg_confidence\":5.0,\"topic\":\"data diversi\\ufb01cation\",\"tldr\":\"How to use stacked generalization to improve the performance of existing transfer learning algorithms when limited labeled data is available.\",\"ratings\":\"[3, 4, 2]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryxOIsA5FQ\"},{\"Index\":1299,\"qgrid_unfiltered_index\":1299,\"title\":\"A Self-Supervised Method for Mapping Human Instructions to Robot Policies\",\"avg_rating\":3.0,\"avg_confidence\":4.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[4, 3, 2]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkgiM20cYX\"},{\"Index\":563,\"qgrid_unfiltered_index\":563,\"title\":\"A Forensic Representation to Detect Non-Trivial Image Duplicates, and How it Applies to Semantic Segmentation\",\"avg_rating\":3.0,\"avg_confidence\":4.7,\"topic\":\"metric learning\",\"tldr\":\"A forensic metric to determine if a given image is a copy (with possible manipulation) of another image from a given dataset.\",\"ratings\":\"[4, 3, 2]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxY_oCqKQ\"},{\"Index\":1293,\"qgrid_unfiltered_index\":1293,\"title\":\"End-to-End Multi-Lingual Multi-Speaker Speech Recognition\",\"avg_rating\":3.0,\"avg_confidence\":4.3,\"topic\":\"end-to-end asr\",\"tldr\":\"\",\"ratings\":\"[3, 3, 3]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJxqMhC5YQ\"},{\"Index\":460,\"qgrid_unfiltered_index\":460,\"title\":\"ReNeg and Backseat Driver: Learning from demonstration with continuous human feedback\",\"avg_rating\":3.0,\"avg_confidence\":4.3,\"topic\":\"learning from demonstration\",\"tldr\":\"We introduce a novel framework for learning from demonstration that uses continuous human feedback; we evaluate this framework on continuous control for autonomous vehicles.\",\"ratings\":\"[3, 4, 2]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJl7DsR5YQ\"},{\"Index\":856,\"qgrid_unfiltered_index\":856,\"title\":\"Learning with Reflective Likelihoods\",\"avg_rating\":3.0,\"avg_confidence\":4.0,\"topic\":\"new learning criterion\",\"tldr\":\"We identify a peculiarity in maximum likelihood learning that causes input collapse and propose a new learning criterion for better representation learning.\",\"ratings\":\"[4, 2, 3]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJlh2jR9FX\"},{\"Index\":266,\"qgrid_unfiltered_index\":266,\"title\":\"ATTENTION INCORPORATE NETWORK: A NETWORK CAN ADAPT VARIOUS DATA SIZE\",\"avg_rating\":3.0,\"avg_confidence\":4.3,\"topic\":\"attention mechanism\",\"tldr\":\"\",\"ratings\":\"[3, 4, 2]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1g_EsActm\"},{\"Index\":373,\"qgrid_unfiltered_index\":373,\"title\":\"An Exhaustive Analysis of Lazy vs. Eager Learning Methods for Real-Estate Property Investment\",\"avg_rating\":3.0,\"avg_confidence\":4.3,\"topic\":\"applied machine learning\",\"tldr\":\"\",\"ratings\":\"[3, 4, 2]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1ge8sCqFX\"},{\"Index\":1263,\"qgrid_unfiltered_index\":1263,\"title\":\"Classification in the dark using tactile exploration\",\"avg_rating\":3.0,\"avg_confidence\":4.3,\"topic\":\"tactile sensing\",\"tldr\":\"In this work, we study the problem of learning representations to identify novel objects by exploring objects using tactile sensing. Key point here is that the query is provided in image domain.\",\"ratings\":\"[4, 3, 2]\",\"confidence\":\"[3, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1lXGnRctX\"},{\"Index\":1457,\"qgrid_unfiltered_index\":1457,\"title\":\"From Amortised to Memoised Inference: Combining Wake-Sleep and Variational-Bayes for Unsupervised Few-Shot Program Learning\",\"avg_rating\":3.0,\"avg_confidence\":4.7,\"topic\":\"wake-sleep\",\"tldr\":\"We extend the wake-sleep algorithm and use it to learn to learn structured models from few examples, \",\"ratings\":\"[3, 3, 3]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1gTE2AcKQ\"},{\"Index\":1283,\"qgrid_unfiltered_index\":1283,\"title\":\"Learning powerful policies and better generative models by interaction\",\"avg_rating\":3.0,\"avg_confidence\":3.3,\"topic\":\"model based reinforcement learning\",\"tldr\":\"In this paper, we formulate a way to ensure consistency between the predictions of dynamics model and the real observations from the environment. Thus allowing us to learn powerful policies, as well as better dynamics models.\",\"ratings\":\"[3, 2, 4]\",\"confidence\":\"[5, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJldzhA5tQ\"},{\"Index\":1019,\"qgrid_unfiltered_index\":1019,\"title\":\"Feature quantization for parsimonious and meaningful predictive models\",\"avg_rating\":3.0,\"avg_confidence\":3.0,\"topic\":\"discretization\",\"tldr\":\"We tackle discretization of continuous features and grouping of factor levels as a representation learning problem and provide a rigorous way of estimating the best quantization to yield good performance and interpretability.\",\"ratings\":\"[2, 3, 4]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1geJhC9Km\"},{\"Index\":1408,\"qgrid_unfiltered_index\":1408,\"title\":\"ATTENTIVE EXPLAINABILITY FOR PATIENT TEMPO- RAL EMBEDDING\",\"avg_rating\":3.0,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[4, 3, 2]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkgMNnC9YQ\"},{\"Index\":875,\"qgrid_unfiltered_index\":875,\"title\":\"Variational Autoencoders for Text Modeling without Weakening the Decoder\",\"avg_rating\":3.0,\"avg_confidence\":4.0,\"topic\":\"variational autoencoders\",\"tldr\":\"We propose a model of variational autoencoders for text modeling without weakening the decoder, which improves the quality of text generation and interpretability of acquired representations.\",\"ratings\":\"[4, 4, 1]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1eZ6sRcFm\"},{\"Index\":497,\"qgrid_unfiltered_index\":497,\"title\":\"Real-time Neural-based Input Method\",\"avg_rating\":3.0,\"avg_confidence\":3.3,\"topic\":\"input method\",\"tldr\":\"\",\"ratings\":\"[3, 3, 3]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Ske6wiAcKQ\"},{\"Index\":1159,\"qgrid_unfiltered_index\":1159,\"title\":\"Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference\",\"avg_rating\":3.0,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 3]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lpx3A9K7\"},{\"Index\":694,\"qgrid_unfiltered_index\":694,\"title\":\"Calibration of neural network logit vectors to combat adversarial attacks\",\"avg_rating\":3.0,\"avg_confidence\":4.3,\"topic\":\"adversarial attack\",\"tldr\":\"This paper uses principles from the field of calibration in machine learning on the logits of a neural network to defend against adversarial attacks\",\"ratings\":\"[3, 2, 4]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bkxdqj0cFQ\"},{\"Index\":702,\"qgrid_unfiltered_index\":702,\"title\":\"KNOWLEDGE DISTILL VIA LEARNING NEURON MANIFOLD\",\"avg_rating\":3.0,\"avg_confidence\":4.0,\"topic\":\"deep learning\",\"tldr\":\"A new knowledge distill method for transfer learning\",\"ratings\":\"[5, 1, 3]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJlYcoCcKX\"},{\"Index\":931,\"qgrid_unfiltered_index\":931,\"title\":\"Evaluation Methodology for Attacks Against Confidence Thresholding Models\",\"avg_rating\":3.0,\"avg_confidence\":3.7,\"topic\":\"adversarial example\",\"tldr\":\"We present metrics and an optimal attack for evaluating models that defend against adversarial examples using confidence thresholding\",\"ratings\":\"[2, 3, 4]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1g0piA9tQ\"},{\"Index\":322,\"qgrid_unfiltered_index\":322,\"title\":\"SpaMHMM: Sparse Mixture of Hidden Markov Models for Graph Connected Entities\",\"avg_rating\":3.0,\"avg_confidence\":4.0,\"topic\":\"multi-entity sequential data\",\"tldr\":\"A method to model the generative distribution of sequences coming from graph connected entities.\",\"ratings\":\"[3, 3, 3]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJM4SjR5KQ\"},{\"Index\":979,\"qgrid_unfiltered_index\":979,\"title\":\"Learn From Neighbour: A Curriculum That Train Low Weighted Samples By Imitating\",\"avg_rating\":3.0,\"avg_confidence\":4.0,\"topic\":\"curriculum learning\",\"tldr\":\"\",\"ratings\":\"[2, 3, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1luCsCqFm\"},{\"Index\":440,\"qgrid_unfiltered_index\":440,\"title\":\"Mapping the hyponymy relation of wordnet onto vector Spaces\",\"avg_rating\":3.0,\"avg_confidence\":4.0,\"topic\":\"fasttext\",\"tldr\":\"We investigate mapping the hyponymy relation of wordnet to feature vectors\",\"ratings\":\"[3, 3, 3]\",\"confidence\":\"[4, 3, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xywsC9tQ\"},{\"Index\":530,\"qgrid_unfiltered_index\":530,\"title\":\"iRDA Method for Sparse Convolutional Neural Networks\",\"avg_rating\":3.0,\"avg_confidence\":4.7,\"topic\":\"sparse convolutional neural networks\",\"tldr\":\"A sparse optimization algorithm for deep CNN models.\",\"ratings\":\"[3, 3, 3]\",\"confidence\":\"[5, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMXus0ct7\"},{\"Index\":343,\"qgrid_unfiltered_index\":343,\"title\":\"Hybrid Policies Using Inverse Rewards for Reinforcement Learning\",\"avg_rating\":3.0,\"avg_confidence\":4.7,\"topic\":\"reinforcement learning\",\"tldr\":\"A broad-spectrum improvement for reinforcement learning algorithms, which combines the policies using original rewards and inverse (negative) rewards\",\"ratings\":\"[3, 2, 4]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HketHo0qFm\"},{\"Index\":838,\"qgrid_unfiltered_index\":838,\"title\":\"Dopamine: A Research Framework for Deep Reinforcement Learning\",\"avg_rating\":3.0,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"In this paper we introduce Dopamine, a new research framework for deep RL that is open-source, TensorFlow-based, and provides compact yet reliable implementations of some state-of-the-art deep RL agents.\",\"ratings\":\"[3, 3, 3]\",\"confidence\":\"[4, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByG_3s09KX\"},{\"Index\":245,\"qgrid_unfiltered_index\":245,\"title\":\"A Rate-Distortion Theory of Adversarial Examples\",\"avg_rating\":3.0,\"avg_confidence\":3.3,\"topic\":\"adversarial example\",\"tldr\":\"We argue that excess capacity is a significant cause of susceptibility to adversarial examples.\",\"ratings\":\"[4, 3, 2]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkezfhA5Y7\"},{\"Index\":517,\"qgrid_unfiltered_index\":517,\"title\":\"REVERSED NEURAL NETWORK - AUTOMATICALLY FINDING NASH EQUILIBRIUM\",\"avg_rating\":3.0,\"avg_confidence\":4.5,\"topic\":\"reinforcement learning\",\"tldr\":\"REVERSED NEURAL NETWORK - A PRIMAL\",\"ratings\":\"[2, 4]\",\"confidence\":\"[4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxZdj09tX\"},{\"Index\":777,\"qgrid_unfiltered_index\":777,\"title\":\"Probabilistic Program Induction for Intuitive Physics Game Play\",\"avg_rating\":3.0,\"avg_confidence\":3.3,\"topic\":\"intuitive physics\",\"tldr\":\"The paper describes a method imitating human cognition about the physical world to play games in environments of physical interactions.\",\"ratings\":\"[3, 4, 2]\",\"confidence\":\"[4, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMsiiRctX\"},{\"Index\":1178,\"qgrid_unfiltered_index\":1178,\"title\":\"HR-TD: A Regularized TD Method to Avoid Over-Generalization\",\"avg_rating\":3.0,\"avg_confidence\":4.3,\"topic\":\"reinforcement learning\",\"tldr\":\"A regularization technique for TD learning that avoids temporal over-generalization, especially in Deep Networks\",\"ratings\":\"[4, 3, 2]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylbWhC5Ym\"},{\"Index\":342,\"qgrid_unfiltered_index\":342,\"title\":\"Nonlinear Channels Aggregation Networks for Deep Action Recognition\",\"avg_rating\":3.0,\"avg_confidence\":4.0,\"topic\":\"action recognition\",\"tldr\":\"An architecture enables CNN trained on the video sequences converging rapidly \",\"ratings\":\"[3, 3, 3]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgdHs05FQ\"},{\"Index\":1207,\"qgrid_unfiltered_index\":1207,\"title\":\"HANDLING CONCEPT DRIFT  IN WIFI-BASED INDOOR LOCALIZATION USING REPRESENTATION LEARNING\",\"avg_rating\":3.0,\"avg_confidence\":3.0,\"topic\":\"concept drift\",\"tldr\":\"We introduce an augmented robust feature space for streaming wifi data that is capable of tackling concept drift for indoor localization\",\"ratings\":\"[2, 3, 4]\",\"confidence\":\"[1, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxdbnR9YQ\"},{\"Index\":522,\"qgrid_unfiltered_index\":522,\"title\":\"Learning of Sophisticated Curriculums by viewing them as Graphs over Tasks\",\"avg_rating\":3.0,\"avg_confidence\":2.3,\"topic\":\"learning\",\"tldr\":\"We present a new algorithm for learning by curriculum based on the notion of mastering rate that outperforms previous algorithms.\",\"ratings\":\"[3, 2, 4]\",\"confidence\":\"[1, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlGdsC9Ym\"},{\"Index\":1001,\"qgrid_unfiltered_index\":1001,\"title\":\"One Bit Matters: Understanding Adversarial Examples as the Abuse of Redundancy\",\"avg_rating\":3.0,\"avg_confidence\":4.0,\"topic\":\"adversarial example\",\"tldr\":\"A new theoretical explanation for the existence of adversarial examples\",\"ratings\":\"[3, 3, 3]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1enCo0cK7\"},{\"Index\":821,\"qgrid_unfiltered_index\":821,\"title\":\"An Analysis of Composite Neural Network Performance from Function Composition Perspective\",\"avg_rating\":3.0,\"avg_confidence\":3.0,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 3]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkGSniC9FQ\"},{\"Index\":946,\"qgrid_unfiltered_index\":946,\"title\":\"A NON-LINEAR  THEORY FOR SENTENCE EMBEDDING\",\"avg_rating\":3.0,\"avg_confidence\":3.3,\"topic\":\"sentence embedding\",\"tldr\":\"\",\"ratings\":\"[3, 3, 3]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJMZRsC9Y7\"},{\"Index\":1200,\"qgrid_unfiltered_index\":1200,\"title\":\"ATTACK GRAPH CONVOLUTIONAL NETWORKS BY ADDING FAKE NODES\",\"avg_rating\":3.3,\"avg_confidence\":3.0,\"topic\":\"graph convolutional network\",\"tldr\":\"non-targeted and targeted attack on GCN by adding fake nodes\",\"ratings\":\"[4, 3, 3]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke8ZhCcFQ\"},{\"Index\":680,\"qgrid_unfiltered_index\":680,\"title\":\"Step-wise Sensitivity Analysis: Identifying Partially Distributed Representations for Interpretable Deep Learning\",\"avg_rating\":3.3,\"avg_confidence\":4.3,\"topic\":\"interpretability\",\"tldr\":\"We find dependency graphs between learned representations as a first step towards building decision trees to interpret the representation manifold.\",\"ratings\":\"[3, 4, 3]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyeBqsRctm\"},{\"Index\":477,\"qgrid_unfiltered_index\":477,\"title\":\"Geometric Operator Convolutional Neural Network\",\"avg_rating\":3.3,\"avg_confidence\":4.7,\"topic\":\"convolutional neural network\",\"tldr\":\"Traditional image processing algorithms are combined with Convolutional Neural Networks\\uff0ca new neural network.\",\"ratings\":\"[2, 5, 3]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkVvwj0qFm\"},{\"Index\":887,\"qgrid_unfiltered_index\":887,\"title\":\"Detecting Topological Defects in 2D Active Nematics Using Convolutional Neural Networks\",\"avg_rating\":3.3,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"An interesting application of CNN in soft condensed matter physics experiments.\",\"ratings\":\"[4, 4, 2]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklVTi09tm\"},{\"Index\":594,\"qgrid_unfiltered_index\":594,\"title\":\"BIGSAGE: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating\",\"avg_rating\":3.3,\"avg_confidence\":3.7,\"topic\":\"network embedding\",\"tldr\":\"For unsupervised and inductive network embedding, we propose a novel approach to explore most relevant neighbors and preserve previously learnt knowledge of nodes by utilizing bi-attention architecture and introducing global bias, respectively\",\"ratings\":\"[2, 4, 4]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygxYoC5FX\"},{\"Index\":533,\"qgrid_unfiltered_index\":533,\"title\":\"MAJOR-MINOR LSTMS FOR WORD-LEVEL LANGUAGE MODEL\",\"avg_rating\":3.3,\"avg_confidence\":4.7,\"topic\":\"language model\",\"tldr\":\"\",\"ratings\":\"[4, 3, 3]\",\"confidence\":\"[5, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1MVuoCctX\"},{\"Index\":1166,\"qgrid_unfiltered_index\":1166,\"title\":\"Neural Network Regression with Beta, Dirichlet, and Dirichlet-Multinomial Outputs\",\"avg_rating\":3.3,\"avg_confidence\":4.3,\"topic\":\"regression\",\"tldr\":\"Neural network regression should use Dirichlet output distribution when targets are probabilities in order to quantify uncertainty of predictions.\",\"ratings\":\"[3, 3, 4]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJeRg205Fm\"},{\"Index\":1031,\"qgrid_unfiltered_index\":1031,\"title\":\"Learning Spatio-Temporal Representations Using Spike-Based Backpropagation\",\"avg_rating\":3.3,\"avg_confidence\":4.7,\"topic\":\"spiking neural networks\",\"tldr\":\"\",\"ratings\":\"[3, 4, 3]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJxfJnC9YX\"},{\"Index\":228,\"qgrid_unfiltered_index\":228,\"title\":\"Deterministic Policy Gradients with General State Transitions\",\"avg_rating\":3.3,\"avg_confidence\":3.7,\"topic\":\"reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[4, 5, 1]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylRgh0qK7\"},{\"Index\":441,\"qgrid_unfiltered_index\":441,\"title\":\"Discrete Structural Planning for Generating Diverse Translations\",\"avg_rating\":3.3,\"avg_confidence\":4.3,\"topic\":\"machine translation\",\"tldr\":\"Learning discrete structural representation to control sentence generation and obtain diverse outputs\",\"ratings\":\"[5, 2, 3]\",\"confidence\":\"[3, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJG1wjRqFQ\"},{\"Index\":646,\"qgrid_unfiltered_index\":646,\"title\":\"BEHAVIOR MODULE IN NEURAL NETWORKS\",\"avg_rating\":3.3,\"avg_confidence\":4.7,\"topic\":\"modular network\",\"tldr\":\"Extendable Modular Architecture is proposed for developing of variety of Agent Behaviors in DQN.\",\"ratings\":\"[3, 3, 4]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syl6tjAqKX\"},{\"Index\":634,\"qgrid_unfiltered_index\":634,\"title\":\"Gradient Acceleration in Activation Functions\",\"avg_rating\":3.3,\"avg_confidence\":4.0,\"topic\":\"gradient acceleration\",\"tldr\":\"\",\"ratings\":\"[3, 5, 2]\",\"confidence\":\"[4, 3, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1M9FjC5FQ\"},{\"Index\":964,\"qgrid_unfiltered_index\":964,\"title\":\"LSH Microbatches for Stochastic Gradients:  Value in Rearrangement\",\"avg_rating\":3.3,\"avg_confidence\":3.3,\"topic\":\"stochastic gradient descent\",\"tldr\":\"Accelerating SGD by arranging examples differently\",\"ratings\":\"[4, 3, 3]\",\"confidence\":\"[4, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1erRoCqtX\"},{\"Index\":1081,\"qgrid_unfiltered_index\":1081,\"title\":\"Empirical Study of Easy and Hard Examples in CNN Training\",\"avg_rating\":3.3,\"avg_confidence\":4.3,\"topic\":\"easy examples\",\"tldr\":\"Unknown properties of easy and hard examples are shown, and they come from biases in a dataset and SGD.\",\"ratings\":\"[3, 4, 3]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJepJh0qKX\"},{\"Index\":427,\"qgrid_unfiltered_index\":427,\"title\":\"Encoder Discriminator Networks for Unsupervised Representation Learning\",\"avg_rating\":3.3,\"avg_confidence\":4.3,\"topic\":\"representation learning\",\"tldr\":\"\",\"ratings\":\"[3, 4, 3]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJEhIjA9tQ\"},{\"Index\":392,\"qgrid_unfiltered_index\":392,\"title\":\"SHE2: Stochastic Hamiltonian Exploration and Exploitation for Derivative-Free Optimization\",\"avg_rating\":3.3,\"avg_confidence\":4.0,\"topic\":\"derivative-free optimization\",\"tldr\":\"a new derivative-free optimization algorithms derived from Nesterov's accelerated gradient methods and Hamiltonian dynamics\",\"ratings\":\"[4, 3, 3]\",\"confidence\":\"[4, 3, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rklEUjR5tm\"},{\"Index\":1021,\"qgrid_unfiltered_index\":1021,\"title\":\"Beyond Games: Bringing Exploration to Robots in Real-world\",\"avg_rating\":3.3,\"avg_confidence\":4.0,\"topic\":\"exploration\",\"tldr\":\"\",\"ratings\":\"[3, 3, 4]\",\"confidence\":\"[5, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkzeJ3A9F7\"},{\"Index\":264,\"qgrid_unfiltered_index\":264,\"title\":\"Linearizing Visual Processes with Deep Generative Models\",\"avg_rating\":3.3,\"avg_confidence\":3.7,\"topic\":\"generative adversarial network\",\"tldr\":\"We model non-linear visual processes as autoregressive noise via generative deep learning.\",\"ratings\":\"[3, 3, 4]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkMPNoCcKQ\"},{\"Index\":960,\"qgrid_unfiltered_index\":960,\"title\":\"Neural Distribution Learning for generalized time-to-event prediction\",\"avg_rating\":3.3,\"avg_confidence\":4.0,\"topic\":\"deep learning\",\"tldr\":\"We present a general solution to event prediction that has been there all along; Discrete Time Parametric Survival Analysis.\",\"ratings\":\"[4, 3, 3]\",\"confidence\":\"[5, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyG4RiR5Ym\"},{\"Index\":1422,\"qgrid_unfiltered_index\":1422,\"title\":\"Combining adaptive algorithms and hypergradient method: a performance and robustness study\",\"avg_rating\":3.3,\"avg_confidence\":3.3,\"topic\":\"optimisation\",\"tldr\":\"We provide a study trying to see how the recent online learning rate adaptation extends the conclusion made by Wilson et al. 2018 about adaptive gradient methods, along with comparison and sensitivity analysis.\",\"ratings\":\"[3, 3, 4]\",\"confidence\":\"[4, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgSV3AqKQ\"},{\"Index\":919,\"qgrid_unfiltered_index\":919,\"title\":\"Logit Regularization Methods for Adversarial Robustness\",\"avg_rating\":3.3,\"avg_confidence\":5.0,\"topic\":\"adversarial\",\"tldr\":\"Logit regularization methods help explain and improve state of the art adversarial defenses\",\"ratings\":\"[3, 5, 2]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bylj6oC5K7\"},{\"Index\":466,\"qgrid_unfiltered_index\":466,\"title\":\"Understanding and Improving Sequence-Labeling NER with Self-Attentive LSTMs\",\"avg_rating\":3.3,\"avg_confidence\":4.3,\"topic\":\"interpretability\",\"tldr\":\"We provide insightful understanding of sequence-labeling NER and propose to use two types of cross structures, both of which bring theoretical and empirical improvements.\",\"ratings\":\"[3, 3, 4]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rklNwjCcYm\"},{\"Index\":668,\"qgrid_unfiltered_index\":668,\"title\":\"Neural Random Projections for Language Modelling\",\"avg_rating\":3.3,\"avg_confidence\":3.7,\"topic\":\"neural networks\",\"tldr\":\"Neural language models can be trained with a compressed embedding space, by using sparse random projections, created incrementally for each unique discrete input.\",\"ratings\":\"[3, 4, 3]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlMcjC5K7\"},{\"Index\":254,\"qgrid_unfiltered_index\":254,\"title\":\"Multi-Scale Stacked Hourglass Network for Human Pose Estimation\",\"avg_rating\":3.3,\"avg_confidence\":4.7,\"topic\":\"human pose estimation\",\"tldr\":\"Differentiated inputs cause functional differentiation of the network, and the interaction of loss functions between networks can affect the optimization process.\",\"ratings\":\"[3, 4, 3]\",\"confidence\":\"[5, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkM3vjCcF7\"},{\"Index\":267,\"qgrid_unfiltered_index\":267,\"title\":\"Interpreting Layered Neural Networks via Hierarchical Modular Representation\",\"avg_rating\":3.3,\"avg_confidence\":3.7,\"topic\":\"interpretabile machine learning\",\"tldr\":\"A method for obtaining a hierarchical cluster structure of a trained layered neural network\",\"ratings\":\"[4, 3, 3]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hyed4i05KX\"},{\"Index\":327,\"qgrid_unfiltered_index\":327,\"title\":\"Learning and Data Selection in Big Datasets\",\"avg_rating\":3.3,\"avg_confidence\":4.0,\"topic\":\"data selection\",\"tldr\":\"\",\"ratings\":\"[4, 3, 3]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1l8SsR9Fm\"},{\"Index\":1541,\"qgrid_unfiltered_index\":1541,\"title\":\"Human Action Recognition Based on Spatial-Temporal Attention\",\"avg_rating\":3.3,\"avg_confidence\":4.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[4, 3, 3]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Byx7LjRcYm\"},{\"Index\":1343,\"qgrid_unfiltered_index\":1343,\"title\":\"Uncertainty in Multitask Transfer Learning\",\"avg_rating\":3.3,\"avg_confidence\":4.3,\"topic\":\"multi task\",\"tldr\":\"A scalable method for learning an expressive prior over neural networks across multiple tasks.\",\"ratings\":\"[3, 2, 5]\",\"confidence\":\"[5, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eEmn05tQ\"},{\"Index\":511,\"qgrid_unfiltered_index\":511,\"title\":\"A quantifiable testing of global translational invariance in Convolutional and Capsule Networks\",\"avg_rating\":3.3,\"avg_confidence\":4.7,\"topic\":\"translational invariance\",\"tldr\":\"Testing of global translational invariance in Convolutional and Capsule Networks\",\"ratings\":\"[3, 4, 3]\",\"confidence\":\"[5, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJlgOjAqYQ\"},{\"Index\":1345,\"qgrid_unfiltered_index\":1345,\"title\":\"Associate Normalization\",\"avg_rating\":3.3,\"avg_confidence\":4.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 5, 2]\",\"confidence\":\"[5, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkNN7nR5Ym\"},{\"Index\":305,\"qgrid_unfiltered_index\":305,\"title\":\"Accidental explorationa through value predictors\",\"avg_rating\":3.3,\"avg_confidence\":4.0,\"topic\":\"reinforcement learning\",\"tldr\":\"We study the biases introduced in common value predictors by the fact that trajectories are, in practice, finite.\",\"ratings\":\"[4, 3, 3]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1llBiR5YX\"},{\"Index\":296,\"qgrid_unfiltered_index\":296,\"title\":\"IEA: Inner Ensemble Average within a convolutional neural network\",\"avg_rating\":3.3,\"avg_confidence\":4.0,\"topic\":\"ensemble convolutional neural networks\",\"tldr\":\"We inner ensemble the features of a convolutional neural layer, it increases the network accuracy and generates distinct features.\",\"ratings\":\"[4, 2, 4]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygANjA5FX\"},{\"Index\":573,\"qgrid_unfiltered_index\":573,\"title\":\"Deep models calibration with bayesian neural networks\",\"avg_rating\":3.3,\"avg_confidence\":4.0,\"topic\":\"calibration\",\"tldr\":\"We apply bayesian neural networks to improve calibration\",\"ratings\":\"[4, 3, 3]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xjdoC9Fm\"},{\"Index\":758,\"qgrid_unfiltered_index\":758,\"title\":\"Deconfounding Reinforcement Learning\",\"avg_rating\":3.3,\"avg_confidence\":3.7,\"topic\":\"confounder\",\"tldr\":\"This is the first attempt to build a bridge between confounding and the full reinforcement learning problem.\",\"ratings\":\"[4, 4, 2]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryxDjjCqtQ\"},{\"Index\":1231,\"qgrid_unfiltered_index\":1231,\"title\":\"Generative model based on minimizing exact empirical Wasserstein distance\",\"avg_rating\":3.3,\"avg_confidence\":3.7,\"topic\":\"generative modeling\",\"tldr\":\"We have proposed a flexible generative model that learns stably by directly minimizing exact empirical Wasserstein distance.\",\"ratings\":\"[5, 2, 3]\",\"confidence\":\"[2, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgTZ3C5FX\"},{\"Index\":1364,\"qgrid_unfiltered_index\":1364,\"title\":\"The Conditional Entropy Bottleneck\",\"avg_rating\":3.3,\"avg_confidence\":3.3,\"topic\":\"representation learning\",\"tldr\":\"The Conditional Entropy Bottleneck is an information-theoretic objective function for learning optimal representations.\",\"ratings\":\"[3, 2, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkVOXhAqY7\"},{\"Index\":1302,\"qgrid_unfiltered_index\":1302,\"title\":\"Non-Synergistic Variational Autoencoders\",\"avg_rating\":3.3,\"avg_confidence\":4.0,\"topic\":\"vae\",\"tldr\":\"Minimising the synergistic mutual information within the latents and the data for the task of disentanglement using the VAE framework.\",\"ratings\":\"[3, 4, 3]\",\"confidence\":\"[4, 3, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Skl3M20qYQ\"},{\"Index\":1522,\"qgrid_unfiltered_index\":1522,\"title\":\"MCTSBug: Generating Adversarial Text Sequences via Monte Carlo Tree Search and Homoglyph Attack\",\"avg_rating\":3.5,\"avg_confidence\":3.5,\"topic\":\"adversarial sample\",\"tldr\":\"Use Monte carlo Tree Search and Homoglyphs to generate indistinguishable adversarial samples on text data\",\"ratings\":\"[3, 4]\",\"confidence\":\"[4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJxiHnCqKQ\"},{\"Index\":728,\"qgrid_unfiltered_index\":728,\"title\":\"Using Deep Siamese Neural Networks to Speed up Natural Products Research\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"clustering\",\"tldr\":\"We learn a direct mapping from NMR spectra of small molecules to a molecular structure based cluster space. \",\"ratings\":\"[3, 4]\",\"confidence\":\"[2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1ggosR9Ym\"},{\"Index\":227,\"qgrid_unfiltered_index\":227,\"title\":\"Learning to Reinforcement Learn by Imitation\",\"avg_rating\":3.5,\"avg_confidence\":3.5,\"topic\":\"meta learning\",\"tldr\":\"\",\"ratings\":\"[2, 5]\",\"confidence\":\"[5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJG1Uo09Fm\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional network\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlaYi05tm\"},{\"Index\":1026,\"qgrid_unfiltered_index\":1026,\"title\":\"Bamboo: Ball-Shape Data Augmentation Against Adversarial Attacks from All Directions\",\"avg_rating\":3.5,\"avg_confidence\":4.0,\"topic\":\"dnn robustness\",\"tldr\":\"The first data augmentation method specially designed for improving the general robustness of DNN without any hypothesis on the attacking algorithms.\",\"ratings\":\"[4, 3]\",\"confidence\":\"[3, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1zW13R5tm\"},{\"Index\":928,\"qgrid_unfiltered_index\":928,\"title\":\"GEOMETRIC AUGMENTATION FOR ROBUST NEURAL NETWORK CLASSIFIERS\",\"avg_rating\":3.7,\"avg_confidence\":4.0,\"topic\":\"bayesian nonparametric\",\"tldr\":\"We develop a statistical-geometric unsupervised learning augmentation framework for deep neural networks to make them robust to adversarial attacks.\",\"ratings\":\"[4, 4, 3]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJeapjA5FX\"},{\"Index\":1425,\"qgrid_unfiltered_index\":1425,\"title\":\"INTERPRETABLE CONVOLUTIONAL FILTER PRUNING\",\"avg_rating\":3.7,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[4, 4, 3]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJ4BVhRcYX\"},{\"Index\":456,\"qgrid_unfiltered_index\":456,\"title\":\"An Attention-Based Model for Learning Dynamic Interaction Networks\",\"avg_rating\":3.7,\"avg_confidence\":4.0,\"topic\":\"dynamic network\",\"tldr\":\"A graph neural network able to automatically learn and leverage a dynamic interactive graph structure\",\"ratings\":\"[4, 3, 4]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJEGwo0cFX\"},{\"Index\":627,\"qgrid_unfiltered_index\":627,\"title\":\"Quantile Regression Reinforcement Learning with State Aligned Vector Rewards\",\"avg_rating\":3.7,\"avg_confidence\":3.7,\"topic\":\"deep reinforcement learning\",\"tldr\":\"We train with state aligned vector rewards an agent predicting state changes from action distributions, using a new reinforcement learning technique inspired by quantile regression.\",\"ratings\":\"[4, 3, 4]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lFYoRcFm\"},{\"Index\":134,\"qgrid_unfiltered_index\":134,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_rating\":3.7,\"avg_confidence\":3.3,\"topic\":\"visualisation\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"ratings\":\"[4, 3, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Skz3Q2CcFX\"},{\"Index\":622,\"qgrid_unfiltered_index\":622,\"title\":\"Riemannian Stochastic Gradient Descent for Tensor-Train Recurrent Neural Networks\",\"avg_rating\":3.7,\"avg_confidence\":3.7,\"topic\":\"riemannian stochastic gradient descent\",\"tldr\":\"Applying the Riemannian SGD (RSGD) algorithm for training Tensor-Train RNNs to further reduce model parameters.\",\"ratings\":\"[4, 4, 3]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1fPYj0qt7\"}]}",
       "_df_range": [
        0,
        107
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": "avg_rating",
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        7,
        24
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 100,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": false,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "903f3a0c-fa49-4aa1-8278-0576c31e33ce",
       "layout": "IPY_MODEL_1cb9343528a84397adf2d99eafb28f96",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "bf4f9216d3374e438b0e1761b01dec2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bf858461c6574e41b51696fbf3c5e2b7": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"State-Regularized Recurrent Networks\",\"avg_confidence\":4.66667,\"avg_rating\":5.66667,\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_confidence\":3.33333,\"avg_rating\":5.66667,\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"The Deep Weight Prior\",\"avg_confidence\":3.66667,\"avg_rating\":6.33333,\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_confidence\":2.66667,\"avg_rating\":7.0,\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"Adversarial Information Factorization\",\"avg_confidence\":4.0,\"avg_rating\":6.0,\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"Attentive Neural Processes\",\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Complement Objective Training\",\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"tldr\":\"\",\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"tldr\":\"\",\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_confidence\":2.0,\"avg_rating\":6.66667,\"tldr\":\"\",\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_confidence\":4.66667,\"avg_rating\":5.33333,\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_confidence\":3.33333,\"avg_rating\":4.66667,\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"tldr\":\"\",\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_confidence\":4.33333,\"avg_rating\":4.33333,\"tldr\":\"\",\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_confidence\":3.25,\"avg_rating\":4.0,\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_confidence\":4.5,\"avg_rating\":6.5,\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learning what you can do before doing anything\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_confidence\":4.0,\"avg_rating\":7.33333,\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_confidence\":4.33333,\"avg_rating\":5.0,\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"tldr\":\"\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_confidence\":3.0,\"avg_rating\":7.0,\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_confidence\":3.66667,\"avg_rating\":4.66667,\"tldr\":\"\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_confidence\":4.0,\"avg_rating\":6.5,\"tldr\":\"\",\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_confidence\":3.0,\"avg_rating\":5.0,\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_confidence\":3.5,\"avg_rating\":5.5,\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"The Problem of Model Completion\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_confidence\":3.0,\"avg_rating\":7.0,\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"tldr\":\"\",\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"tldr\":\"\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_confidence\":4.66667,\"avg_rating\":7.66667,\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Generative Feature Matching Networks\",\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Adversarial Audio Synthesis\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_confidence\":3.0,\"avg_rating\":3.5,\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"tldr\":\"\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Learning Entropic Wasserstein Embeddings\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\",\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Invariance and Inverse Stability under ReLU\",\"avg_confidence\":3.5,\"avg_rating\":6.5,\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\",\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"avg_confidence\":4.5,\"avg_rating\":6.0,\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\",\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\",\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"avg_confidence\":4.0,\"avg_rating\":4.66667,\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\",\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"avg_confidence\":3.33333,\"avg_rating\":6.33333,\"tldr\":\"\",\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Reward Constrained Policy Optimization\",\"avg_confidence\":3.0,\"avg_rating\":6.0,\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\",\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_confidence\":4.66667,\"avg_rating\":7.0,\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"avg_confidence\":3.66667,\"avg_rating\":6.0,\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Adaptive Neural Trees\",\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\",\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"Phrase-Based Attentions\",\"avg_confidence\":4.66667,\"avg_rating\":5.0,\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\",\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Deep Layers as Stochastic Solvers\",\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\",\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\",\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"tldr\":\"\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"avg_confidence\":4.66667,\"avg_rating\":6.33333,\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\",\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"tldr\":\"\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"tldr\":\"\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \",\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"avg_confidence\":4.33333,\"avg_rating\":5.33333,\"tldr\":\"\",\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Feature-Wise Bias Amplification\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"\",\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"avg_confidence\":4.0,\"avg_rating\":3.66667,\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\",\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Sorting out Lipschitz function approximation\",\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\",\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"avg_confidence\":3.0,\"avg_rating\":6.0,\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\",\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Interpretable Continual Learning\",\"avg_confidence\":3.0,\"avg_rating\":5.5,\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \",\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"Implicit Autoencoders\",\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\",\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"avg_confidence\":4.0,\"avg_rating\":4.33333,\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_confidence\":3.33333,\"avg_rating\":3.66667,\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"avg_confidence\":4.33333,\"avg_rating\":5.66667,\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\",\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"avg_confidence\":4.0,\"avg_rating\":6.0,\"tldr\":\"\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\",\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"avg_confidence\":4.0,\"avg_rating\":6.0,\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\",\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"avg_confidence\":4.5,\"avg_rating\":5.5,\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\",\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\",\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \",\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_confidence\":3.0,\"avg_rating\":7.0,\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\",\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"DEEP GRAPH TRANSLATION\",\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"tldr\":\"\",\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "692c3711-4b6d-4110-9cdd-1db4e9c4eac3",
       "layout": "IPY_MODEL_724496f32c7a4f2c9354ab338313021d",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "c2d951eb3eef4603a2b9b1174ee18b8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c311a7a496db474ba621950475f6c4bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c427dcc971b8459993f540f4faa523bb": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"avg_confidence\":4.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"avg_confidence\":3.33333,\"avg_rating\":5.66667,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"avg_confidence\":3.66667,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"avg_confidence\":2.66667,\"avg_rating\":7.0,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"avg_confidence\":4.0,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"avg_confidence\":2.0,\"avg_rating\":6.66667,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"avg_confidence\":4.66667,\"avg_rating\":5.33333,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"avg_confidence\":3.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"avg_confidence\":4.33333,\"avg_rating\":4.33333,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"avg_confidence\":3.25,\"avg_rating\":4.0,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"avg_confidence\":4.5,\"avg_rating\":6.5,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"avg_confidence\":4.0,\"avg_rating\":7.33333,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"avg_confidence\":4.33333,\"avg_rating\":5.0,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"avg_confidence\":3.66667,\"avg_rating\":4.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"avg_confidence\":4.0,\"avg_rating\":6.5,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"avg_confidence\":3.0,\"avg_rating\":5.0,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"avg_confidence\":3.5,\"avg_rating\":5.5,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"avg_confidence\":4.66667,\"avg_rating\":7.66667,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"avg_confidence\":3.0,\"avg_rating\":3.5,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"avg_confidence\":3.5,\"avg_rating\":6.5,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"avg_confidence\":4.5,\"avg_rating\":6.0,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"avg_confidence\":4.0,\"avg_rating\":4.66667,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"avg_confidence\":3.33333,\"avg_rating\":6.33333,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"avg_confidence\":3.0,\"avg_rating\":6.0,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"avg_confidence\":4.66667,\"avg_rating\":7.0,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"avg_confidence\":3.66667,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"avg_confidence\":4.66667,\"avg_rating\":5.0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"avg_confidence\":4.66667,\"avg_rating\":6.33333,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"avg_confidence\":4.33333,\"avg_rating\":5.33333,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"avg_confidence\":4.0,\"avg_rating\":3.66667,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"avg_confidence\":3.0,\"avg_rating\":6.0,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"avg_confidence\":3.0,\"avg_rating\":5.5,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"avg_confidence\":4.0,\"avg_rating\":4.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"avg_confidence\":3.33333,\"avg_rating\":3.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"avg_confidence\":4.33333,\"avg_rating\":5.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"avg_confidence\":4.0,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"avg_confidence\":4.0,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"avg_confidence\":4.5,\"avg_rating\":5.5,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "fd3928e3-0f9c-4cd2-95bd-042e42f5857e",
       "layout": "IPY_MODEL_bba10f23ce664e38a5d2bde040e9ae06",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "c4c842032d6a485bb7b871cbbd5ef2e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c79f4e7c0b30442ea5541b9639fc767e": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 100
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "url": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "url",
         "id": "url",
         "minWidth": 30,
         "name": "url",
         "position": 9,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxfEn09Y7\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"adversarial example\",\"tldr\":\"We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.\",\"ratings\":\"[7, 7, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4dFjR5K7\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"Generative Code Modeling with Graphs\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"generative models\",\"tldr\":\"Representing programs as graphs including semantics helps when generating programs\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke4KsA5FX\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"generative adversarial network\",\"tldr\":\"We propose a new metric for evaluating GAN models.\",\"ratings\":\"[4, 6, 5]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgYl205tQ\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data\",\"avg_rating\":6.3,\"avg_confidence\":3.0,\"topic\":\"model interpretation\",\"tldr\":\"We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1E3Ko09F7\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"Transfer and Exploration via the Information Bottleneck\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information bottleneck\",\"tldr\":\"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus\",\"ratings\":\"[6, 6, 3]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJg8yhAqKm\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"On the Margin Theory of Feedforward Neural Networks\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"generalization theory\",\"tldr\":\"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.\",\"ratings\":\"[5, 5, 5, 7]\",\"confidence\":\"[4, 4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJGtFoC5Fm\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"avg_rating\":6.0,\"avg_confidence\":3.8,\"topic\":\"adversarial example\",\"tldr\":\"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  \",\"ratings\":\"[4, 5, 9, 6]\",\"confidence\":\"[5, 3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgVRiC9Km\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy\",\"avg_rating\":4.7,\"avg_confidence\":3.0,\"topic\":\"compact representation\",\"tldr\":\"Compact perception of dynamical process\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[3, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJgTciR9tm\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"artificial intelligence\",\"tldr\":\"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl42iA5t7\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Assessing Generalization in Deep Reinforcement Learning\",\"avg_rating\":4.3,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.\",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylKB3A9Fm\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"An Empirical Study of Example Forgetting during Deep Neural Network Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"catastrophic forgetting\",\"tldr\":\"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlxm30cKm\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"On the Relationship between Neural Machine Translation and Word Alignment\",\"avg_rating\":5.0,\"avg_confidence\":4.0,\"topic\":\"neural machine translation\",\"tldr\":\"It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.\",\"ratings\":\"[4, 5, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1eEdj0cK7\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyxPx3R9tm\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Learning Factorized Multimodal Representations\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"multimodal learning\",\"tldr\":\"We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[3, 2, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rygqqsA9KX\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience\",\"avg_rating\":5.2,\"avg_confidence\":3.0,\"topic\":\"generalization\",\"tldr\":\"We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.\",\"ratings\":\"[4, 7, 6, 4]\",\"confidence\":\"[4, 2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygn2o0qKX\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Learning Backpropagation-Free Deep Architectures with Kernels\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"supervised learning\",\"tldr\":\"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. \",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1GLm2R9Km\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Learning concise representations for regression by evolving networks of trees\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"regression\",\"tldr\":\"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. \",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[1, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hke-JhA9Y7\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"inverse reinforcement learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJlmHoR5tQ\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"The role of over-parametrization in generalization of neural networks\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"generalization\",\"tldr\":\"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.\",\"ratings\":\"[5, 7]\",\"confidence\":\"[5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BygfghAcYX\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learnable Embedding Space for Efficient Neural Architecture Compression\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"network compression\",\"tldr\":\"We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xLN3C9YX\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Learning from Positive and Unlabeled Data with a Selection Bias\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"pu learning\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJzLciCqKm\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Empirical Bounds on Linear Regions of Deep Rectifier Networks\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"linear regions\",\"tldr\":\"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1MAJhR5YX\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"Learning to Understand Goal Specifications by Modelling Reward\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"instruction following\",\"tldr\":\"We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xsSjC9Ym\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"maximum mean discrepancy\",\"tldr\":\"\",\"ratings\":\"[6, 5, 8]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkG5SjR5YQ\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"TabNN: A Universal Neural Network Solution for Tabular Data\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"neural networks\",\"tldr\":\"We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.\",\"ratings\":\"[5, 4, 5]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1eJssCqY7\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"Learning Mixed-Curvature Representations in Product Spaces\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"embedding\",\"tldr\":\"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.\",\"ratings\":\"[7, 2, 7]\",\"confidence\":\"[2, 5, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJxeWnCcF7\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation\",\"avg_rating\":5.0,\"avg_confidence\":3.7,\"topic\":\"generalized stochastic approximation\",\"tldr\":\"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables\",\"ratings\":\"[5, 4, 6]\",\"confidence\":\"[4, 2, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1grRoR9tQ\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Diverse Machine Translation with a Single Multinomial Latent Variable\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"machine translation\",\"tldr\":\"\",\"ratings\":\"[6, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgnmhA5KQ\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Computation-Efficient Quantization Method for Deep Neural Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.0,\"topic\":\"quantization\",\"tldr\":\"A simple computation-efficient quantization training method for CNNs and RNNs.\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxnvsAqFm\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Local Binary Pattern Networks for Character Recognition\",\"avg_rating\":5.3,\"avg_confidence\":4.3,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJxcHnRqYQ\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"adversarial example\",\"tldr\":\"Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJl2niR9KQ\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkxt8oC9FQ\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Efficient Lifelong Learning with A-GEM\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"life-long learning\",\"tldr\":\"An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time\\/ memory complexity compared to other algorithms. \",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hkf2_sC5FX\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Recall Traces: Backtracking Models for Efficient Reinforcement Learning\",\"avg_rating\":6.0,\"avg_confidence\":2.7,\"topic\":\"model free rl\",\"tldr\":\"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[2, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HygsfnR9Ym\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Regularized Learning for  Domain Adaptation under Label Shifts\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target\",\"ratings\":\"[7, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl0r3R9KX\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"adversarial example\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[3, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlk6iRqKX\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"Subgradient Descent Learns Orthogonal Dictionaries\",\"avg_rating\":6.2,\"avg_confidence\":2.6,\"topic\":\"dictionary learning\",\"tldr\":\"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.\",\"ratings\":\"[7, 7, 7, 3, 7]\",\"confidence\":\"[2, 3, 4, 1, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklSf3CqKm\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"cnn\",\"tldr\":\"\",\"ratings\":\"[7, 6, 7]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJMHpjC9Ym\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJf_YjCqYX\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJlEojAqFm\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Remember and Forget for Experience Replay\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bye9LiR9YX\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1lYRjC9F7\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Transferrable End-to-End Learning for Protein Interface Prediction\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"transfer learning\",\"tldr\":\"We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkgToo0qFm\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\"Stable Recurrent Models\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"stability\",\"tldr\":\"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.\",\"ratings\":\"[7, 5, 6]\",\"confidence\":\"[2, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygxb2CqKm\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"hierarchical softmax\",\"tldr\":\"We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. \",\"ratings\":\"[6, 4, 7]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJl2E3AcF7\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hk4fpoA5Km\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"Attention, Learn to Solve Routing Problems!\",\"avg_rating\":6.3,\"avg_confidence\":5.0,\"topic\":\"learning\",\"tldr\":\"Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByxBFsRqYm\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyVU6s05K7\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"nlp\",\"tldr\":\"\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1xtAjR5tX\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.7,\"avg_confidence\":4.7,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJf7ts0cFm\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.7,\"avg_confidence\":3.3,\"topic\":\"non convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SklcFsAcKX\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.3,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByGuynAct7\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"generative models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkxxIs0qY7\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representation\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJfRpoA9YX\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syxt2jC5FX\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"neural processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkE6PjC9KX\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Complement Objective Training\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"optimisation\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyM7AiA5YX\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1lqZhRcFm\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.7,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1ebTsActm\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"gan\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SJeXSo09FQ\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.3,\"avg_confidence\":4.7,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx38iC5KX\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.7,\"avg_confidence\":3.3,\"topic\":\"cnn\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HklnzhR9YQ\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.3,\"avg_confidence\":3.3,\"topic\":\"multi agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJx7l309Fm\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzjBiR9t7\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.3,\"topic\":\"generative adversarial network\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1MB-3RcF7\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.3,\"avg_confidence\":4.3,\"topic\":\"\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HkgnpiR9Y7\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.2,\"topic\":\"deep rl\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=B1e7hs05Km\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.0,\"avg_confidence\":4.3,\"topic\":\"dynamic graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 5, 8]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyePrhR5KX\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SylPMnR9Ym\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyehMhC9Y7\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyzVb3CcFX\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.3,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Hygm8jC9FQ\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"relgan\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rJedV3R5tm\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"deep learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HyNA5iRcFQ\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.7,\"avg_confidence\":3.7,\"topic\":\"model based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Bke96sC5tm\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryf6Fs09YX\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.3,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rke4HiAcY7\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"multi agent reinforcement learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkl6As0cF7\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1fQSiCcYm\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.3,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SkNksoRctQ\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rkemqsC9Fm\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rk4Qso0cKm\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1xlvi0qYm\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=HJeQbnA5tm\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=H1xEtoRqtQ\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial example\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyxAb30cY7\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.3,\"topic\":\"meta learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJgK6iA5KX\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.3,\"avg_confidence\":3.7,\"topic\":\"bayesian nonparametric\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SygHGnRqK7\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.7,\"avg_confidence\":4.3,\"topic\":\"gans\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ryMQ5sRqYX\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.7,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkedwoC5t7\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=r1My6sR9tX\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.3,\"avg_confidence\":3.0,\"topic\":\"ai\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=S1erHoR5t7\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.3,\"avg_confidence\":4.3,\"topic\":\"reinforcement learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=SyNvti09KQ\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.3,\"avg_confidence\":3.7,\"topic\":\"direct feedback alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BkGiPoC5FX\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=rylIAsCqYm\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.7,\"avg_confidence\":3.0,\"topic\":\"generative deep neural networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=Syfz6sC9tQ\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.7,\"avg_confidence\":3.7,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=ByMVTsR5KQ\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional network\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlaYi05tm\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.7,\"avg_confidence\":3.3,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\",\"url\":\"https:\\/\\/openreview.net\\/forum?id=BJlgNh0qKQ\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "7d322548-436f-4dce-8033-8a7b2ab2d830",
       "layout": "IPY_MODEL_4babd21974c04b8580038f09dd84f120",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "ca6603ac713c41b3aa7ab8251b54c829": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 50,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "0218446c-3b59-4343-8658-0b155649268d",
       "layout": "IPY_MODEL_6df3f32fb5d24f84933bac98c4237235",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "cda88ae2bd604adbb10d0f49f1b6db58": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cf682439116a4aa79a61c0180bade574": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cf747af030174adf9a15074e55f21918": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cfe614e3906b4f19aa8740b8b1e9fc55": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 5000
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.66667,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.66667,\"avg_confidence\":3.33333,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Complement Objective Training\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.66667,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.33333,\"avg_confidence\":4.66667,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.33333,\"avg_confidence\":4.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.25,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.5,\"avg_confidence\":4.5,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 8]\",\"confidence\":\"[5, 4]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":6.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[8, 5]\",\"confidence\":\"[4, 4]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Learning Entropic Wasserstein Embeddings\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Embedding\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\",\"ratings\":\"[7, 7, 3]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"sgd\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\",\"ratings\":\"[6, 6, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Invariance and Inverse Stability under ReLU\",\"avg_rating\":6.5,\"avg_confidence\":3.5,\"topic\":\"deep neural networks\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\",\"ratings\":\"[6, 7]\",\"confidence\":\"[4, 3]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"avg_rating\":6.0,\"avg_confidence\":4.5,\"topic\":\"VAE\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\",\"ratings\":\"[4, 8]\",\"confidence\":\"[4, 5]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep learning\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"avg_rating\":4.66667,\"avg_confidence\":4.0,\"topic\":\"GAN\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"avg_rating\":6.33333,\"avg_confidence\":3.33333,\"topic\":\"dialogue\",\"tldr\":\"\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Reward Constrained Policy Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\",\"ratings\":\"[6, 7, 5]\",\"confidence\":\"[4, 2, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.66667,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"avg_rating\":6.0,\"avg_confidence\":3.66667,\"topic\":\"rotation equivariance\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\",\"ratings\":\"[7, 3, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Graph\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Adaptive Neural Trees\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"neural networks\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"Phrase-Based Attentions\",\"avg_rating\":5.0,\"avg_confidence\":4.66667,\"topic\":\"neural machine translation\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Deep Layers as Stochastic Solvers\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep networks\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[4, 5, 1]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Sparse rewards\",\"tldr\":\"\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"avg_rating\":6.33333,\"avg_confidence\":4.66667,\"topic\":\"domain adaptation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"crowdsourcing\",\"tldr\":\"\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"unsupervised learning\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\",\"ratings\":\"[5, 3, 9]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"imitation learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[8, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"relation representations\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"avg_rating\":5.33333,\"avg_confidence\":4.33333,\"topic\":\"Empirical Bayes\",\"tldr\":\"\",\"ratings\":\"[6, 3, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Feature-Wise Bias Amplification\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"bias\",\"tldr\":\"\",\"ratings\":\"[6, 7, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"avg_rating\":3.66667,\"avg_confidence\":4.0,\"topic\":\"Neural Response Generation\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\",\"ratings\":\"[3, 7, 1]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Sorting out Lipschitz function approximation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"agent evaluation\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Interpretable Continual Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.0,\"topic\":\"Interpretability\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \",\"ratings\":\"[5, 6]\",\"confidence\":\"[3, 3]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"Implicit Autoencoders\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Unsupervised Learning\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\",\"ratings\":\"[2, 7, 6]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"avg_rating\":4.33333,\"avg_confidence\":4.0,\"topic\":\"Hierarchical reinforcement learning\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_rating\":3.66667,\"avg_confidence\":3.33333,\"topic\":\"visualization\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"ratings\":\"[4, 3, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"avg_rating\":5.66667,\"avg_confidence\":4.33333,\"topic\":\"cross-lingual transfer learning\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"word embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"VAE\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"preconditioner\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\",\"ratings\":\"[8, 4, 7]\",\"confidence\":\"[5, 5, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Model quantization\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\",\"ratings\":\"[8, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"avg_rating\":5.5,\"avg_confidence\":4.5,\"topic\":\"neural program repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\",\"ratings\":\"[6, 5]\",\"confidence\":\"[4, 5]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"unsupervised learning\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \",\"ratings\":\"[7, 5, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"positive-unlabeled learning\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 3, 3]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"DEEP GRAPH TRANSLATION\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[2, 4, 4]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "defaultColumnWidth": 150,
        "forceFitColumns": false
       },
       "id": "dd337857-95b7-4941-bd4f-8aa163e43d10",
       "layout": "IPY_MODEL_c4c842032d6a485bb7b871cbbd5ef2e8",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "d0ef2382e1ce4b29ab6507db952e970b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d706b8f5dd0a4f15a492f3df689c0b8d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d744fa0ae1af44648690557a21de948d": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number"
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"avg_confidence\":4.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"avg_confidence\":3.33333,\"avg_rating\":5.66667,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"avg_confidence\":3.66667,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"avg_confidence\":2.66667,\"avg_rating\":7.0,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"avg_confidence\":4.0,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"avg_confidence\":2.0,\"avg_rating\":6.66667,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"avg_confidence\":4.66667,\"avg_rating\":5.33333,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"avg_confidence\":3.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"avg_confidence\":4.33333,\"avg_rating\":4.33333,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"avg_confidence\":3.25,\"avg_rating\":4.0,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"avg_confidence\":4.5,\"avg_rating\":6.5,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"avg_confidence\":4.0,\"avg_rating\":7.33333,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"avg_confidence\":4.33333,\"avg_rating\":5.0,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"avg_confidence\":4.0,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"avg_confidence\":3.66667,\"avg_rating\":4.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"avg_confidence\":4.0,\"avg_rating\":6.5,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"avg_confidence\":3.0,\"avg_rating\":5.0,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"avg_confidence\":3.5,\"avg_rating\":5.5,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"avg_confidence\":3.33333,\"avg_rating\":6.0,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"avg_confidence\":3.0,\"avg_rating\":5.33333,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"avg_confidence\":3.66667,\"avg_rating\":4.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"avg_confidence\":4.66667,\"avg_rating\":7.66667,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"avg_confidence\":3.0,\"avg_rating\":5.66667,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"avg_confidence\":3.0,\"avg_rating\":3.5,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"avg_confidence\":3.66667,\"avg_rating\":7.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"avg_confidence\":3.66667,\"avg_rating\":6.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"avg_confidence\":3.5,\"avg_rating\":6.5,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"avg_confidence\":4.5,\"avg_rating\":6.0,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"avg_confidence\":4.0,\"avg_rating\":4.66667,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"avg_confidence\":3.33333,\"avg_rating\":6.33333,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"avg_confidence\":3.0,\"avg_rating\":6.0,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"avg_confidence\":4.66667,\"avg_rating\":7.0,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"avg_confidence\":3.66667,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"avg_confidence\":3.33333,\"avg_rating\":7.0,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"avg_confidence\":4.66667,\"avg_rating\":5.0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"avg_confidence\":3.33333,\"avg_rating\":6.66667,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"avg_confidence\":4.0,\"avg_rating\":5.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"avg_confidence\":4.66667,\"avg_rating\":6.33333,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"avg_confidence\":4.0,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"avg_confidence\":4.0,\"avg_rating\":6.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"avg_confidence\":3.66667,\"avg_rating\":7.33333,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"avg_confidence\":4.33333,\"avg_rating\":4.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"avg_confidence\":4.33333,\"avg_rating\":5.33333,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"avg_confidence\":4.0,\"avg_rating\":3.66667,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"avg_confidence\":3.0,\"avg_rating\":6.0,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"avg_confidence\":3.0,\"avg_rating\":5.5,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"avg_confidence\":3.33333,\"avg_rating\":5.0,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"avg_confidence\":4.0,\"avg_rating\":4.33333,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"avg_confidence\":3.33333,\"avg_rating\":3.66667,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"avg_confidence\":4.33333,\"avg_rating\":5.66667,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"avg_confidence\":3.66667,\"avg_rating\":5.0,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"avg_confidence\":4.0,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"avg_confidence\":3.66667,\"avg_rating\":5.66667,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"avg_confidence\":4.0,\"avg_rating\":6.0,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"avg_confidence\":4.5,\"avg_rating\":5.5,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"avg_confidence\":4.33333,\"avg_rating\":6.33333,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"avg_confidence\":3.0,\"avg_rating\":7.0,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"avg_confidence\":3.66667,\"avg_rating\":5.33333,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"avg_confidence\":3.33333,\"avg_rating\":5.33333,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "6b7af821-8eca-4bc1-8085-87427766b1a9",
       "layout": "IPY_MODEL_98e9fd455eb249aa84334731682822ad",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "d85f788fc55e478c8361b5a72b3f8b54": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dd522c0fe65b40f3911e3987e17bfbdc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "de8136690474491b8ad3dfef034cfd7c": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        16
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "049b5b55-cb1c-48e1-89d8-d46f3df03f98",
       "layout": "IPY_MODEL_4b491a9d2c5a41148a45556b30e0dc5c",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "de983a2331894715be7e6b4d2d32742b": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "autoHeight": true,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "bc9aa706-17ea-438d-b156-51e6c14632cd",
       "layout": "IPY_MODEL_46f24c0f312542deab9b2c90c4b99ceb",
       "precision": 5,
       "show_toolbar": true
      }
     },
     "e11ce3fa9648432da3f6e7a730a111a3": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 5,
       "_row_styles": {},
       "_sort_ascending": false,
       "_sort_field": "ratings",
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "8f78fc69-5a3f-42bf-9bdd-e9fe78d74f8d",
       "layout": "IPY_MODEL_f2c17aeaff56454c80ae74784434cbbe",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "e51e07e38bbb4a5392a4e3cdf929ce0b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "edd30b293f40402aa8e5283a4158d893": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ee9804666c534f0d9234bb5005e01af2": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "index",
         "first_index": true,
         "id": "index",
         "index_display_text": "",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer"
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"index\":0,\"qgrid_unfiltered_index\":0,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[6, 6, 5]\",\"title\":\"State-Regularized Recurrent Networks\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\"},{\"index\":1,\"qgrid_unfiltered_index\":1,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\"},{\"index\":2,\"qgrid_unfiltered_index\":2,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 8, 7]\",\"title\":\"The Deep Weight Prior\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\"},{\"index\":3,\"qgrid_unfiltered_index\":3,\"confidence\":\"[2, 2, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\"},{\"index\":4,\"qgrid_unfiltered_index\":4,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Adversarial Information Factorization\",\"tldr\":\"Learn representations for images that factor out a single attribute.\"},{\"index\":5,\"qgrid_unfiltered_index\":5,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\"},{\"index\":6,\"qgrid_unfiltered_index\":6,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Attentive Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\"},{\"index\":7,\"qgrid_unfiltered_index\":7,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 7]\",\"title\":\"Complement Objective Training\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\"},{\"index\":8,\"qgrid_unfiltered_index\":8,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"tldr\":\"\"},{\"index\":9,\"qgrid_unfiltered_index\":9,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"tldr\":\"\"},{\"index\":10,\"qgrid_unfiltered_index\":10,\"confidence\":\"[2, 2, 2]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"tldr\":\"\"},{\"index\":11,\"qgrid_unfiltered_index\":11,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[9, 4, 7]\",\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\"},{\"index\":12,\"qgrid_unfiltered_index\":12,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[4, 7, 5]\",\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\"},{\"index\":13,\"qgrid_unfiltered_index\":13,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\"},{\"index\":14,\"qgrid_unfiltered_index\":14,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 6, 4]\",\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\"},{\"index\":15,\"qgrid_unfiltered_index\":15,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[5, 4, 4]\",\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"tldr\":\"\"},{\"index\":16,\"qgrid_unfiltered_index\":16,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \"},{\"index\":17,\"qgrid_unfiltered_index\":17,\"confidence\":\"[5, 4, 4]\",\"ratings\":\"[3, 3, 7]\",\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"tldr\":\"\"},{\"index\":18,\"qgrid_unfiltered_index\":18,\"confidence\":\"[2, 5, 2, 4]\",\"ratings\":\"[6, 2, 4, 4]\",\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\"},{\"index\":19,\"qgrid_unfiltered_index\":19,\"confidence\":\"[5, 4]\",\"ratings\":\"[5, 8]\",\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\"},{\"index\":20,\"qgrid_unfiltered_index\":20,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Learning what you can do before doing anything\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\"},{\"index\":21,\"qgrid_unfiltered_index\":21,\"confidence\":\"[5, 3, 1]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\"},{\"index\":22,\"qgrid_unfiltered_index\":22,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[7, 8, 7]\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\"},{\"index\":23,\"qgrid_unfiltered_index\":23,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 6, 4]\",\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\"},{\"index\":24,\"qgrid_unfiltered_index\":24,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 6]\",\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"tldr\":\"\"},{\"index\":25,\"qgrid_unfiltered_index\":25,\"confidence\":\"[4, 3, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\"},{\"index\":26,\"qgrid_unfiltered_index\":26,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"tldr\":\"\"},{\"index\":27,\"qgrid_unfiltered_index\":27,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 7, 6]\",\"title\":\"GO Gradient for Expectation-Based Objectives\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\"},{\"index\":28,\"qgrid_unfiltered_index\":28,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[2, 8, 6]\",\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\"},{\"index\":29,\"qgrid_unfiltered_index\":29,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 6]\",\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\"},{\"index\":30,\"qgrid_unfiltered_index\":30,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 8, 9]\",\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\"},{\"index\":31,\"qgrid_unfiltered_index\":31,\"confidence\":\"[5, 4, 3]\",\"ratings\":\"[8, 5, 6]\",\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\"},{\"index\":32,\"qgrid_unfiltered_index\":32,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 7, 6]\",\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\"},{\"index\":33,\"qgrid_unfiltered_index\":33,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\"},{\"index\":34,\"qgrid_unfiltered_index\":34,\"confidence\":\"[4, 4]\",\"ratings\":\"[8, 5]\",\"title\":\"Learning to Remember More with Less Memorization\",\"tldr\":\"\"},{\"index\":35,\"qgrid_unfiltered_index\":35,\"confidence\":\"[2, 3, 4]\",\"ratings\":\"[7, 5, 3]\",\"title\":\"Noisy Information Bottlenecks for Generalization\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\"},{\"index\":36,\"qgrid_unfiltered_index\":36,\"confidence\":\"[4, 3, 3, 4]\",\"ratings\":\"[5, 6, 6, 5]\",\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\"},{\"index\":37,\"qgrid_unfiltered_index\":37,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 4, 9]\",\"title\":\"The Problem of Model Completion\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\"},{\"index\":38,\"qgrid_unfiltered_index\":38,\"confidence\":\"[3, 4, 2]\",\"ratings\":\"[6, 7, 8]\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\"},{\"index\":39,\"qgrid_unfiltered_index\":39,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 4, 7]\",\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\"},{\"index\":40,\"qgrid_unfiltered_index\":40,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Probabilistic Federated Neural Matching\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\"},{\"index\":41,\"qgrid_unfiltered_index\":41,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 5, 5]\",\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"tldr\":\"\"},{\"index\":42,\"qgrid_unfiltered_index\":42,\"confidence\":\"[5, 3, 4]\",\"ratings\":\"[8, 5, 4]\",\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\"},{\"index\":43,\"qgrid_unfiltered_index\":43,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[4, 8, 5]\",\"title\":\"Unsupervised Learning via Meta-Learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\"},{\"index\":44,\"qgrid_unfiltered_index\":44,\"confidence\":\"[2, 4, 3]\",\"ratings\":\"[3, 6, 7]\",\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\"},{\"index\":45,\"qgrid_unfiltered_index\":45,\"confidence\":\"[4, 4, 5]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \"},{\"index\":46,\"qgrid_unfiltered_index\":46,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[4, 4, 5]\",\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"tldr\":\"\"},{\"index\":47,\"qgrid_unfiltered_index\":47,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[7, 7, 9]\",\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\"},{\"index\":48,\"qgrid_unfiltered_index\":48,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Generative Feature Matching Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\"},{\"index\":49,\"qgrid_unfiltered_index\":49,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 6, 6]\",\"title\":\"Adversarial Audio Synthesis\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\"},{\"index\":50,\"qgrid_unfiltered_index\":50,\"confidence\":\"[4, 2]\",\"ratings\":\"[4, 3]\",\"title\":\"Geometry of Deep Convolutional Networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\"},{\"index\":51,\"qgrid_unfiltered_index\":51,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[8, 7, 5]\",\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\"},{\"index\":52,\"qgrid_unfiltered_index\":52,\"confidence\":\"[4, 5, 2]\",\"ratings\":\"[4, 6, 6]\",\"title\":\"Identifying Bias in AI using Simulation\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \"},{\"index\":53,\"qgrid_unfiltered_index\":53,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[8, 6, 7]\",\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"tldr\":\"\"},{\"index\":54,\"qgrid_unfiltered_index\":54,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 7, 3]\",\"title\":\"Learning Entropic Wasserstein Embeddings\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\"},{\"index\":55,\"qgrid_unfiltered_index\":55,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[7, 7, 7]\",\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\"},{\"index\":56,\"qgrid_unfiltered_index\":56,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 6, 8]\",\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\"},{\"index\":57,\"qgrid_unfiltered_index\":57,\"confidence\":\"[4, 3]\",\"ratings\":\"[6, 7]\",\"title\":\"Invariance and Inverse Stability under ReLU\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\"},{\"index\":58,\"qgrid_unfiltered_index\":58,\"confidence\":\"[4, 5]\",\"ratings\":\"[4, 8]\",\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\"},{\"index\":59,\"qgrid_unfiltered_index\":59,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[9, 5, 6]\",\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\"},{\"index\":60,\"qgrid_unfiltered_index\":60,\"confidence\":\"[3, 4, 5]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\"},{\"index\":61,\"qgrid_unfiltered_index\":61,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[7, 7, 5]\",\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"tldr\":\"\"},{\"index\":62,\"qgrid_unfiltered_index\":62,\"confidence\":\"[4, 2, 3]\",\"ratings\":\"[6, 7, 5]\",\"title\":\"Reward Constrained Policy Optimization\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\"},{\"index\":63,\"qgrid_unfiltered_index\":63,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[8, 4, 9]\",\"title\":\"Invariant and Equivariant Graph Networks\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\"},{\"index\":64,\"qgrid_unfiltered_index\":64,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[7, 3, 8]\",\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\"},{\"index\":65,\"qgrid_unfiltered_index\":65,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\"},{\"index\":66,\"qgrid_unfiltered_index\":66,\"confidence\":\"[4, 2, 4]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \"},{\"index\":67,\"qgrid_unfiltered_index\":67,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[4, 5, 7]\",\"title\":\"Adaptive Neural Trees\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\"},{\"index\":68,\"qgrid_unfiltered_index\":68,\"confidence\":\"[4, 5, 5]\",\"ratings\":\"[5, 5, 5]\",\"title\":\"Phrase-Based Attentions\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\"},{\"index\":69,\"qgrid_unfiltered_index\":69,\"confidence\":\"[4, 5, 1]\",\"ratings\":\"[7, 5, 8]\",\"title\":\"Deep Layers as Stochastic Solvers\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\"},{\"index\":70,\"qgrid_unfiltered_index\":70,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[4, 6, 4]\",\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\"},{\"index\":71,\"qgrid_unfiltered_index\":71,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"tldr\":\"\"},{\"index\":72,\"qgrid_unfiltered_index\":72,\"confidence\":\"[5, 5, 4]\",\"ratings\":\"[6, 6, 7]\",\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\"},{\"index\":73,\"qgrid_unfiltered_index\":73,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"tldr\":\"\"},{\"index\":74,\"qgrid_unfiltered_index\":74,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 9]\",\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\"},{\"index\":75,\"qgrid_unfiltered_index\":75,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\"},{\"index\":76,\"qgrid_unfiltered_index\":76,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 6, 5]\",\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"tldr\":\"\"},{\"index\":77,\"qgrid_unfiltered_index\":77,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[8, 8, 6]\",\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\"},{\"index\":78,\"qgrid_unfiltered_index\":78,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[5, 5, 4]\",\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \"},{\"index\":79,\"qgrid_unfiltered_index\":79,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 3, 7]\",\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"tldr\":\"\"},{\"index\":80,\"qgrid_unfiltered_index\":80,\"confidence\":\"[4, 4, 3]\",\"ratings\":\"[6, 7, 4]\",\"title\":\"Feature-Wise Bias Amplification\",\"tldr\":\"\"},{\"index\":81,\"qgrid_unfiltered_index\":81,\"confidence\":\"[4, 3, 5]\",\"ratings\":\"[3, 7, 1]\",\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\"},{\"index\":82,\"qgrid_unfiltered_index\":82,\"confidence\":\"[3, 4, 4]\",\"ratings\":\"[7, 5, 4]\",\"title\":\"Sorting out Lipschitz function approximation\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\"},{\"index\":83,\"qgrid_unfiltered_index\":83,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[6, 6, 6]\",\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\"},{\"index\":84,\"qgrid_unfiltered_index\":84,\"confidence\":\"[3, 3]\",\"ratings\":\"[5, 6]\",\"title\":\"Interpretable Continual Learning\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \"},{\"index\":85,\"qgrid_unfiltered_index\":85,\"confidence\":\"[3, 4, 3]\",\"ratings\":\"[2, 7, 6]\",\"title\":\"Implicit Autoencoders\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\"},{\"index\":86,\"qgrid_unfiltered_index\":86,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[5, 3, 5]\",\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \"},{\"index\":87,\"qgrid_unfiltered_index\":87,\"confidence\":\"[4, 3, 3]\",\"ratings\":\"[4, 3, 4]\",\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\"},{\"index\":88,\"qgrid_unfiltered_index\":88,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[6, 5, 6]\",\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\"},{\"index\":89,\"qgrid_unfiltered_index\":89,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[6, 5, 4]\",\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\"},{\"index\":90,\"qgrid_unfiltered_index\":90,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[7, 6, 5]\",\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"tldr\":\"\"},{\"index\":91,\"qgrid_unfiltered_index\":91,\"confidence\":\"[5, 5, 3]\",\"ratings\":\"[8, 4, 7]\",\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\"},{\"index\":92,\"qgrid_unfiltered_index\":92,\"confidence\":\"[4, 3, 4]\",\"ratings\":\"[5, 7, 5]\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\"},{\"index\":93,\"qgrid_unfiltered_index\":93,\"confidence\":\"[4, 4, 4]\",\"ratings\":\"[8, 5, 5]\",\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\"},{\"index\":94,\"qgrid_unfiltered_index\":94,\"confidence\":\"[4, 5]\",\"ratings\":\"[6, 5]\",\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\"},{\"index\":95,\"qgrid_unfiltered_index\":95,\"confidence\":\"[3, 3, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\"},{\"index\":96,\"qgrid_unfiltered_index\":96,\"confidence\":\"[4, 5, 4]\",\"ratings\":\"[7, 5, 7]\",\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \"},{\"index\":97,\"qgrid_unfiltered_index\":97,\"confidence\":\"[3, 3, 3]\",\"ratings\":\"[7, 6, 8]\",\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\"},{\"index\":98,\"qgrid_unfiltered_index\":98,\"confidence\":\"[5, 3, 3]\",\"ratings\":\"[5, 6, 5]\",\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\"},{\"index\":99,\"qgrid_unfiltered_index\":99,\"confidence\":\"[2, 4, 4]\",\"ratings\":\"[5, 5, 6]\",\"title\":\"DEEP GRAPH TRANSLATION\",\"tldr\":\"\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        100
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "f55c3d1a-9583-4a14-a48b-0823cb70084e",
       "layout": "IPY_MODEL_96ac06f46af14caba212d3bab16e2639",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "f12d7b90a86143099fedc0de1143b21f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f17930a7acc04c47a95fb4eb20b0ec7f": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":0,\"qgrid_unfiltered_index\":0,\"title\":\"State-Regularized Recurrent Networks\",\"avg_rating\":5.66667,\"avg_confidence\":4.66667,\"topic\":\"recurrent network\",\"tldr\":\"We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.\",\"ratings\":\"[6, 6, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":1,\"qgrid_unfiltered_index\":1,\"title\":\"Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior\",\"avg_rating\":5.66667,\"avg_confidence\":3.33333,\"topic\":\"non-convex optimization\",\"tldr\":\"By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":2,\"qgrid_unfiltered_index\":2,\"title\":\"The Deep Weight Prior\",\"avg_rating\":6.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.\",\"ratings\":\"[4, 8, 7]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":3,\"qgrid_unfiltered_index\":3,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.66667,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\"},{\"Index\":4,\"qgrid_unfiltered_index\":4,\"title\":\"Adversarial Information Factorization\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"disentangled representations\",\"tldr\":\"Learn representations for images that factor out a single attribute.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":5,\"qgrid_unfiltered_index\":5,\"title\":\"From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Spline\",\"tldr\":\"Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":6,\"qgrid_unfiltered_index\":6,\"title\":\"Attentive Neural Processes\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"Neural Processes\",\"tldr\":\"A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":7,\"qgrid_unfiltered_index\":7,\"title\":\"Complement Objective Training\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":8,\"qgrid_unfiltered_index\":8,\"title\":\"Deep Frank-Wolfe For Neural Network Optimization\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":9,\"qgrid_unfiltered_index\":9,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":10,\"qgrid_unfiltered_index\":10,\"title\":\"Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality\",\"avg_rating\":6.66667,\"avg_confidence\":2.0,\"topic\":\"deep learning theory\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[2, 2, 2]\"},{\"Index\":11,\"qgrid_unfiltered_index\":11,\"title\":\"Learning Localized Generative Models for 3D Point Clouds via Graph Convolution\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"GAN\",\"tldr\":\"A GAN using graph convolution operations with dynamically computed graphs from hidden features\",\"ratings\":\"[9, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":12,\"qgrid_unfiltered_index\":12,\"title\":\"Domain Generalization via Invariant Representation under Domain-Class Dependency\",\"avg_rating\":5.33333,\"avg_confidence\":4.66667,\"topic\":\"domain generalization\",\"tldr\":\"Address the trade-off caused by the dependency of classes on domains in domain generalization\",\"ratings\":\"[4, 7, 5]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks\",\"avg_rating\":4.66667,\"avg_confidence\":3.33333,\"topic\":\"CNN\",\"tldr\":\"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\\\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":14,\"qgrid_unfiltered_index\":14,\"title\":\"Actor-Attention-Critic for Multi-Agent Reinforcement Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"multi-agent\",\"tldr\":\"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.\",\"ratings\":\"[6, 6, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":15,\"qgrid_unfiltered_index\":15,\"title\":\"MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 4, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":16,\"qgrid_unfiltered_index\":16,\"title\":\"Multi-objective training of Generative Adversarial Networks with multiple discriminators\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. \",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":17,\"qgrid_unfiltered_index\":17,\"title\":\"Recycling the discriminator for improving the inference mapping of GAN\",\"avg_rating\":4.33333,\"avg_confidence\":4.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[3, 3, 7]\",\"confidence\":\"[5, 4, 4]\"},{\"Index\":18,\"qgrid_unfiltered_index\":18,\"title\":\"Efficient Exploration through Bayesian Deep Q-Networks\",\"avg_rating\":4.0,\"avg_confidence\":3.25,\"topic\":\"Deep RL\",\"tldr\":\"Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound\",\"ratings\":\"[6, 2, 4, 4]\",\"confidence\":\"[2, 5, 2, 4]\"},{\"Index\":19,\"qgrid_unfiltered_index\":19,\"title\":\"DyRep: Learning Representations over Dynamic Graphs\",\"avg_rating\":6.5,\"avg_confidence\":4.5,\"topic\":\"Dynamic Graphs\",\"tldr\":\"Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.\",\"ratings\":\"[5, 8]\",\"confidence\":\"[5, 4]\"},{\"Index\":20,\"qgrid_unfiltered_index\":20,\"title\":\"Learning what you can do before doing anything\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"unsupervised learning\",\"tldr\":\"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":21,\"qgrid_unfiltered_index\":21,\"title\":\"Deep Imitative Models for Flexible Inference, Planning, and Control\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"imitation learning\",\"tldr\":\"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[5, 3, 1]\"},{\"Index\":22,\"qgrid_unfiltered_index\":22,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.33333,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":23,\"qgrid_unfiltered_index\":23,\"title\":\"FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE\",\"avg_rating\":5.0,\"avg_confidence\":4.33333,\"topic\":\"disentangled representation learning\",\"tldr\":\"We propose new model that can disentangle multiple dynamic factors in sequential data\",\"ratings\":\"[5, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":24,\"qgrid_unfiltered_index\":24,\"title\":\"RelGAN: Relational Generative Adversarial Networks for Text Generation\",\"avg_rating\":6.66667,\"avg_confidence\":4.0,\"topic\":\"RelGAN\",\"tldr\":\"\",\"ratings\":\"[8, 6, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":25,\"qgrid_unfiltered_index\":25,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\"},{\"Index\":26,\"qgrid_unfiltered_index\":26,\"title\":\"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning\",\"avg_rating\":4.66667,\"avg_confidence\":3.66667,\"topic\":\"model-based reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":27,\"qgrid_unfiltered_index\":27,\"title\":\"GO Gradient for Expectation-Based Objectives\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"generalized reparameterization gradient\",\"tldr\":\"a Rep-like gradient for non-reparameterizable continuous\\/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation\",\"ratings\":\"[6, 7, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":28,\"qgrid_unfiltered_index\":28,\"title\":\"Caveats for information bottleneck in deterministic scenarios\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"information bottleneck\",\"tldr\":\"Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.\",\"ratings\":\"[2, 8, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":29,\"qgrid_unfiltered_index\":29,\"title\":\"Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"Multi-agent Reinforcement Learning\",\"tldr\":\"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":30,\"qgrid_unfiltered_index\":30,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":31,\"qgrid_unfiltered_index\":31,\"title\":\"Fluctuation-dissipation relations for stochastic gradient descent\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"stochastic gradient descent\",\"tldr\":\"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.\",\"ratings\":\"[8, 5, 6]\",\"confidence\":\"[5, 4, 3]\"},{\"Index\":32,\"qgrid_unfiltered_index\":32,\"title\":\"Information Theoretic lower bounds on negative log likelihood\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"latent variable modeling\",\"tldr\":\"Use rate-distortion theory to bound how much a latent variable model can be improved\",\"ratings\":\"[5, 7, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":33,\"qgrid_unfiltered_index\":33,\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":34,\"qgrid_unfiltered_index\":34,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":6.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[8, 5]\",\"confidence\":\"[4, 4]\"},{\"Index\":35,\"qgrid_unfiltered_index\":35,\"title\":\"Noisy Information Bottlenecks for Generalization\",\"avg_rating\":5.0,\"avg_confidence\":3.0,\"topic\":\"information theory\",\"tldr\":\"We limit mutual information between parameters and data using noise to improve generalization in deep models.\",\"ratings\":\"[7, 5, 3]\",\"confidence\":\"[2, 3, 4]\"},{\"Index\":36,\"qgrid_unfiltered_index\":36,\"title\":\"Relational Forward Models for Multi-Agent Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.5,\"topic\":\"multi-agent reinforcement learning\",\"tldr\":\"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.\",\"ratings\":\"[5, 6, 6, 5]\",\"confidence\":\"[4, 3, 3, 4]\"},{\"Index\":37,\"qgrid_unfiltered_index\":37,\"title\":\"The Problem of Model Completion\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We study empirically how hard it is to recover missing parts of trained models\",\"ratings\":\"[4, 4, 9]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":38,\"qgrid_unfiltered_index\":38,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\"},{\"Index\":39,\"qgrid_unfiltered_index\":39,\"title\":\"AutoLoss: Learning Discrete Schedule for Alternate Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.33333,\"topic\":\"Meta Learning\",\"tldr\":\"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.\",\"ratings\":\"[7, 4, 7]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":40,\"qgrid_unfiltered_index\":40,\"title\":\"Probabilistic Federated Neural Matching\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bayesian nonparametrics\",\"tldr\":\"We propose a Bayesian nonparametric model for federated learning with neural networks.\",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":41,\"qgrid_unfiltered_index\":41,\"title\":\"Finding Mixed Nash Equilibria of Generative Adversarial Networks\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"GANs\",\"tldr\":\"\",\"ratings\":\"[4, 5, 5]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Formal Limitations on the Measurement of Mutual Information\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"mutual information\",\"tldr\":\"We give a theoretical analysis of the measurement and optimization of mutual information.\",\"ratings\":\"[8, 5, 4]\",\"confidence\":\"[5, 3, 4]\"},{\"Index\":43,\"qgrid_unfiltered_index\":43,\"title\":\"Unsupervised Learning via Meta-Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"unsupervised learning\",\"tldr\":\"An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.\",\"ratings\":\"[4, 8, 5]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":44,\"qgrid_unfiltered_index\":44,\"title\":\" The relativistic discriminator: a key element missing from standard GAN\",\"avg_rating\":5.33333,\"avg_confidence\":3.0,\"topic\":\"AI\",\"tldr\":\"Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.\",\"ratings\":\"[3, 6, 7]\",\"confidence\":\"[2, 4, 3]\"},{\"Index\":45,\"qgrid_unfiltered_index\":45,\"title\":\"Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"Reinforcement Learning\",\"tldr\":\"We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. \",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[4, 4, 5]\"},{\"Index\":46,\"qgrid_unfiltered_index\":46,\"title\":\"Efficient Convolutional Neural Network Training with Direct Feedback Alignment\",\"avg_rating\":4.33333,\"avg_confidence\":3.66667,\"topic\":\"Direct Feedback Alignment\",\"tldr\":\"\",\"ratings\":\"[4, 4, 5]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":47,\"qgrid_unfiltered_index\":47,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.66667,\"avg_confidence\":4.66667,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":48,\"qgrid_unfiltered_index\":48,\"title\":\"Generative Feature Matching Networks\",\"avg_rating\":5.66667,\"avg_confidence\":3.0,\"topic\":\"Generative Deep Neural Networks\",\"tldr\":\"A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":49,\"qgrid_unfiltered_index\":49,\"title\":\"Adversarial Audio Synthesis\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"audio\",\"tldr\":\"Learning to synthesize raw waveform audio with GANs\",\"ratings\":\"[5, 6, 6]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":50,\"qgrid_unfiltered_index\":50,\"title\":\"Geometry of Deep Convolutional Networks\",\"avg_rating\":3.5,\"avg_confidence\":3.0,\"topic\":\"convolutional networks\",\"tldr\":\"Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes\",\"ratings\":\"[4, 3]\",\"confidence\":\"[4, 2]\"},{\"Index\":51,\"qgrid_unfiltered_index\":51,\"title\":\"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"differentiable dynamic programming\",\"tldr\":\"Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE\",\"ratings\":\"[8, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":52,\"qgrid_unfiltered_index\":52,\"title\":\"Identifying Bias in AI using Simulation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"Bias\",\"tldr\":\"We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. \",\"ratings\":\"[4, 6, 6]\",\"confidence\":\"[4, 5, 2]\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":54,\"qgrid_unfiltered_index\":54,\"title\":\"Learning Entropic Wasserstein Embeddings\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Embedding\",\"tldr\":\"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.\",\"ratings\":\"[7, 7, 3]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":55,\"qgrid_unfiltered_index\":55,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.66667,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":56,\"qgrid_unfiltered_index\":56,\"title\":\"Quasi-hyperbolic momentum and Adam for deep learning\",\"avg_rating\":6.66667,\"avg_confidence\":3.66667,\"topic\":\"sgd\",\"tldr\":\"Mix plain SGD and momentum (or do something similar with Adam) for great profit.\",\"ratings\":\"[6, 6, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":57,\"qgrid_unfiltered_index\":57,\"title\":\"Invariance and Inverse Stability under ReLU\",\"avg_rating\":6.5,\"avg_confidence\":3.5,\"topic\":\"deep neural networks\",\"tldr\":\"We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.\",\"ratings\":\"[6, 7]\",\"confidence\":\"[4, 3]\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos\",\"avg_rating\":6.0,\"avg_confidence\":4.5,\"topic\":\"VAE\",\"tldr\":\"We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.\",\"ratings\":\"[4, 8]\",\"confidence\":\"[4, 5]\"},{\"Index\":59,\"qgrid_unfiltered_index\":59,\"title\":\"Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep learning\",\"tldr\":\"We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.\",\"ratings\":\"[9, 5, 6]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":60,\"qgrid_unfiltered_index\":60,\"title\":\"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs\",\"avg_rating\":4.66667,\"avg_confidence\":4.0,\"topic\":\"GAN\",\"tldr\":\"A statistical approach to compute sample likelihoods in Generative Adversarial Networks\",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[3, 4, 5]\"},{\"Index\":61,\"qgrid_unfiltered_index\":61,\"title\":\"DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder\",\"avg_rating\":6.33333,\"avg_confidence\":3.33333,\"topic\":\"dialogue\",\"tldr\":\"\",\"ratings\":\"[7, 7, 5]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":62,\"qgrid_unfiltered_index\":62,\"title\":\"Reward Constrained Policy Optimization\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"reinforcement learning\",\"tldr\":\"For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.\",\"ratings\":\"[6, 7, 5]\",\"confidence\":\"[4, 2, 3]\"},{\"Index\":63,\"qgrid_unfiltered_index\":63,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.66667,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":64,\"qgrid_unfiltered_index\":64,\"title\":\"A rotation-equivariant convolutional neural network model of primary visual cortex\",\"avg_rating\":6.0,\"avg_confidence\":3.66667,\"topic\":\"rotation equivariance\",\"tldr\":\"A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.\",\"ratings\":\"[7, 3, 8]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":65,\"qgrid_unfiltered_index\":65,\"title\":\"Combining Neural Networks with Personalized PageRank for Classification on Graphs\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Graph\",\"tldr\":\"Personalized propagation of neural predictions (PPNP) combines neural networks with personalized PageRank for semi-supervised classification on graphs.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":66,\"qgrid_unfiltered_index\":66,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.33333,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\"},{\"Index\":67,\"qgrid_unfiltered_index\":67,\"title\":\"Adaptive Neural Trees\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"neural networks\",\"tldr\":\"We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.\",\"ratings\":\"[4, 5, 7]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":68,\"qgrid_unfiltered_index\":68,\"title\":\"Phrase-Based Attentions\",\"avg_rating\":5.0,\"avg_confidence\":4.66667,\"topic\":\"neural machine translation\",\"tldr\":\"Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.\",\"ratings\":\"[5, 5, 5]\",\"confidence\":\"[4, 5, 5]\"},{\"Index\":69,\"qgrid_unfiltered_index\":69,\"title\":\"Deep Layers as Stochastic Solvers\",\"avg_rating\":6.66667,\"avg_confidence\":3.33333,\"topic\":\"deep networks\",\"tldr\":\"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[4, 5, 1]\"},{\"Index\":70,\"qgrid_unfiltered_index\":70,\"title\":\"TequilaGAN: How To Easily Identify GAN Samples\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"Generative Adversarial Networks\",\"tldr\":\"We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.\",\"ratings\":\"[4, 6, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"DHER: Hindsight Experience Replay for Dynamic Goals\",\"avg_rating\":5.33333,\"avg_confidence\":4.0,\"topic\":\"Sparse rewards\",\"tldr\":\"\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":72,\"qgrid_unfiltered_index\":72,\"title\":\"SPIGAN: Privileged Adversarial Learning from Simulation\",\"avg_rating\":6.33333,\"avg_confidence\":4.66667,\"topic\":\"domain adaptation\",\"tldr\":\"An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.\",\"ratings\":\"[6, 6, 7]\",\"confidence\":\"[5, 5, 4]\"},{\"Index\":73,\"qgrid_unfiltered_index\":73,\"title\":\"Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"crowdsourcing\",\"tldr\":\"\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Unsupervised Neural Multi-Document Abstractive Summarization of Reviews\",\"avg_rating\":5.66667,\"avg_confidence\":4.0,\"topic\":\"unsupervised learning\",\"tldr\":\"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.\",\"ratings\":\"[5, 3, 9]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":75,\"qgrid_unfiltered_index\":75,\"title\":\"What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"imitation learning\",\"tldr\":\"We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":76,\"qgrid_unfiltered_index\":76,\"title\":\"Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions\",\"avg_rating\":6.33333,\"avg_confidence\":4.0,\"topic\":\"optimization\",\"tldr\":\"\",\"ratings\":\"[8, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":77,\"qgrid_unfiltered_index\":77,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.33333,\"avg_confidence\":3.66667,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":78,\"qgrid_unfiltered_index\":78,\"title\":\"RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding\",\"avg_rating\":4.66667,\"avg_confidence\":4.33333,\"topic\":\"relation representations\",\"tldr\":\"We present a theoretically proven generative model of knowledge graph embedding. \",\"ratings\":\"[5, 5, 4]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks\",\"avg_rating\":5.33333,\"avg_confidence\":4.33333,\"topic\":\"Empirical Bayes\",\"tldr\":\"\",\"ratings\":\"[6, 3, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":80,\"qgrid_unfiltered_index\":80,\"title\":\"Feature-Wise Bias Amplification\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"bias\",\"tldr\":\"\",\"ratings\":\"[6, 7, 4]\",\"confidence\":\"[4, 4, 3]\"},{\"Index\":81,\"qgrid_unfiltered_index\":81,\"title\":\"Why Do Neural Response Generation Models Prefer Universal Replies?\",\"avg_rating\":3.66667,\"avg_confidence\":4.0,\"topic\":\"Neural Response Generation\",\"tldr\":\"Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.\",\"ratings\":\"[3, 7, 1]\",\"confidence\":\"[4, 3, 5]\"},{\"Index\":82,\"qgrid_unfiltered_index\":82,\"title\":\"Sorting out Lipschitz function approximation\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"deep learning\",\"tldr\":\"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.\",\"ratings\":\"[7, 5, 4]\",\"confidence\":\"[3, 4, 4]\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures\",\"avg_rating\":6.0,\"avg_confidence\":3.0,\"topic\":\"agent evaluation\",\"tldr\":\"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.\",\"ratings\":\"[6, 6, 6]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":84,\"qgrid_unfiltered_index\":84,\"title\":\"Interpretable Continual Learning\",\"avg_rating\":5.5,\"avg_confidence\":3.0,\"topic\":\"Interpretability\",\"tldr\":\"The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. \",\"ratings\":\"[5, 6]\",\"confidence\":\"[3, 3]\"},{\"Index\":85,\"qgrid_unfiltered_index\":85,\"title\":\"Implicit Autoencoders\",\"avg_rating\":5.0,\"avg_confidence\":3.33333,\"topic\":\"Unsupervised Learning\",\"tldr\":\"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.\",\"ratings\":\"[2, 7, 6]\",\"confidence\":\"[3, 4, 3]\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization\",\"avg_rating\":4.33333,\"avg_confidence\":4.0,\"topic\":\"Hierarchical reinforcement learning\",\"tldr\":\"This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. \",\"ratings\":\"[5, 3, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":87,\"qgrid_unfiltered_index\":87,\"title\":\"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae\",\"avg_rating\":3.66667,\"avg_confidence\":3.33333,\"topic\":\"visualization\",\"tldr\":\"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.\",\"ratings\":\"[4, 3, 4]\",\"confidence\":\"[4, 3, 3]\"},{\"Index\":88,\"qgrid_unfiltered_index\":88,\"title\":\"Zero-Resource Multilingual Model Transfer: Learning What to Share\",\"avg_rating\":5.66667,\"avg_confidence\":4.33333,\"topic\":\"cross-lingual transfer learning\",\"tldr\":\"A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.\",\"ratings\":\"[6, 5, 6]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":89,\"qgrid_unfiltered_index\":89,\"title\":\"Poincare Glove: Hyperbolic Word Embeddings\",\"avg_rating\":5.0,\"avg_confidence\":3.66667,\"topic\":\"word embeddings\",\"tldr\":\"We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.\",\"ratings\":\"[6, 5, 4]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":90,\"qgrid_unfiltered_index\":90,\"title\":\"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"VAE\",\"tldr\":\"\",\"ratings\":\"[7, 6, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":91,\"qgrid_unfiltered_index\":91,\"title\":\"Learning Preconditioner on Matrix Lie Group\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"preconditioner\",\"tldr\":\"We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.\",\"ratings\":\"[8, 4, 7]\",\"confidence\":\"[5, 5, 3]\"},{\"Index\":92,\"qgrid_unfiltered_index\":92,\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"avg_rating\":5.66667,\"avg_confidence\":3.66667,\"topic\":\"Inverse Reinforcement Learning\",\"tldr\":\"Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.\",\"ratings\":\"[5, 7, 5]\",\"confidence\":\"[4, 3, 4]\"},{\"Index\":93,\"qgrid_unfiltered_index\":93,\"title\":\"ProxQuant: Quantized Neural Networks via Proximal Operators\",\"avg_rating\":6.0,\"avg_confidence\":4.0,\"topic\":\"Model quantization\",\"tldr\":\"A principled framework for model quantization using the proximal gradient method.\",\"ratings\":\"[8, 5, 5]\",\"confidence\":\"[4, 4, 4]\"},{\"Index\":94,\"qgrid_unfiltered_index\":94,\"title\":\"Neural Program Repair by Jointly Learning to Localize and Repair\",\"avg_rating\":5.5,\"avg_confidence\":4.5,\"topic\":\"neural program repair\",\"tldr\":\"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs\",\"ratings\":\"[6, 5]\",\"confidence\":\"[4, 5]\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"Statistical Relational Learning\",\"tldr\":\"We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[3, 3, 4]\"},{\"Index\":96,\"qgrid_unfiltered_index\":96,\"title\":\"On Self Modulation for Generative Adversarial Networks\",\"avg_rating\":6.33333,\"avg_confidence\":4.33333,\"topic\":\"unsupervised learning\",\"tldr\":\"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. \",\"ratings\":\"[7, 5, 7]\",\"confidence\":\"[4, 5, 4]\"},{\"Index\":97,\"qgrid_unfiltered_index\":97,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\"},{\"Index\":98,\"qgrid_unfiltered_index\":98,\"title\":\"Classification from Positive, Unlabeled and Biased Negative Data\",\"avg_rating\":5.33333,\"avg_confidence\":3.66667,\"topic\":\"positive-unlabeled learning\",\"tldr\":\"This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.\",\"ratings\":\"[5, 6, 5]\",\"confidence\":\"[5, 3, 3]\"},{\"Index\":99,\"qgrid_unfiltered_index\":99,\"title\":\"DEEP GRAPH TRANSLATION\",\"avg_rating\":5.33333,\"avg_confidence\":3.33333,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[5, 5, 6]\",\"confidence\":\"[2, 4, 4]\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1561,
       "_row_styles": {},
       "_sort_ascending": true,
       "_sort_field": null,
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        16
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "3d50ee68-4c45-47e4-acf1-2c5330fe1ce3",
       "layout": "IPY_MODEL_17a77799e8bf455eb5ecde7857bde805",
       "precision": 5,
       "show_toolbar": false
      }
     },
     "f1bed599f635475abf93b8555409bb43": {
      "model_module": "qgrid",
      "model_module_version": "1.1.1",
      "model_name": "QgridModel",
      "state": {
       "_columns": {
        "Index": {
         "cssClass": "integer first-idx-col idx-col",
         "defaultSortAsc": true,
         "editable": true,
         "field": "Index",
         "first_index": true,
         "id": "Index",
         "index_display_text": "Index",
         "is_index": true,
         "level": 0,
         "minWidth": 30,
         "name": "Index",
         "position": 0,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": 50
        },
        "avg_confidence": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_confidence",
         "id": "avg_confidence",
         "minWidth": 30,
         "name": "avg_confidence",
         "position": 4,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "avg_rating": {
         "cssClass": "number",
         "defaultSortAsc": true,
         "editable": true,
         "field": "avg_rating",
         "id": "avg_rating",
         "minWidth": 30,
         "name": "avg_rating",
         "position": 3,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "number",
         "width": 50
        },
        "confidence": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "confidence",
         "id": "confidence",
         "minWidth": 30,
         "name": "confidence",
         "position": 8,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "qgrid_unfiltered_index": {
         "cssClass": "integer",
         "defaultSortAsc": true,
         "editable": true,
         "field": "qgrid_unfiltered_index",
         "id": "qgrid_unfiltered_index",
         "maxWidth": null,
         "minWidth": 30,
         "name": "qgrid_unfiltered_index",
         "position": 1,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "integer",
         "width": null
        },
        "ratings": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "ratings",
         "id": "ratings",
         "minWidth": 30,
         "name": "ratings",
         "position": 7,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 50
        },
        "title": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "title",
         "id": "title",
         "minWidth": 30,
         "name": "title",
         "position": 2,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string",
         "width": 500
        },
        "tldr": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "tldr",
         "id": "tldr",
         "minWidth": 30,
         "name": "tldr",
         "position": 6,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        },
        "topic": {
         "cssClass": "string",
         "defaultSortAsc": true,
         "editable": true,
         "field": "topic",
         "id": "topic",
         "minWidth": 30,
         "name": "topic",
         "position": 5,
         "resizable": true,
         "sortable": true,
         "toolTip": "",
         "type": "string"
        }
       },
       "_df_json": "{\"schema\": {\"fields\":[{\"name\":\"Index\",\"type\":\"integer\"},{\"name\":\"qgrid_unfiltered_index\",\"type\":\"integer\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"avg_rating\",\"type\":\"number\"},{\"name\":\"avg_confidence\",\"type\":\"number\"},{\"name\":\"topic\",\"type\":\"string\"},{\"name\":\"tldr\",\"type\":\"string\"},{\"name\":\"ratings\",\"type\":\"string\"},{\"name\":\"confidence\",\"type\":\"string\"},{\"name\":\"topic_qgrid_sort_column\",\"type\":\"string\"}],\"primaryKey\":[\"Index\"],\"pandas_version\":\"0.20.0\"}, \"data\": [{\"Index\":1017,\"qgrid_unfiltered_index\":1017,\"title\":\"Exploration by random distillation\",\"avg_rating\":8.7,\"avg_confidence\":4.3,\"topic\":\"reinforcement learning\",\"tldr\":\"A simple exploration bonus is introduced and achieves state of the art performance in 3 hard exploration Atari games.\",\"ratings\":\"[9, 10, 7]\",\"confidence\":\"[5, 4, 4]\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":648,\"qgrid_unfiltered_index\":648,\"title\":\"Benchmarking Neural Network Robustness to Common Corruptions and Perturbations\",\"avg_rating\":8.3,\"avg_confidence\":4.0,\"topic\":\"robustness\",\"tldr\":\"We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness\",\"ratings\":\"[7, 9, 9]\",\"confidence\":\"[3, 5, 4]\",\"topic_qgrid_sort_column\":\"robustness\"},{\"Index\":707,\"qgrid_unfiltered_index\":707,\"title\":\"Large Scale GAN Training for High Fidelity Natural Image Synthesis\",\"avg_rating\":8.3,\"avg_confidence\":3.7,\"topic\":\"GANs\",\"tldr\":\"GANs benefit from scaling up.\",\"ratings\":\"[7, 8, 10]\",\"confidence\":\"[3, 4, 4]\",\"topic_qgrid_sort_column\":\"GANs\"},{\"Index\":13,\"qgrid_unfiltered_index\":13,\"title\":\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\",\"avg_rating\":8.0,\"avg_confidence\":3.3,\"topic\":\"reinforcement learning\",\"tldr\":\"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.\",\"ratings\":\"[6, 10, 8]\",\"confidence\":\"[3, 4, 3]\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":950,\"qgrid_unfiltered_index\":950,\"title\":\"Slimmable Neural Networks\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"Slimmable neural networks\",\"tldr\":\"We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[4, 5, 4]\",\"topic_qgrid_sort_column\":\"Slimmable neural networks\"},{\"Index\":42,\"qgrid_unfiltered_index\":42,\"title\":\"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"music\",\"tldr\":\"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.\",\"ratings\":\"[8, 8, 8]\",\"confidence\":\"[5, 2, 4]\",\"topic_qgrid_sort_column\":\"music\"},{\"Index\":1304,\"qgrid_unfiltered_index\":1304,\"title\":\"ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"sparse recovery\",\"tldr\":\"\",\"ratings\":\"[10, 6, 8]\",\"confidence\":\"[5, 4, 4]\",\"topic_qgrid_sort_column\":\"sparse recovery\"},{\"Index\":1442,\"qgrid_unfiltered_index\":1442,\"title\":\"Posterior Attention Models for Sequence to Sequence Learning\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"posterior inference\",\"tldr\":\"Computing attention based on posterior distribution leads to more meaningful attention and better performance\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[5, 4, 4]\",\"topic_qgrid_sort_column\":\"posterior inference\"},{\"Index\":878,\"qgrid_unfiltered_index\":878,\"title\":\"GENERATING HIGH FIDELITY IMAGES WITH SUBSCALE PIXEL NETWORKS AND MULTIDIMENSIONAL UPSCALING\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"We show that autoregressive models can generate high fidelity images. \",\"ratings\":\"[10, 7, 7]\",\"confidence\":\"[5, 3, 3]\",\"topic_qgrid_sort_column\":\"None\"},{\"Index\":717,\"qgrid_unfiltered_index\":717,\"title\":\"Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks\",\"avg_rating\":8.0,\"avg_confidence\":3.7,\"topic\":\"Deep Learning\",\"tldr\":\"We introduce a new inductive bias that integrates tree structures in recurrent neural networks.\",\"ratings\":\"[9, 7, 8]\",\"confidence\":\"[4, 3, 4]\",\"topic_qgrid_sort_column\":\"Deep Learning\"},{\"Index\":1115,\"qgrid_unfiltered_index\":1115,\"title\":\"Temporal Difference Variational Auto-Encoder\",\"avg_rating\":8.0,\"avg_confidence\":4.3,\"topic\":\"generative models\",\"tldr\":\"Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.\",\"ratings\":\"[8, 9, 7]\",\"confidence\":\"[4, 4, 5]\",\"topic_qgrid_sort_column\":\"generative models\"},{\"Index\":1239,\"qgrid_unfiltered_index\":1239,\"title\":\"Supervised Community Detection with Line Graph Neural Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"community detection\",\"tldr\":\"We propose a novel graph neural network architecture based on the non-backtracking operator defined over edge adjacencies and demonstrate its effectiveness on community detection tasks on graphs.\",\"ratings\":\"[6, 9, 8]\",\"confidence\":\"[4, 4, 4]\",\"topic_qgrid_sort_column\":\"community detection\"},{\"Index\":762,\"qgrid_unfiltered_index\":762,\"title\":\"Learning Unsupervised Learning Rules\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"Meta-learning\",\"tldr\":\"We learn an unsupervised learning algorithm that produces useful representations from a set of supervised tasks. At test-time, we apply this algorithm to new tasks without any supervision and show performance comparable to a VAE.\",\"ratings\":\"[8, 7, 8]\",\"confidence\":\"[4, 3, 3]\",\"topic_qgrid_sort_column\":\"Meta-learning\"},{\"Index\":1330,\"qgrid_unfiltered_index\":1330,\"title\":\"Adaptive Input Representations for Neural Language Modeling\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Neural language modeling\",\"tldr\":\"Variable capacity input word embeddings and SOTA on WikiText-103, Billion Word benchmarks.\",\"ratings\":\"[7, 8, 8]\",\"confidence\":\"[4, 4, 4]\",\"topic_qgrid_sort_column\":\"Neural language modeling\"},{\"Index\":614,\"qgrid_unfiltered_index\":614,\"title\":\"Critical Learning Periods in Deep Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.3,\"topic\":\"Critical Period\",\"tldr\":\"Sensory deficits in early training phases can lead to irreversible performance loss in both artificial and neuronal networks, suggesting information phenomena as the common cause, and point to the importance of the initial transient and forgetting.\",\"ratings\":\"[9, 8, 6]\",\"confidence\":\"[4, 4, 5]\",\"topic_qgrid_sort_column\":\"Critical Period\"},{\"Index\":95,\"qgrid_unfiltered_index\":95,\"title\":\"A2BCD: Asynchronous Acceleration with Optimal Complexity\",\"avg_rating\":7.7,\"avg_confidence\":4.7,\"topic\":\"asynchronous\",\"tldr\":\"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 5, 5]\",\"topic_qgrid_sort_column\":\"asynchronous\"},{\"Index\":636,\"qgrid_unfiltered_index\":636,\"title\":\"Sparse Dictionary Learning by Dynamical Neural Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[6, 9, 8]\",\"confidence\":\"[4, 4, 4]\",\"topic_qgrid_sort_column\":\"None\"},{\"Index\":1154,\"qgrid_unfiltered_index\":1154,\"title\":\"Pay Less Attention with Lightweight and Dynamic Convolutions\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Deep learning\",\"tldr\":\"Dynamic lightweight convolutions are competitive to self-attention on language tasks.\",\"ratings\":\"[8, 7, 8]\",\"confidence\":\"[4, 4, 4]\",\"topic_qgrid_sort_column\":\"Deep learning\"},{\"Index\":450,\"qgrid_unfiltered_index\":450,\"title\":\"Identifying and Controlling Important Neurons in Neural Machine Translation\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"neural machine translation\",\"tldr\":\"Unsupervised methods for finding, analyzing, and controlling important neurons in NMT\",\"ratings\":\"[7, 10, 6]\",\"confidence\":\"[3, 3, 4]\",\"topic_qgrid_sort_column\":\"neural machine translation\"},{\"Index\":778,\"qgrid_unfiltered_index\":778,\"title\":\"Learning Robust Representations by Projecting Superficial Statistics Out\",\"avg_rating\":7.7,\"avg_confidence\":3.7,\"topic\":\"domain generalization\",\"tldr\":\"Building on previous work on domain generalization, we hope to produce a classifier that will generalize to previously unseen domains, even when domain identifiers are not available during training.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[4, 4, 3]\",\"topic_qgrid_sort_column\":\"domain generalization\"},{\"Index\":661,\"qgrid_unfiltered_index\":661,\"title\":\"KnockoffGAN: Generating Knockoffs for Feature Selection using Generative Adversarial Networks\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Knockoff model\",\"tldr\":\"\",\"ratings\":\"[6, 10, 7]\",\"confidence\":\"[4, 4, 4]\",\"topic_qgrid_sort_column\":\"Knockoff model\"},{\"Index\":1454,\"qgrid_unfiltered_index\":1454,\"title\":\"A Variational Inequality Perspective on Generative Adversarial Networks\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"optimization\",\"tldr\":\"We cast GANs in the variational inequality framework and import techniques from this literature to optimize GANs better; we give algorithmic extensions and empirically test their performance for training GANs.\",\"ratings\":\"[8, 8, 7]\",\"confidence\":\"[3, 3, 4]\",\"topic_qgrid_sort_column\":\"optimization\"},{\"Index\":353,\"qgrid_unfiltered_index\":353,\"title\":\"Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware\",\"avg_rating\":7.7,\"avg_confidence\":3.0,\"topic\":\"Trusted hardware\",\"tldr\":\"We accelerate secure DNN inference in trusted execution environments (by a factor 4x-20x) by selectively outsourcing the computation of linear layers to a faster yet untrusted co-processor.\",\"ratings\":\"[7, 7, 9]\",\"confidence\":\"[3, 2, 4]\",\"topic_qgrid_sort_column\":\"Trusted hardware\"},{\"Index\":1495,\"qgrid_unfiltered_index\":1495,\"title\":\"Composing Complex Skills by Learning Transition Policies with Proximity Reward Induction\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"reinforcement learning\",\"tldr\":\"Transition policies enable agents to execute learned skills smoothly to perform complex tasks.\",\"ratings\":\"[7, 9, 7]\",\"confidence\":\"[4, 4, 4]\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":276,\"qgrid_unfiltered_index\":276,\"title\":\"ON RANDOM DEEP AUTOENCODERS: EXACT ASYMPTOTIC ANALYSIS, PHASE TRANSITIONS, AND IMPLICATIONS TO TRAINING\",\"avg_rating\":7.7,\"avg_confidence\":4.0,\"topic\":\"Random Deep Autoencoders\",\"tldr\":\"We study the behavior of weight-tied multilayer vanilla autoencoders under the assumption of random weights. Via an exact characterization in the limit of large dimensions, our analysis reveals interesting phase transition phenomena.\",\"ratings\":\"[9, 6, 8]\",\"confidence\":\"[4, 4, 4]\",\"topic_qgrid_sort_column\":\"Random Deep Autoencoders\"},{\"Index\":255,\"qgrid_unfiltered_index\":255,\"title\":\"Smoothing the Geometry of Probabilistic Box Embeddings\",\"avg_rating\":7.7,\"avg_confidence\":3.3,\"topic\":\"embeddings\",\"tldr\":\"Improve hierarchical embedding models using kernel smoothing\",\"ratings\":\"[8, 8, 7]\",\"confidence\":\"[3, 4, 3]\",\"topic_qgrid_sort_column\":\"embeddings\"},{\"Index\":348,\"qgrid_unfiltered_index\":348,\"title\":\"Diffusion Scattering Transforms on Graphs\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"graph neural networks\",\"tldr\":\"Stability of scattering transform representations of graph data to deformations of the underlying graph support.\",\"ratings\":\"[9, 6]\",\"confidence\":\"[5, 3]\",\"topic_qgrid_sort_column\":\"graph neural networks\"},{\"Index\":83,\"qgrid_unfiltered_index\":83,\"title\":\"Learning to Remember More with Less Memorization\",\"avg_rating\":7.5,\"avg_confidence\":4.0,\"topic\":\"memory-augmented neural networks\",\"tldr\":\"\",\"ratings\":\"[7, 8]\",\"confidence\":\"[4, 4]\",\"topic_qgrid_sort_column\":\"memory-augmented neural networks\"},{\"Index\":662,\"qgrid_unfiltered_index\":662,\"title\":\"On the Minimal Supervision for Training Any Binary Classifier from Only Unlabeled Data\",\"avg_rating\":7.5,\"avg_confidence\":3.5,\"topic\":\"learning from only unlabeled data\",\"tldr\":\"Three class priors are all you need to train deep models from only U data, while any two should not be enough.\",\"ratings\":\"[8, 7]\",\"confidence\":\"[3, 4]\",\"topic_qgrid_sort_column\":\"learning from only unlabeled data\"},{\"Index\":861,\"qgrid_unfiltered_index\":861,\"title\":\"Diversity is All You Need: Learning Skills without a Reward Function\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"reinforcement learning\",\"tldr\":\"We propose an algorithm for learning useful skills without a reward function, and show how these skills can be used to solve downstream tasks.\",\"ratings\":\"[8, 7, 7]\",\"confidence\":\"[4, 3, 4]\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":1094,\"qgrid_unfiltered_index\":1094,\"title\":\"Gradient descent aligns the layers of deep linear networks\",\"avg_rating\":7.3,\"avg_confidence\":4.3,\"topic\":\"implicit regularization\",\"tldr\":\"\",\"ratings\":\"[7, 9, 6]\",\"confidence\":\"[4, 4, 5]\",\"topic_qgrid_sort_column\":\"implicit regularization\"},{\"Index\":79,\"qgrid_unfiltered_index\":79,\"title\":\"Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"autoencoders\",\"tldr\":\"We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.\",\"ratings\":\"[5, 8, 9]\",\"confidence\":\"[4, 3, 4]\",\"topic_qgrid_sort_column\":\"autoencoders\"},{\"Index\":997,\"qgrid_unfiltered_index\":997,\"title\":\"Efficient Training on Very Large Corpora via Gramian Estimation\",\"avg_rating\":7.3,\"avg_confidence\":2.7,\"topic\":\"similarity learning\",\"tldr\":\"We develop efficient methods to train neural embedding models with a dot-product structure, by reformulating the objective function in terms of generalized Gram matrices, and maintaining estimates of those matrices.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[4, 2, 2]\",\"topic_qgrid_sort_column\":\"similarity learning\"},{\"Index\":957,\"qgrid_unfiltered_index\":957,\"title\":\"ProMP: Proximal Meta-Policy Search\",\"avg_rating\":7.3,\"avg_confidence\":3.0,\"topic\":\"Meta-Reinforcement Learning\",\"tldr\":\"A novel and theoretically grounded meta-reinforcement learning algorithm\",\"ratings\":\"[6, 7, 9]\",\"confidence\":\"[3, 3, 3]\",\"topic_qgrid_sort_column\":\"Meta-Reinforcement Learning\"},{\"Index\":663,\"qgrid_unfiltered_index\":663,\"title\":\"Approximability of Discriminators Implies Diversity in GANs\",\"avg_rating\":7.3,\"avg_confidence\":2.7,\"topic\":\"Theory\",\"tldr\":\"GANs can in principle learn distributions sample-efficiently, if the discriminator class is compact and has strong distinguishing power against the particular generator class.\",\"ratings\":\"[8, 7, 7]\",\"confidence\":\"[2, 3, 3]\",\"topic_qgrid_sort_column\":\"Theory\"},{\"Index\":1204,\"qgrid_unfiltered_index\":1204,\"title\":\"Biologically-Plausible Learning Algorithms Can Scale to Large Datasets\",\"avg_rating\":7.3,\"avg_confidence\":4.3,\"topic\":\"biologically plausible learning algorithm\",\"tldr\":\"Biologically plausible learning algorithms, particularly sign-symmetry, works well on ImageNet\",\"ratings\":\"[9, 9, 4]\",\"confidence\":\"[5, 4, 4]\",\"topic_qgrid_sort_column\":\"biologically plausible learning algorithm\"},{\"Index\":71,\"qgrid_unfiltered_index\":71,\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"visual prediction\",\"tldr\":\"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \\\"bottleneck state\\\" predictions, which are useful for planning.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[3, 4, 5]\",\"topic_qgrid_sort_column\":\"visual prediction\"},{\"Index\":478,\"qgrid_unfiltered_index\":478,\"title\":\"Large-Scale Study of Curiosity-Driven Learning\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"exploration\",\"tldr\":\"An agent trained only with curiosity, and no extrinsic reward, does surprisingly well on 54 popular environments, including the suite of Atari games, Mario etc.\",\"ratings\":\"[6, 9, 7]\",\"confidence\":\"[4, 5, 3]\",\"topic_qgrid_sort_column\":\"exploration\"},{\"Index\":1540,\"qgrid_unfiltered_index\":1540,\"title\":\"Visualizing and Understanding Generative Adversarial Networks\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"GANs\",\"tldr\":\"GAN representations are examined in detail, and sets of representation units are found that control the generation of semantic concepts in the output.\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 4, 4]\",\"topic_qgrid_sort_column\":\"GANs\"},{\"Index\":124,\"qgrid_unfiltered_index\":124,\"title\":\"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"natural image model\",\"tldr\":\"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.\",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[4, 4, 3]\",\"topic_qgrid_sort_column\":\"natural image model\"},{\"Index\":548,\"qgrid_unfiltered_index\":548,\"title\":\"Evaluating Robustness of Neural Networks with Mixed Integer Programming\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"verification\",\"tldr\":\"We efficiently verify the robustness of deep neural models with over 100,000 ReLUs, certifying more samples than the state-of-the-art and finding more adversarial examples than a strong first-order attack.\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[5, 5, 1]\",\"topic_qgrid_sort_column\":\"verification\"},{\"Index\":1509,\"qgrid_unfiltered_index\":1509,\"title\":\"Label super-resolution networks\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"weakly supervised segmentation\",\"tldr\":\"Super-resolving coarse labels into pixel-level labels, applied to aerial imagery and medical scans.\",\"ratings\":\"[7, 6, 9]\",\"confidence\":\"[4, 4, 4]\",\"topic_qgrid_sort_column\":\"weakly supervised segmentation\"},{\"Index\":625,\"qgrid_unfiltered_index\":625,\"title\":\"Small nonlinearities in activation functions create bad local minima in neural networks\",\"avg_rating\":7.3,\"avg_confidence\":3.3,\"topic\":\"spurious local minima\",\"tldr\":\"We constructively prove that even the slightest nonlinear activation functions introduce spurious local minima, for general datasets and activation functions.\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 3, 4]\",\"topic_qgrid_sort_column\":\"spurious local minima\"},{\"Index\":1286,\"qgrid_unfiltered_index\":1286,\"title\":\"LanczosNet: Multi-Scale Deep Graph Convolutional Networks\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 5, 4]\",\"topic_qgrid_sort_column\":\"None\"},{\"Index\":1253,\"qgrid_unfiltered_index\":1253,\"title\":\"Kernel Change-point Detection with Auxiliary Deep Generative Models\",\"avg_rating\":7.3,\"avg_confidence\":3.7,\"topic\":\"deep kernel learning\",\"tldr\":\"In this paper, we propose KL-CPD, a novel kernel learning framework for time series CPD that optimizes a lower bound of test power via an auxiliary generative model as a surrogate to the abnormal distribution. \",\"ratings\":\"[8, 8, 6]\",\"confidence\":\"[3, 4, 4]\",\"topic_qgrid_sort_column\":\"deep kernel learning\"},{\"Index\":1252,\"qgrid_unfiltered_index\":1252,\"title\":\"Towards Metamerism via Foveated Style Transfer\",\"avg_rating\":7.3,\"avg_confidence\":4.3,\"topic\":\"Metamerism\",\"tldr\":\"We introduce a novel feed-forward framework to generate visual metamers\",\"ratings\":\"[7, 8, 7]\",\"confidence\":\"[4, 4, 5]\",\"topic_qgrid_sort_column\":\"Metamerism\"},{\"Index\":372,\"qgrid_unfiltered_index\":372,\"title\":\"Differentiable Learning-to-Normalize via Switchable Normalization\",\"avg_rating\":7.3,\"avg_confidence\":4.0,\"topic\":\"normalization\",\"tldr\":\"\",\"ratings\":\"[7, 7, 8]\",\"confidence\":\"[3, 4, 5]\",\"topic_qgrid_sort_column\":\"normalization\"},{\"Index\":197,\"qgrid_unfiltered_index\":197,\"title\":\"Learning a SAT Solver from Single-Bit Supervision\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"sat\",\"tldr\":\"We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 4, 3]\",\"topic_qgrid_sort_column\":\"sat\"},{\"Index\":242,\"qgrid_unfiltered_index\":242,\"title\":\"Auxiliary Variational MCMC\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"MCMC\",\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[5, 4, 4]\",\"topic_qgrid_sort_column\":\"MCMC\"},{\"Index\":929,\"qgrid_unfiltered_index\":929,\"title\":\"The Comparative Power of ReLU Networks and Polynomial Kernels in the Presence of Sparse Latent Structure\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"theory\",\"tldr\":\"Beyond-worst-case analysis of the representational power of  ReLU nets & polynomial kernels  -- in particular in the presence of sparse latent structure.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"topic_qgrid_sort_column\":\"theory\"},{\"Index\":794,\"qgrid_unfiltered_index\":794,\"title\":\"Neural network gradient-based learning of black-box function interfaces\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"neural networks\",\"tldr\":\"Training DNNs to interface w\\\\ black box functions w\\\\o intermediate labels by using an estimator sub-network that can be replaced with the black box after training\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"topic_qgrid_sort_column\":\"neural networks\"},{\"Index\":143,\"qgrid_unfiltered_index\":143,\"title\":\"On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Quantized Neural Networks\",\"tldr\":\"This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[3, 3, 3]\",\"topic_qgrid_sort_column\":\"Quantized Neural Networks\"},{\"Index\":304,\"qgrid_unfiltered_index\":304,\"title\":\"Deep, Skinny Neural Networks are not Universal Approximators\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"neural network\",\"tldr\":\"This paper proves that skinny neural networks cannot approximate certain functions, no matter how deep they are.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[4, 4, 4]\",\"topic_qgrid_sort_column\":\"neural network\"},{\"Index\":345,\"qgrid_unfiltered_index\":345,\"title\":\"DARTS: Differentiable Architecture Search\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"deep learning\",\"tldr\":\"We propose a differentiable architecture search algorithm for both convolutional and recurrent networks, achieving competitive performance with the state of the art using orders of magnitude less computation resources.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[2, 5, 3]\",\"topic_qgrid_sort_column\":\"deep learning\"},{\"Index\":361,\"qgrid_unfiltered_index\":361,\"title\":\"ADVERSARIAL DOMAIN ADAPTATION FOR STABLE BRAIN-MACHINE INTERFACES\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"Brain-Machine Interfaces\",\"tldr\":\"We implement an adversarial domain adaptation network to stabilize a fixed Brain-Machine Interface against gradual changes in the recorded neural signals.\",\"ratings\":\"[9, 5, 7]\",\"confidence\":\"[4, 3, 5]\",\"topic_qgrid_sort_column\":\"Brain-Machine Interfaces\"},{\"Index\":86,\"qgrid_unfiltered_index\":86,\"title\":\"Robustness May Be at Odds with Accuracy\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"adversarial examples\",\"tldr\":\"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 2]\",\"topic_qgrid_sort_column\":\"adversarial examples\"},{\"Index\":846,\"qgrid_unfiltered_index\":846,\"title\":\"The effects of neural resource constraints on early visual representations \",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"visual system\",\"tldr\":\"We reproduced neural representations found in biological visual systems by simulating their neural resource constraints in a deep convolutional model.\",\"ratings\":\"[5, 8, 8]\",\"confidence\":\"[5, 5, 3]\",\"topic_qgrid_sort_column\":\"visual system\"},{\"Index\":814,\"qgrid_unfiltered_index\":814,\"title\":\"Wizard of Wikipedia: Knowledge-Powered Conversational Agents\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"dialogue\",\"tldr\":\"We build knowledgeable conversational agents by conditioning on Wikipedia + a new supervised task.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 5, 4]\",\"topic_qgrid_sort_column\":\"dialogue\"},{\"Index\":74,\"qgrid_unfiltered_index\":74,\"title\":\"Detecting Egregious Responses in Neural Sequence-to-sequence Models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deep Learning\",\"tldr\":\"This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 3, 2]\",\"topic_qgrid_sort_column\":\"Deep Learning\"},{\"Index\":383,\"qgrid_unfiltered_index\":383,\"title\":\"An analytic theory of generalization dynamics and transfer learning in deep linear networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Generalization\",\"tldr\":\"We provide many insights into neural network generalization from the theoretically tractable linear case.\",\"ratings\":\"[8, 7, 6]\",\"confidence\":\"[4, 4, 3]\",\"topic_qgrid_sort_column\":\"Generalization\"},{\"Index\":768,\"qgrid_unfiltered_index\":768,\"title\":\"How Important is a Neuron\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"attribution\",\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 2, 5]\",\"topic_qgrid_sort_column\":\"attribution\"},{\"Index\":110,\"qgrid_unfiltered_index\":110,\"title\":\"Invariant and Equivariant Graph Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.7,\"topic\":\"graph learning\",\"tldr\":\"The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.\",\"ratings\":\"[8, 4, 9]\",\"confidence\":\"[5, 5, 4]\",\"topic_qgrid_sort_column\":\"graph learning\"},{\"Index\":748,\"qgrid_unfiltered_index\":748,\"title\":\"Deep Learning 3D Shapes Using Alt-az Anisotropic 2-Sphere Convolution\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"Spherical Convolution\",\"tldr\":\"A method for applying deep learning to 3D surfaces using their spherical descriptors and alt-az anisotropic convolution on 2-sphere.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[3, 5, 5]\",\"topic_qgrid_sort_column\":\"Spherical Convolution\"},{\"Index\":527,\"qgrid_unfiltered_index\":527,\"title\":\"Near-Optimal Representation Learning for Hierarchical Reinforcement Learning\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"representation hierarchy reinforcement learning\",\"tldr\":\"We translate a bound on sub-optimality of representations to a practical training objective in the context of hierarchical reinforcement learning.\",\"ratings\":\"[6, 6, 9]\",\"confidence\":\"[3, 5, 5]\",\"topic_qgrid_sort_column\":\"representation hierarchy reinforcement learning\"},{\"Index\":100,\"qgrid_unfiltered_index\":100,\"title\":\"Towards Robust, Locally Linear Deep Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[4, 3, 4]\",\"topic_qgrid_sort_column\":\"None\"},{\"Index\":102,\"qgrid_unfiltered_index\":102,\"title\":\"Relaxed Quantization for Discretized Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Quantization\",\"tldr\":\"We introduce a technique that allows for gradient based training of quantized neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 3, 4]\",\"topic_qgrid_sort_column\":\"Quantization\"},{\"Index\":706,\"qgrid_unfiltered_index\":706,\"title\":\"Riemannian Adaptive Optimization Methods\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"Riemannian optimization\",\"tldr\":\"Adapting Adam, Amsgrad, Adagrad to Riemannian manifolds. \",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 5, 4]\",\"topic_qgrid_sort_column\":\"Riemannian optimization\"},{\"Index\":666,\"qgrid_unfiltered_index\":666,\"title\":\"Deep Graph Infomax\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Unsupervised Learning\",\"tldr\":\"A new method for unsupervised representation learning on graphs, relying on maximizing mutual information between local and global representations in a graph. State-of-the-art results, competitive with supervised learning.\",\"ratings\":\"[7, 9, 5]\",\"confidence\":\"[3, 4, 4]\",\"topic_qgrid_sort_column\":\"Unsupervised Learning\"},{\"Index\":665,\"qgrid_unfiltered_index\":665,\"title\":\"SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"neural network pruning\",\"tldr\":\"We present a new approach, SNIP, that is simple, versatile and interpretable; it prunes irrelevant connections for a given task at single-shot prior to training and is applicable to a variety of neural network models without modifications.\",\"ratings\":\"[6, 6, 9]\",\"confidence\":\"[5, 4, 4]\",\"topic_qgrid_sort_column\":\"neural network pruning\"},{\"Index\":642,\"qgrid_unfiltered_index\":642,\"title\":\"Greedy Attack and Gumbel Attack: Generating Adversarial Examples for Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"Adversarial Examples\",\"tldr\":\"We develop two methods for generating adversarial examples on discrete data under a probabilistic framework.\",\"ratings\":\"[6, 8, 7]\",\"confidence\":\"[4, 2, 4]\",\"topic_qgrid_sort_column\":\"Adversarial Examples\"},{\"Index\":113,\"qgrid_unfiltered_index\":113,\"title\":\"Meta-Learning Probabilistic Inference for Prediction\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"probabilistic models\",\"tldr\":\"Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   \",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 2, 4]\",\"topic_qgrid_sort_column\":\"probabilistic models\"},{\"Index\":1559,\"qgrid_unfiltered_index\":1559,\"title\":\"Learning sparse relational transition models\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Deictic reference\",\"tldr\":\"A new approach that learns a representation for describing transition models in complex uncertaindomains using relational rules. \",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 2, 3]\",\"topic_qgrid_sort_column\":\"Deictic reference\"},{\"Index\":921,\"qgrid_unfiltered_index\":921,\"title\":\"How Powerful are Graph Neural Networks?\",\"avg_rating\":7.0,\"avg_confidence\":5.0,\"topic\":\"graph neural networks\",\"tldr\":\"We develop theoretical foundations for expressive power of GNNs and design a provably most powerful GNN.\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[5, 5, 5]\",\"topic_qgrid_sort_column\":\"graph neural networks\"},{\"Index\":1280,\"qgrid_unfiltered_index\":1280,\"title\":\"Lagging Inference Networks and Posterior Collapse in Variational Autoencoders\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"variational autoencoders\",\"tldr\":\"To address posterior collapse in VAEs, we propose a simple yet effective training algorithm that aggressively optimizes inference network with more updates\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[4, 4, 4]\",\"topic_qgrid_sort_column\":\"variational autoencoders\"},{\"Index\":1025,\"qgrid_unfiltered_index\":1025,\"title\":\"Feature Intertwiners\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"feature learning\",\"tldr\":\"A feature intertwiner module to leverage features from one accurate set to help the learning of another less reliable set.\",\"ratings\":\"[7, 5, 9]\",\"confidence\":\"[3, 4, 4]\",\"topic_qgrid_sort_column\":\"feature learning\"},{\"Index\":1108,\"qgrid_unfiltered_index\":1108,\"title\":\"Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word Vectors\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"word vectors\",\"tldr\":\"Max-pooled word vectors with fuzzy Jaccard set similarity are an extremely competitive baseline for semantic similarity; we propose a simple dynamic variant that performs even better.\",\"ratings\":\"[8, 8, 5]\",\"confidence\":\"[3, 4, 3]\",\"topic_qgrid_sort_column\":\"word vectors\"},{\"Index\":1103,\"qgrid_unfiltered_index\":1103,\"title\":\"The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"Neuro-Symbolic Representations\",\"tldr\":\"We present a Neuro-Symbolic Concept Learner to learn visual concepts, words, and semantic parsing of sentences without explicit annotations for any of them. \",\"ratings\":\"[7, 5, 9]\",\"confidence\":\"[4, 4, 5]\",\"topic_qgrid_sort_column\":\"Neuro-Symbolic Representations\"},{\"Index\":53,\"qgrid_unfiltered_index\":53,\"title\":\"CoT: Cooperative Training for Generative Modeling of Discrete Data\",\"avg_rating\":7.0,\"avg_confidence\":2.7,\"topic\":\"Generative Models\",\"tldr\":\"We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[2, 2, 4]\",\"topic_qgrid_sort_column\":\"Generative Models\"},{\"Index\":1180,\"qgrid_unfiltered_index\":1180,\"title\":\"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"Neural networks\",\"tldr\":\"Feedforward neural networks that can have weights pruned after training could have had the same weights pruned before training\",\"ratings\":\"[5, 8, 8]\",\"confidence\":\"[4, 4, 4]\",\"topic_qgrid_sort_column\":\"Neural networks\"},{\"Index\":1077,\"qgrid_unfiltered_index\":1077,\"title\":\"Local SGD Converges Fast and Communicates Little\",\"avg_rating\":7.0,\"avg_confidence\":4.7,\"topic\":\"optimization\",\"tldr\":\"We prove that parallel local SGD achieves linear speedup with much lesser communication than parallel mini-batch SGD.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[5, 5, 4]\",\"topic_qgrid_sort_column\":\"optimization\"},{\"Index\":1484,\"qgrid_unfiltered_index\":1484,\"title\":\"Learning to Screen for Fast Softmax  Inference on Large Vocabulary Neural Networks\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"fast inference\",\"tldr\":\"\",\"ratings\":\"[7, 6, 8]\",\"confidence\":\"[4, 3, 4]\",\"topic_qgrid_sort_column\":\"fast inference\"},{\"Index\":1063,\"qgrid_unfiltered_index\":1063,\"title\":\"ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"text-to-speech\",\"tldr\":\"\",\"ratings\":\"[9, 5, 7]\",\"confidence\":\"[4, 3, 4]\",\"topic_qgrid_sort_column\":\"text-to-speech\"},{\"Index\":58,\"qgrid_unfiltered_index\":58,\"title\":\"Unsupervised Learning of the Set of Local Maxima\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"None\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[3, 3, 4]\",\"topic_qgrid_sort_column\":\"None\"},{\"Index\":1232,\"qgrid_unfiltered_index\":1232,\"title\":\"Learning Neural PDE Solvers with Convergence Guarantees\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"Partial differential equation\",\"tldr\":\"We learn a fast neural solver for PDEs that has convergence guarantees.\",\"ratings\":\"[7, 8, 6]\",\"confidence\":\"[4, 4, 3]\",\"topic_qgrid_sort_column\":\"Partial differential equation\"},{\"Index\":1138,\"qgrid_unfiltered_index\":1138,\"title\":\"Learning Implicitly Recurrent CNNs Through Parameter Sharing\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"deep learning\",\"tldr\":\"We propose a method that enables CNN folding to create recurrent connections\",\"ratings\":\"[8, 7, 6]\",\"confidence\":\"[4, 3, 4]\",\"topic_qgrid_sort_column\":\"deep learning\"},{\"Index\":1268,\"qgrid_unfiltered_index\":1268,\"title\":\"Improving the Differentiable Neural Computer Through Memory Masking, De-allocation, and Link Distribution Sharpness Control\",\"avg_rating\":7.0,\"avg_confidence\":5.0,\"topic\":\"rnn\",\"tldr\":\"\",\"ratings\":\"[8, 6, 7]\",\"confidence\":\"[5, 5, 5]\",\"topic_qgrid_sort_column\":\"rnn\"},{\"Index\":1119,\"qgrid_unfiltered_index\":1119,\"title\":\"What do you learn from context? Probing for sentence structure in contextualized word representations\",\"avg_rating\":7.0,\"avg_confidence\":4.0,\"topic\":\"natural language processing\",\"tldr\":\"We probe for sentence structure in ELMo and related contextual embedding models. We find existing models efficiently encode syntax and show evidence of long-range dependencies, but only offer small improvements on semantic tasks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 4, 4]\",\"topic_qgrid_sort_column\":\"natural language processing\"},{\"Index\":1020,\"qgrid_unfiltered_index\":1020,\"title\":\"Scalable Reversible Generative Models with Free-form Continuous Dynamics\",\"avg_rating\":7.0,\"avg_confidence\":3.7,\"topic\":\"generative models\",\"tldr\":\"We use continuous time dynamics to define a generative model with exact likelihoods and efficient sampling that is parameterized by unrestricted neural networks.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[4, 4, 3]\",\"topic_qgrid_sort_column\":\"generative models\"},{\"Index\":1530,\"qgrid_unfiltered_index\":1530,\"title\":\"Global-to-local Memory Pointer Networks for Task-Oriented Dialogue\",\"avg_rating\":7.0,\"avg_confidence\":2.3,\"topic\":\"pointer networks\",\"tldr\":\"We propose a global memory encoder and a global memory decoder that share an external knowledge to strengthen task-oriented dialogue generation via sketch responses and pointer networks. \",\"ratings\":\"[8, 8, 5]\",\"confidence\":\"[2, 2, 3]\",\"topic_qgrid_sort_column\":\"pointer networks\"},{\"Index\":949,\"qgrid_unfiltered_index\":949,\"title\":\"Learning Self-Imitating Diverse Policies\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"Reinforcement-learning\",\"tldr\":\"Policy optimization by using past good rollouts from the agent; learning shaped rewards via divergence minimization; SVPG with JS-kernel for population-based exploration.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[3, 2, 4]\",\"topic_qgrid_sort_column\":\"Reinforcement-learning\"},{\"Index\":1414,\"qgrid_unfiltered_index\":1414,\"title\":\"GANSynth: Adversarial Neural Audio Synthesis\",\"avg_rating\":7.0,\"avg_confidence\":3.3,\"topic\":\"GAN\",\"tldr\":\"High-quality audio synthesis with GANs\",\"ratings\":\"[6, 7, 8]\",\"confidence\":\"[3, 4, 3]\",\"topic_qgrid_sort_column\":\"GAN\"},{\"Index\":1337,\"qgrid_unfiltered_index\":1337,\"title\":\"Learning to Navigate the Web\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"navigating web pages\",\"tldr\":\"We train reinforcement learning policies using reward augmentation, curriculum learning, and meta-learning  to successfully navigate web pages.\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"topic_qgrid_sort_column\":\"navigating web pages\"},{\"Index\":999,\"qgrid_unfiltered_index\":999,\"title\":\"Unsupervised Domain Adaptation for Distance Metric Learning\",\"avg_rating\":7.0,\"avg_confidence\":4.3,\"topic\":\"domain adaptation\",\"tldr\":\"A new theory of unsupervised domain adaptation for distance metric learning and its application to face recognition across diverse ethnicity variations.\",\"ratings\":\"[8, 5, 8]\",\"confidence\":\"[5, 4, 4]\",\"topic_qgrid_sort_column\":\"domain adaptation\"},{\"Index\":1313,\"qgrid_unfiltered_index\":1313,\"title\":\"Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based RL\",\"avg_rating\":7.0,\"avg_confidence\":3.0,\"topic\":\"meta-learning\",\"tldr\":\"\",\"ratings\":\"[7, 7, 7]\",\"confidence\":\"[3, 3, 3]\",\"topic_qgrid_sort_column\":\"meta-learning\"},{\"Index\":493,\"qgrid_unfiltered_index\":493,\"title\":\"Visual Explanation by Interpretation: Improving Visual Feedback Capabilities of Deep Neural Networks\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"model explanation\",\"tldr\":\"Interpretation by Identifying model-learned features that serve as indicators for the task of interest. Explain model decisions by highlighting the response of these features in test data. Evaluate explanations objectively with a controlled dataset.\",\"ratings\":\"[8, 5, 7]\",\"confidence\":\"[4, 4, 3]\",\"topic_qgrid_sort_column\":\"model explanation\"},{\"Index\":502,\"qgrid_unfiltered_index\":502,\"title\":\"Woulda, Coulda, Shoulda: Counterfactually-Guided Policy Search\",\"avg_rating\":6.7,\"avg_confidence\":2.7,\"topic\":\"reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[6, 7, 7]\",\"confidence\":\"[2, 3, 3]\",\"topic_qgrid_sort_column\":\"reinforcement learning\"},{\"Index\":422,\"qgrid_unfiltered_index\":422,\"title\":\"Sample Efficient Adaptive Text-to-Speech\",\"avg_rating\":6.7,\"avg_confidence\":4.3,\"topic\":\"few shot\",\"tldr\":\"Sample efficient algorithms to adapt a text-to-speech model to a new voice style with the state-of-the-art performance.\",\"ratings\":\"[7, 7, 6]\",\"confidence\":\"[4, 4, 5]\",\"topic_qgrid_sort_column\":\"few shot\"},{\"Index\":410,\"qgrid_unfiltered_index\":410,\"title\":\"Analysis of Quantized Deep Networks\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"weight quantization\",\"tldr\":\"\",\"ratings\":\"[6, 7, 7]\",\"confidence\":\"[4, 4, 4]\",\"topic_qgrid_sort_column\":\"weight quantization\"},{\"Index\":1431,\"qgrid_unfiltered_index\":1431,\"title\":\"K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning\",\"avg_rating\":6.7,\"avg_confidence\":4.0,\"topic\":\"deep learning\",\"tldr\":\"\",\"ratings\":\"[7, 5, 8]\",\"confidence\":\"[5, 3, 4]\",\"topic_qgrid_sort_column\":\"deep learning\"},{\"Index\":509,\"qgrid_unfiltered_index\":509,\"title\":\"EMI: Exploration with Mutual Information Maximizing State and Action Embeddings\",\"avg_rating\":6.7,\"avg_confidence\":3.7,\"topic\":\"reinforcement learning\",\"tldr\":\"\",\"ratings\":\"[6, 7, 7]\",\"confidence\":\"[4, 4, 3]\",\"topic_qgrid_sort_column\":\"reinforcement learning\"}]}",
       "_df_range": [
        0,
        100
       ],
       "_editable_rows": {},
       "_index_col_name": "qgrid_unfiltered_index",
       "_interval_columns": [],
       "_model_module_version": "1.1.1",
       "_multi_index": false,
       "_row_count": 1560,
       "_row_styles": {},
       "_sort_ascending": false,
       "_sort_field": "avg_rating",
       "_view_module_version": "1.1.1",
       "_viewport_range": [
        0,
        16
       ],
       "grid_options": {
        "autoEdit": false,
        "boldIndex": true,
        "defaultColumnWidth": 150,
        "editable": true,
        "enableColumnReorder": false,
        "enableTextSelectionOnCells": true,
        "explicitInitialization": true,
        "filterable": true,
        "forceFitColumns": true,
        "fullWidthRows": true,
        "highlightSelectedCell": false,
        "highlightSelectedRow": true,
        "maxVisibleRows": 15,
        "minVisibleRows": 8,
        "rowHeight": 28,
        "sortable": true,
        "syncColumnCellResize": true
       },
       "id": "dd1e0002-679b-49e9-ac89-8b3183d5f76e",
       "layout": "IPY_MODEL_d0ef2382e1ce4b29ab6507db952e970b",
       "precision": 1,
       "show_toolbar": false
      }
     },
     "f2937727cad843049f7d4e8f4cdda09f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f2c17aeaff56454c80ae74784434cbbe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fb05712c30f0424da3683bff032f0f96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ff001664432c4430ade9e899f5fcafdb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
